{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brianreed/opt/anaconda3/lib/python3.7/site-packages/dask/dataframe/utils.py:14: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import os\n",
    "import re\n",
    "\n",
    "import collections\n",
    "import datetime\n",
    "import time\n",
    " \n",
    "import geopandas as gpd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import rasterio\n",
    "\n",
    "from difflib import get_close_matches\n",
    "\n",
    "from fuzzywuzzy import process\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "import dask.dataframe as dd\n",
    "\n",
    "import gc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(weatherType,yearRange1,yearRange2):\n",
    "\n",
    "    if weatherType == \"Tmax\":\n",
    "        weatherVar = \"temperature\"\n",
    "    else: \n",
    "        weatherVar = \"precipitation\"\n",
    "    \n",
    "    year = yearRange1\n",
    "    filename = \"../../../../../../../Volumes/backup2/dissData/prism/zipcode\" + weatherType + str(year) + \".csv\"\n",
    "    data = dd.read_csv(filename, assume_missing=True)[['ZIP','date',weatherVar]]\n",
    "    # data = data[~(data[weatherVar].isna().compute())]\n",
    "\n",
    "    years = range(yearRange1 + 1,yearRange2 + 1)\n",
    "    for year in years:\n",
    "        filename = \"../../../../../../../Volumes/backup2/dissData/prism/zipcode\" + weatherType + str(year) + \".csv\"\n",
    "        tempData = dd.read_csv(filename, assume_missing=True)[['ZIP','date',weatherVar]]\n",
    "        # tempData = tempData[~(tempData[weatherVar].isna().compute())]\n",
    "        data = data.append(tempData)\n",
    "\n",
    "    data = data[~(data[weatherVar].isna())].compute()\n",
    "    \n",
    "    return(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numberQuants    = 20\n",
    "\n",
    "quantiles       = np.arange(0.0, 1.05, 1/numberQuants)\n",
    "\n",
    "quant_labels   = ['quant_' + str(n)[0:4] for n in quantiles]\n",
    "\n",
    "print(quant_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(quantiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precipitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "weatherType = \"Precip\" # Tmax\n",
    "data = getData(weatherType,1981,2009)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precipQuants = data.precipitation.quantile(q = quantiles)\n",
    "\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../../../../../../../Volumes/backup2/dissData/prism/precipQuants_1981.2009.txt'\n",
    "'''with open(filename, 'wb') as handle:\n",
    "    pickle.dump(precipQuants, handle)'''\n",
    "    \n",
    "with open(filename, 'w') as f:\n",
    "    f.write(str(precipQuants.values))\n",
    "    \n",
    "del data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ZIP</th>\n",
       "      <th>date</th>\n",
       "      <th>precipitation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>1001.0</td>\n",
       "      <td>19810101.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>1002.0</td>\n",
       "      <td>19810101.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>1003.0</td>\n",
       "      <td>19810101.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>1005.0</td>\n",
       "      <td>19810101.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>1007.0</td>\n",
       "      <td>19810101.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ZIP        date  precipitation\n",
       "142  1001.0  19810101.0            0.0\n",
       "143  1002.0  19810101.0            0.0\n",
       "144  1003.0  19810101.0            0.0\n",
       "145  1005.0  19810101.0            0.0\n",
       "146  1007.0  19810101.0            0.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "weatherType = \"Tmax\"\n",
    "data = getData(weatherType, 1981, 2009)\n",
    "\n",
    "tmaxQuants = data.temperature.quantile(q = quantiles) # following is no longer nec bc we call compute for nas: .compute()\n",
    "\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../../../../../../../Volumes/backup2/dissData/prism/tmaxQuants_1981.2009.pkl'\n",
    "with open(filename, 'wb') as handle:\n",
    "    pickle.dump(tmaxQuants, handle)\n",
    "    \n",
    "del data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tmaxQuants)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now go through the data from 2010 - 2019 and find time spent in each bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../../../../../../../Volumes/backup2/dissData/prism/tmaxQuants_1981.2009.pkl'\n",
    "'''with open(filename, 'wb') as handle:\n",
    "    pickle.dump(tmaxQuants, handle)\n",
    "    '''\n",
    "tmaxQuants = pd.read_pickle(filename)\n",
    "tmaxQuants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../../../../../../../Volumes/backup2/dissData/prism/precipQuants_1981.2009.txt'\n",
    "precipQuants = open(filename, \"r\").read()\n",
    "precipQuants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findQuarterlyQuants(weatherType, quartileList, df, quant_labels):\n",
    "    \n",
    "    weatherCut = weatherType + \"Cut\"\n",
    "    weatherCutLabels = weatherCut + 'labels'\n",
    "    \n",
    "    df[weatherCutLabels] = pd.Series(pd.cut(df[weatherType],\n",
    "                                      bins = list(quartileList),\n",
    "                                     labels = quant_labels[1:], duplicates = 'drop'))\n",
    "    \n",
    "    df[weatherCut] = pd.Series(pd.cut(df[weatherType],\n",
    "                                      bins = list(quartileList)))\n",
    "    \n",
    "    df['month'] = df.date.astype(str).str.slice(4,6)\n",
    "\n",
    "    df['quarter'] = 'q1'\n",
    "\n",
    "    df.loc[df['month'].isin(['04','05','06']), 'quarter'] = 'q2'\n",
    "    df.loc[df['month'].isin(['07','08','09']), 'quarter'] = 'q3'\n",
    "    df.loc[df['month'].isin(['10','11','12']), 'quarter'] = 'q4'\n",
    "\n",
    "    df['yearQuarter'] = df.date.astype(str).str.slice(0,4) + df.quarter\n",
    "\n",
    "    occurrences = weatherType + \"Occurences\" \n",
    "\n",
    "    summaryDF = df.groupby(['ZIP','yearQuarter',weatherCutLabels]).size().reset_index()\n",
    "    summaryDF.columns = ['zip','yearQuarter',weatherCutLabels,occurrences]\n",
    "    \n",
    "    '''\n",
    "    summaryDF = df.groupby(['ZIP','yearQuarter',weatherCut]).size().reset_index()\n",
    "    summaryDF.columns = ['zip','yearQuarter',weatherCut,occurrences]\n",
    "    '''\n",
    "    \n",
    "    return(summaryDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "recentDecadeTemps = getData(\"Tmax\",2009,2009)\n",
    "print(time.time() - start)\n",
    "\n",
    "tempQuarterlyBins = findQuarterlyQuants(weatherType = 'temperature', quartileList = tmaxQuants, df = recentDecadeTemps)\n",
    "print(tempQuarterlyBins.head())\n",
    "\n",
    "print(time.time() - start)\n",
    "\n",
    "tempQuarterlyBinsPivot = tempQuarterlyBins.pivot(index=['zip','yearQuarter'], columns='temperatureCutlabels', \n",
    "                            values='temperatureOccurences').reset_index(drop = True).reset_index().rename_axis(None, axis=1)\n",
    "\n",
    "tempQuarterlyBinsPivot.to_csv(\"../../../../../../../Volumes/backup2/dissData/prism/tempQuarterlyBins_2009.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del tempQuarterlyBins\n",
    "del recentDecadeTemps\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many of the precipitation quartiles are duplicated. Let's make sure we just have the unique values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_indices = [list(precipQuants).index(i) for i in precipQuants.unique()]\n",
    "quant_labels_subset = [quant_labels[i] for i in unique_indices]\n",
    "precipQuants_subset = [list(precipQuants)[i] for i in unique_indices]\n",
    "\n",
    "print(precipQuants_subset,quant_labels_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_labels_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "recentDecadePrecip = getData(\"Precip\",2009,2009)\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precipQuarterlyBins = findQuarterlyQuants(weatherType = 'precipitation', quartileList = precipQuants_subset, \n",
    "                                          df = recentDecadePrecip, quant_labels = quant_labels_subset)\n",
    "print(precipQuarterlyBins.head())\n",
    "\n",
    "print(time.time() - start)\n",
    "\n",
    "precipQuarterlyBinsPivot = precipQuarterlyBins.pivot(index=['zip','yearQuarter'], \n",
    "        columns='precipitationCutlabels', values='precipitationOccurences').reset_index().\\\n",
    "        rename_axis(None, axis=1)\n",
    "\n",
    "precipQuarterlyBinsPivot.columns.values[2:] = 'precip_' + precipQuarterlyBinsPivot.columns.values[2:]\n",
    "\n",
    "\n",
    "\n",
    "precipQuarterlyBinsPivot.to_csv(\"../../../../../../../Volumes/backup2/dissData/prism/precipQuarterlyBins_2009.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"../../../../../../../Volumes/backup2/dissData/prism/tempQuarterlyBins_2010.2019.csv\").drop(columns = {\"Unnamed: 0\"})\n",
    "test = test.rename_axis(None, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.columns.values[2:] = 'tmax_' + test.columns.values[2:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv(\"../../../../../../../Volumes/backup2/dissData/prism/tempQuarterlyBins_2010.2019.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmax   = pd.read_csv(\"../../../../../../../Volumes/backup2/dissData/prism/tempQuarterlyBins_2009.csv\").drop(columns = {\"Unnamed: 0\"})\n",
    "precip = pd.read_csv(\"../../../../../../../Volumes/backup2/dissData/prism/precipQuarterlyBins_2009.csv\").drop(columns = {\"Unnamed: 0\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allWeather = tmax.merge(precip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allWeather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allWeather['year'] = allWeather.yearQuarter.str.slice(0,4)\n",
    "allWeather['qtr']  = allWeather.yearQuarter.str.slice(5,6).astype('float')\n",
    "allWeather['zipcode']  = allWeather.zip.astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allWeather.zipcode.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allWeather.to_csv(\"../../../../../../../Volumes/backup2/dissData/prism/allWeatherBins_2009.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
