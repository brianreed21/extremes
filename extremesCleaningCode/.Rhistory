print(years)
for (s in scenarios[1]){
print("getting bricks")
print(s)
# pr
filename_pr_hist = paste0("../../../../../../../Volumes/backup2/dissData/cmip6Data/hist/pr/pr_day_MIROC6_historical_r",s,"i1p1f1_gn_",years,".nc")
# tmax
filename_tasmax_hist    = paste0("../../../../../../../Volumes/backup2/dissData/cmip6Data/hist/tasmax/tasmax_day_MIROC6_historical_r",s,"i1p1f1_gn_",years,".nc")
# extract and save all these
################
if (!is.na(file.info(filename_pr_hist)$size)){
if (file.info(filename_pr_hist)$size > 0){
print("pr_hist")
pr_hist        <- brick(filename_pr_hist,  varname = "pr")
proj4string(pr_hist)=CRS("+init=EPSG:4326")
pr_hist <- rotate(pr_hist)
geoHQ_pr_hist <- raster::extract(pr_hist, hq.spdf,  fun=mean, na.rm=TRUE, sp=TRUE)
data = geoHQ_pr_hist@data
data$s = s
data$variable = "pr_hist"
allData[[index]] =  melt(setDT(data), id.vars = c("zipcode","latitude","longitude","s","variable"), variable.name = "date")
}
}
#################
if (!is.na(file.info(filename_tasmax_hist)$size)){
if (file.info(filename_tasmax_hist)$size > 0){
print("tasmax_hist")
tasmax_hist    <- brick(filename_tasmax_hist,  varname = "tasmax")
proj4string(tasmax_hist)=CRS("+init=EPSG:4326")
tasmax_hist <- rotate(tasmax_hist)
geoHQ_tasmax_hist <- raster::extract(tasmax_hist, hq.spdf,  fun=mean, na.rm=TRUE, sp=TRUE)
data = geoHQ_tasmax_hist@data
data$s = s
data$variable = "tasmax_hist"
allData[[index]] =  melt(setDT(data), id.vars = c("zipcode","latitude","longitude","s","variable"), variable.name = "date")
}
}
index = index + 1
}
}
allData[[1]]
head(data)
data$s
data$variable
melt(setDT(data), id.vars = c("zipcode","latitude","longitude","s","variable"), variable.name = "date")
index
allData_combined <- do.call(rbind.data.frame, allData)
head(allData_combined)
# go through the scenarios and find 95th percentile
index = 1
scenarios = seq(1,2)
yearList = c("19800101-19891231", "19900101-19991231")
allData = list()
for (years in yearList){
print(years)
for (s in scenarios[1]){
print("getting bricks")
print(s)
# pr
filename_pr_hist = paste0("../../../../../../../Volumes/backup2/dissData/cmip6Data/hist/pr/pr_day_MIROC6_historical_r",s,"i1p1f1_gn_",years,".nc")
# tmax
filename_tasmax_hist    = paste0("../../../../../../../Volumes/backup2/dissData/cmip6Data/hist/tasmax/tasmax_day_MIROC6_historical_r",s,"i1p1f1_gn_",years,".nc")
# extract and save all these
################
if (!is.na(file.info(filename_pr_hist)$size)){
if (file.info(filename_pr_hist)$size > 0){
print("pr_hist")
pr_hist        <- brick(filename_pr_hist,  varname = "pr")
proj4string(pr_hist)=CRS("+init=EPSG:4326")
pr_hist <- rotate(pr_hist)
geoHQ_pr_hist <- raster::extract(pr_hist, hq.spdf,  fun=mean, na.rm=TRUE, sp=TRUE)
data = geoHQ_pr_hist@data
data$s = s
data$variable = "pr_hist"
allData[[index]] =  melt(setDT(data), id.vars = c("zipcode","latitude","longitude","s","variable"), variable.name = "date")
}
}
#################
if (!is.na(file.info(filename_tasmax_hist)$size)){
if (file.info(filename_tasmax_hist)$size > 0){
print("tasmax_hist")
tasmax_hist    <- brick(filename_tasmax_hist,  varname = "tasmax")
proj4string(tasmax_hist)=CRS("+init=EPSG:4326")
tasmax_hist <- rotate(tasmax_hist)
geoHQ_tasmax_hist <- raster::extract(tasmax_hist, hq.spdf,  fun=mean, na.rm=TRUE, sp=TRUE)
data = geoHQ_tasmax_hist@data
data$s = s
data$variable = "tasmax_hist"
allData[[index]] =  melt(setDT(data), id.vars = c("zipcode","latitude","longitude","s","variable"), variable.name = "date")
}
}
index = index + 1
}
}
rm(pr_hist, tasmax_hist)
rm(hq,hq.spdf,data,geoHQ_pr_hist,geoHQ_tasmax_hist)
# reformat the data
allData_combined <- do.call(rbind.data.frame, allData)
rm(allData)
allData_combined
allData_combined$convDate <- as.Date(str_sub(long$date,2,11), '%Y.%m.%d')
allData_combined$year <- format(allData_combined$convDate,"%Y")
allData_combined$quarter <- quarters(allData_combined$convDate)
allData_combined <- subset(allData_combined, select = -c(latitude,longitude,s,date,convDate,year))
allData_combined$value <- as.numeric(allData_combined$value)
gc()
allData_combined = allData_combined[complete.cases(allData_combined$value) & (allData_combined$quarter != 'QNA'), ]
gc()
head(allData_combined)
allData_combined <- do.call(rbind.data.frame, allData)
hq = read.csv("~/Documents/supplyChain/data/companyData/justHQs.csv") %>%
filter(year > 2015 & year < 2019) %>% dplyr::select(-c('X', 'year'))
hq.spdf = SpatialPointsDataFrame(coords=hq[,c('longitude','latitude')],
data=hq, proj4string = CRS("+proj=longlat +ellps=WGS84 +no_defs"))
# go through the scenarios and find 95th percentile
index = 1
scenarios = seq(1,2)
yearList = c("19800101-19891231", "19900101-19991231")
allData = list()
for (years in yearList){
print(years)
for (s in scenarios[1]){
print("getting bricks")
print(s)
# pr
filename_pr_hist = paste0("../../../../../../../Volumes/backup2/dissData/cmip6Data/hist/pr/pr_day_MIROC6_historical_r",s,"i1p1f1_gn_",years,".nc")
# tmax
filename_tasmax_hist    = paste0("../../../../../../../Volumes/backup2/dissData/cmip6Data/hist/tasmax/tasmax_day_MIROC6_historical_r",s,"i1p1f1_gn_",years,".nc")
# extract and save all these
################
if (!is.na(file.info(filename_pr_hist)$size)){
if (file.info(filename_pr_hist)$size > 0){
print("pr_hist")
pr_hist        <- brick(filename_pr_hist,  varname = "pr")
proj4string(pr_hist)=CRS("+init=EPSG:4326")
pr_hist <- rotate(pr_hist)
geoHQ_pr_hist <- raster::extract(pr_hist, hq.spdf,  fun=mean, na.rm=TRUE, sp=TRUE)
data = geoHQ_pr_hist@data
data$s = s
data$variable = "pr_hist"
allData[[index]] =  melt(setDT(data), id.vars = c("zipcode","latitude","longitude","s","variable"), variable.name = "date")
}
}
#################
if (!is.na(file.info(filename_tasmax_hist)$size)){
if (file.info(filename_tasmax_hist)$size > 0){
print("tasmax_hist")
tasmax_hist    <- brick(filename_tasmax_hist,  varname = "tasmax")
proj4string(tasmax_hist)=CRS("+init=EPSG:4326")
tasmax_hist <- rotate(tasmax_hist)
geoHQ_tasmax_hist <- raster::extract(tasmax_hist, hq.spdf,  fun=mean, na.rm=TRUE, sp=TRUE)
data = geoHQ_tasmax_hist@data
data$s = s
data$variable = "tasmax_hist"
allData[[index]] =  melt(setDT(data), id.vars = c("zipcode","latitude","longitude","s","variable"), variable.name = "date")
}
}
index = index + 1
}
}
rm(pr_hist, tasmax_hist)
rm(hq,hq.spdf,data,geoHQ_pr_hist,geoHQ_tasmax_hist)
# reformat the data
allData_combined <- do.call(rbind.data.frame, allData)
# rm(allData)
allData_combined
allData_combined$convDate <- as.Date(str_sub(allData_combined$date,2,11), '%Y.%m.%d')
allData_combined = allData_combined %>% filter(year >= 1981 & year <= 1999)
allData_combined$year
allData_combined$convDate
format(allData_combined$convDate,"%Y")
allData_combined$year
allData_combined$year <- format(allData_combined$convDate,"%Y")
allData_combined$year
allData_combined %>% filter(year >= 1981 & year <= 1999)
allData_combined <- allData_combined %>% filter(year >= 1981 & year <= 1999)
allData_combined
allData_combined$quarter <- quarters(allData_combined$convDate)
allData_combined
allData_combined <- subset(allData_combined, select = -c(latitude,longitude,s,date,convDate,year))
allData_combined
allData_combined$value <- as.numeric(allData_combined$value)
gc()
allData_combined = allData_combined[complete.cases(allData_combined$value) & (allData_combined$quarter != 'QNA'), ]
allData_combined
quants = allData_combined %>% group_by(quarter,zipcode,variable) %>% summarize(quant95 = quantile(value,0.95), na.rm = TRUE)
quants
quants$quant95
hist(quants)
quabnts
quants
hist(quants$quant95)
quants = allData_combined %>% group_by(c(quarter,zipcode,variable)) %>% summarize(quant95 = quantile(value,0.95), na.rm = TRUE)
table(quants$variable)
index = 1
scenarios = seq(1,10)
yearList = c("19800101-19891231", "19900101-19991231")
allData = list()
for (years in yearList){
print(years)
for (s in scenarios[1:5]){
print("getting bricks")
print(s)
# pr
filename_pr_hist = paste0("../../../../../../../Volumes/backup2/dissData/cmip6Data/hist/pr/pr_day_MIROC6_historical_r",s,"i1p1f1_gn_",years,".nc")
# tmax
filename_tasmax_hist    = paste0("../../../../../../../Volumes/backup2/dissData/cmip6Data/hist/tasmax/tasmax_day_MIROC6_historical_r",s,"i1p1f1_gn_",years,".nc")
# extract and save all these
################
if (!is.na(file.info(filename_pr_hist)$size)){
if (file.info(filename_pr_hist)$size > 0){
print("pr_hist")
pr_hist        <- brick(filename_pr_hist,  varname = "pr")
proj4string(pr_hist)=CRS("+init=EPSG:4326")
pr_hist <- rotate(pr_hist)
geoHQ_pr_hist <- raster::extract(pr_hist, hq.spdf,  fun=mean, na.rm=TRUE, sp=TRUE)
data = geoHQ_pr_hist@data
data$s = s
data$variable = "pr_hist"
allData[[index]] =  melt(setDT(data), id.vars = c("zipcode","latitude","longitude","s","variable"), variable.name = "date")
}
}
index = index + 1
#################
if (!is.na(file.info(filename_tasmax_hist)$size)){
if (file.info(filename_tasmax_hist)$size > 0){
print("tasmax_hist")
tasmax_hist    <- brick(filename_tasmax_hist,  varname = "tasmax")
proj4string(tasmax_hist)=CRS("+init=EPSG:4326")
tasmax_hist <- rotate(tasmax_hist)
geoHQ_tasmax_hist <- raster::extract(tasmax_hist, hq.spdf,  fun=mean, na.rm=TRUE, sp=TRUE)
data = geoHQ_tasmax_hist@data
data$s = s
data$variable = "tasmax_hist"
allData[[index]] =  melt(setDT(data), id.vars = c("zipcode","latitude","longitude","s","variable"), variable.name = "date")
}
}
index = index + 1
}
}
hq = read.csv("~/Documents/supplyChain/data/companyData/justHQs.csv") %>%
filter(year > 2015 & year < 2019) %>% dplyr::select(-c('X', 'year'))
hq.spdf = SpatialPointsDataFrame(coords=hq[,c('longitude','latitude')],
data=hq, proj4string = CRS("+proj=longlat +ellps=WGS84 +no_defs"))
# go through the scenarios and find 95th percentile
index = 1
scenarios = seq(1,10)
yearList = c("19800101-19891231", "19900101-19991231")
allData = list()
for (years in yearList){
print(years)
for (s in scenarios[1:5]){
print("getting bricks")
print(s)
# pr
filename_pr_hist = paste0("../../../../../../../Volumes/backup2/dissData/cmip6Data/hist/pr/pr_day_MIROC6_historical_r",s,"i1p1f1_gn_",years,".nc")
# tmax
filename_tasmax_hist    = paste0("../../../../../../../Volumes/backup2/dissData/cmip6Data/hist/tasmax/tasmax_day_MIROC6_historical_r",s,"i1p1f1_gn_",years,".nc")
# extract and save all these
################
if (!is.na(file.info(filename_pr_hist)$size)){
if (file.info(filename_pr_hist)$size > 0){
print("pr_hist")
pr_hist        <- brick(filename_pr_hist,  varname = "pr")
proj4string(pr_hist)=CRS("+init=EPSG:4326")
pr_hist <- rotate(pr_hist)
geoHQ_pr_hist <- raster::extract(pr_hist, hq.spdf,  fun=mean, na.rm=TRUE, sp=TRUE)
data = geoHQ_pr_hist@data
data$s = s
data$variable = "pr_hist"
allData[[index]] =  melt(setDT(data), id.vars = c("zipcode","latitude","longitude","s","variable"), variable.name = "date")
}
}
index = index + 1
#################
if (!is.na(file.info(filename_tasmax_hist)$size)){
if (file.info(filename_tasmax_hist)$size > 0){
print("tasmax_hist")
tasmax_hist    <- brick(filename_tasmax_hist,  varname = "tasmax")
proj4string(tasmax_hist)=CRS("+init=EPSG:4326")
tasmax_hist <- rotate(tasmax_hist)
geoHQ_tasmax_hist <- raster::extract(tasmax_hist, hq.spdf,  fun=mean, na.rm=TRUE, sp=TRUE)
data = geoHQ_tasmax_hist@data
data$s = s
data$variable = "tasmax_hist"
allData[[index]] =  melt(setDT(data), id.vars = c("zipcode","latitude","longitude","s","variable"), variable.name = "date")
}
}
index = index + 1
}
}
rm(pr_hist, tasmax_hist)
rm(hq,hq.spdf,data,geoHQ_pr_hist,geoHQ_tasmax_hist)
# reformat the data
allData_combined <- do.call(rbind.data.frame, allData)
# rm(allData)
allData_combined$convDate <- as.Date(str_sub(allData_combined$date,2,11), '%Y.%m.%d')
head(allData_combined)
allData_combined <- do.call(rbind.data.frame, allData) %>%
dplyr::select(-c('latitude', 'longitude','s'))
rm(allData_combined)
rm(long, quants)
allData_combined <- do.call(rbind.data.frame, allData) %>%
dplyr::select(-c('latitude', 'longitude','s'))
hq = read.csv("~/Documents/supplyChain/data/companyData/justHQs.csv") %>%
dplyr::select(-c('X', 'year')) # filter(year > 2015 & year < 2019) %>%
hq.spdf = SpatialPointsDataFrame(coords=hq[,c('longitude','latitude')],
data=hq, proj4string = CRS("+proj=longlat +ellps=WGS84 +no_defs"))
head(hq)
hq = read.csv("~/Documents/supplyChain/data/companyData/justHQs.csv") %>%
dplyr::select(-c('X', 'year')) %>% drop_duplicates() # filter(year > 2015 & year < 2019) %>%
hq = read.csv("~/Documents/supplyChain/data/companyData/justHQs.csv") %>%
dplyr::select(-c('X', 'year')) %>% unique()
hq.spdf = SpatialPointsDataFrame(coords=hq[,c('longitude','latitude')],
data=hq, proj4string = CRS("+proj=longlat +ellps=WGS84 +no_defs"))
# go through the scenarios and find 95th percentile
index = 1
scenarios = seq(1,10)
yearList = c("19800101-19891231", "19900101-19991231")
allData = list()
for (years in yearList){
print(years)
for (s in scenarios[1]){
print("getting bricks")
print(s)
# pr
filename_pr_hist = paste0("../../../../../../../Volumes/backup2/dissData/cmip6Data/hist/pr/pr_day_MIROC6_historical_r",s,"i1p1f1_gn_",years,".nc")
# tmax
filename_tasmax_hist    = paste0("../../../../../../../Volumes/backup2/dissData/cmip6Data/hist/tasmax/tasmax_day_MIROC6_historical_r",s,"i1p1f1_gn_",years,".nc")
# extract and save all these
################
if (!is.na(file.info(filename_pr_hist)$size)){
if (file.info(filename_pr_hist)$size > 0){
print("pr_hist")
pr_hist        <- brick(filename_pr_hist,  varname = "pr")
proj4string(pr_hist)=CRS("+init=EPSG:4326")
pr_hist <- rotate(pr_hist)
geoHQ_pr_hist <- raster::extract(pr_hist, hq.spdf,  fun=mean, na.rm=TRUE, sp=TRUE)
data = geoHQ_pr_hist@data
data$s = s
data$variable = "pr_hist"
allData[[index]] =  melt(setDT(data), id.vars = c("zipcode","latitude","longitude","s","variable"), variable.name = "date")
}
}
index = index + 1
#################
if (!is.na(file.info(filename_tasmax_hist)$size)){
if (file.info(filename_tasmax_hist)$size > 0){
print("tasmax_hist")
tasmax_hist    <- brick(filename_tasmax_hist,  varname = "tasmax")
proj4string(tasmax_hist)=CRS("+init=EPSG:4326")
tasmax_hist <- rotate(tasmax_hist)
geoHQ_tasmax_hist <- raster::extract(tasmax_hist, hq.spdf,  fun=mean, na.rm=TRUE, sp=TRUE)
data = geoHQ_tasmax_hist@data
data$s = s
data$variable = "tasmax_hist"
allData[[index]] =  melt(setDT(data), id.vars = c("zipcode","latitude","longitude","s","variable"), variable.name = "date")
}
}
index = index + 1
}
}
rm(pr_hist, tasmax_hist)
rm(hq,hq.spdf,data,geoHQ_pr_hist,geoHQ_tasmax_hist)
# reformat the data
allData_combined <- do.call(rbind.data.frame, allData) %>%
dplyr::select(-c('latitude', 'longitude','s'))
allData_combined$convDate <- as.Date(str_sub(allData_combined$date,2,11), '%Y.%m.%d')
allData_combined$year <- format(allData_combined$convDate,"%Y")
# filter to match the other time period
allData_combined <- allData_combined %>% filter(year >= 1981 & year <= 1999)
rm(allData)
allData_combined <- allData_combined %>% filter(year >= 1981 & year <= 1999)
gc()
allData_combined$quarter <- quarters(allData_combined$convDate)
allData_combined <- subset(allData_combined, select = -c(latitude,longitude,s,date,convDate,year))
head(allData_combined)
allData_combined <- subset(allData_combined, select = -c(date,convDate,year))
allData_combined$value <- as.numeric(allData_combined$value)
gc()
allData_combined = allData_combined[complete.cases(allData_combined$value) & (allData_combined$quarter != 'QNA'), ]
gc()
quants = allData_combined %>% group_by(c(quarter,zipcode,variable)) %>% summarize(quant95 = quantile(value,0.95), na.rm = TRUE)
allData_combined
quants = allData_combined %>% group_by(c(quarter,zipcode,variable)) %>% summarize(quant95 = quantile(value,0.95), na.rm = TRUE)
write.csv(allData_combined,"../../../../../../../Volumes/backup2/dissData/cmip6Data/hist/mirocHQs_198199.csv",
row.names = FALSE)
index = 1
scenarios = seq(1,10)
yearList = c("20150101-20241231", "20250101-20341231", "20350101-20441231",)
# go through the scenarios and find 95th percentile
index = 1
scenarios = seq(1,10)
yearList = c("20150101-20241231", "20250101-20341231", "20350101-20441231")
allData = list()
for (years in yearList){
print(years)
for (s in scenarios[1]){
print("getting bricks")
print(s)
# pr
# filename_pr_hist = paste0("../../../../../../../Volumes/backup2/dissData/cmip6Data/hist/pr/pr_day_MIROC6_historical_r",s,"i1p1f1_gn_",years,".nc")
filename_pr_hist = paste0("../../../../../../../Volumes/backup2/dissData/cmip6Data/proj/pr/pr_day_MIROC6_ssp585_r",s,"i1p1f1_gn_",years,".nc")
# tmax
# filename_tasmax_hist    = paste0("../../../../../../../Volumes/backup2/dissData/cmip6Data/hist/tasmax/tasmax_day_MIROC6_historical_r",s,"i1p1f1_gn_",years,".nc")
filename_tasmax_hist    = paste0("../../../../../../../Volumes/backup2/dissData/cmip6Data/proj/tasmax/tasmax_day_MIROC6_ssp585_r",s,"i1p1f1_gn_",years,".nc")
# extract and save all these
################
if (!is.na(file.info(filename_pr_hist)$size)){
if (file.info(filename_pr_hist)$size > 0){
print("pr_hist")
pr_hist        <- brick(filename_pr_hist,  varname = "pr")
proj4string(pr_hist)=CRS("+init=EPSG:4326")
pr_hist <- rotate(pr_hist)
geoHQ_pr_hist <- raster::extract(pr_hist, hq.spdf,  fun=mean, na.rm=TRUE, sp=TRUE)
data = geoHQ_pr_hist@data
data$s = s
data$variable = "pr_hist"
allData[[index]] =  melt(setDT(data), id.vars = c("zipcode","latitude","longitude","s","variable"), variable.name = "date")
}
}
index = index + 1
#################
if (!is.na(file.info(filename_tasmax_hist)$size)){
if (file.info(filename_tasmax_hist)$size > 0){
print("tasmax_hist")
tasmax_hist    <- brick(filename_tasmax_hist,  varname = "tasmax")
proj4string(tasmax_hist)=CRS("+init=EPSG:4326")
tasmax_hist <- rotate(tasmax_hist)
geoHQ_tasmax_hist <- raster::extract(tasmax_hist, hq.spdf,  fun=mean, na.rm=TRUE, sp=TRUE)
data = geoHQ_tasmax_hist@data
data$s = s
data$variable = "tasmax_hist"
allData[[index]] =  melt(setDT(data), id.vars = c("zipcode","latitude","longitude","s","variable"), variable.name = "date")
}
}
index = index + 1
}
}
hq = read.csv("~/Documents/supplyChain/data/companyData/justHQs.csv") %>%
dplyr::select(-c('X', 'year')) %>% unique() # filter(year > 2015 & year < 2019) %>%
hq.spdf = SpatialPointsDataFrame(coords=hq[,c('longitude','latitude')],
data=hq, proj4string = CRS("+proj=longlat +ellps=WGS84 +no_defs"))
# go through the scenarios and find 95th percentile
index = 1
scenarios = seq(1,10)
yearList = c("20150101-20241231", "20250101-20341231", "20350101-20441231")
allData = list()
for (years in yearList){
print(years)
for (s in scenarios[1]){
print("getting bricks")
print(s)
# pr
# filename_pr_hist = paste0("../../../../../../../Volumes/backup2/dissData/cmip6Data/hist/pr/pr_day_MIROC6_historical_r",s,"i1p1f1_gn_",years,".nc")
filename_pr_hist = paste0("../../../../../../../Volumes/backup2/dissData/cmip6Data/proj/pr/pr_day_MIROC6_ssp585_r",s,"i1p1f1_gn_",years,".nc")
# tmax
# filename_tasmax_hist    = paste0("../../../../../../../Volumes/backup2/dissData/cmip6Data/hist/tasmax/tasmax_day_MIROC6_historical_r",s,"i1p1f1_gn_",years,".nc")
filename_tasmax_hist    = paste0("../../../../../../../Volumes/backup2/dissData/cmip6Data/proj/tasmax/tasmax_day_MIROC6_ssp585_r",s,"i1p1f1_gn_",years,".nc")
# extract and save all these
################
if (!is.na(file.info(filename_pr_hist)$size)){
if (file.info(filename_pr_hist)$size > 0){
print("pr_hist")
pr_hist        <- brick(filename_pr_hist,  varname = "pr")
proj4string(pr_hist)=CRS("+init=EPSG:4326")
pr_hist <- rotate(pr_hist)
geoHQ_pr_hist <- raster::extract(pr_hist, hq.spdf,  fun=mean, na.rm=TRUE, sp=TRUE)
data = geoHQ_pr_hist@data
data$s = s
data$variable = "pr_hist"
allData[[index]] =  melt(setDT(data), id.vars = c("zipcode","latitude","longitude","s","variable"), variable.name = "date")
}
}
index = index + 1
#################
if (!is.na(file.info(filename_tasmax_hist)$size)){
if (file.info(filename_tasmax_hist)$size > 0){
print("tasmax_hist")
tasmax_hist    <- brick(filename_tasmax_hist,  varname = "tasmax")
proj4string(tasmax_hist)=CRS("+init=EPSG:4326")
tasmax_hist <- rotate(tasmax_hist)
geoHQ_tasmax_hist <- raster::extract(tasmax_hist, hq.spdf,  fun=mean, na.rm=TRUE, sp=TRUE)
data = geoHQ_tasmax_hist@data
data$s = s
data$variable = "tasmax_hist"
allData[[index]] =  melt(setDT(data), id.vars = c("zipcode","latitude","longitude","s","variable"), variable.name = "date")
}
}
index = index + 1
}
}
rm(pr_hist, tasmax_hist)
rm(hq,hq.spdf,data,geoHQ_pr_hist,geoHQ_tasmax_hist)
# reformat the data
allData_combined <- do.call(rbind.data.frame, allData) %>%
dplyr::select(-c('latitude', 'longitude','s'))
rm(allData)
allData_combined$convDate <- as.Date(str_sub(allData_combined$date,2,11), '%Y.%m.%d')
allData_combined$year <- format(allData_combined$convDate,"%Y")
# filter to match the other time period
allData_combined <- allData_combined %>% filter(year >= 2020 & year <= 2040)
allData_combined$quarter <- quarters(allData_combined$convDate)
allData_combined <- subset(allData_combined, select = -c(date,convDate,year))
allData_combined$value <- as.numeric(allData_combined$value)
gc()
allData_combined = allData_combined[complete.cases(allData_combined$value) & (allData_combined$quarter != 'QNA'), ]
gc()
# change this so that it's by zipcode, but otherwise gtg
# quants = allData_combined %>% group_by(c(quarter,zipcode,variable)) %>% summarize(quant95 = quantile(value,0.95), na.rm = TRUE)
write.csv(allData_combined,"../../../../../../../Volumes/backup2/dissData/cmip6Data/proj/mirocHQs_202040.csv",
row.names = FALSE)
