{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Set-Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import os\n",
    "import re\n",
    "\n",
    "import collections\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "import geopandas as gpd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import rasterio\n",
    "\n",
    "from difflib import get_close_matches\n",
    "\n",
    "from fuzzywuzzy import process\n",
    "from fuzzywuzzy import fuzz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Infogroup\n",
    "This is the infogroup code. It has most "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"../../data/companyData/infogroupPublic.csv\"\n",
    "hq = pd.read_csv(file, encoding = 'unicode_escape')[['ticker','archive_version_year',\n",
    "                                                    'company','city','state','zipcode',\n",
    "                                                    'latitude','longitude','business_status_code']]\n",
    "# hq = hq[hq.business_status_code == 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hq.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hq.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code commented out below lets us scale if we do the full infogroup file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "df = dd.read_csv( \"../../data/companyData/infogroup2010s.csv\", assume_missing=True, \n",
    "                 dtype={'parent_number': 'object','parent_employee_size_code': 'object',\n",
    "                       'parent_sales_volume_code': 'object',\n",
    "                       'abi': 'object'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brianreed/opt/anaconda3/lib/python3.7/site-packages/dask/utils.py:29: DtypeWarning: Columns (2) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>archive_version_year</th>\n",
       "      <th>abi</th>\n",
       "      <th>ticker</th>\n",
       "      <th>parent_number</th>\n",
       "      <th>company</th>\n",
       "      <th>address_line_1</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>location_employee_size_code</th>\n",
       "      <th>location_sales_volume_code</th>\n",
       "      <th>primary_naics_code</th>\n",
       "      <th>sic_code</th>\n",
       "      <th>business_status_code</th>\n",
       "      <th>parent_employee_size_code</th>\n",
       "      <th>parent_sales_volume_code</th>\n",
       "      <th>cbsa_code</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010.0</td>\n",
       "      <td>000002907</td>\n",
       "      <td>NaN</td>\n",
       "      <td>004556080</td>\n",
       "      <td>QUINCY COMPRESSOR</td>\n",
       "      <td>701 N DOBSON AVE</td>\n",
       "      <td>BAY MINETTE</td>\n",
       "      <td>AL</td>\n",
       "      <td>36507.0</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33391202.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19300.0</td>\n",
       "      <td>30.88473</td>\n",
       "      <td>-87.79219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010.0</td>\n",
       "      <td>000003178</td>\n",
       "      <td>NaN</td>\n",
       "      <td>389361817</td>\n",
       "      <td>TRONOX INC</td>\n",
       "      <td>1 KERR MCGEE RD</td>\n",
       "      <td>SAVANNAH</td>\n",
       "      <td>GA</td>\n",
       "      <td>31404.0</td>\n",
       "      <td>H</td>\n",
       "      <td>I</td>\n",
       "      <td>32599805.0</td>\n",
       "      <td>509901.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42340.0</td>\n",
       "      <td>32.07764</td>\n",
       "      <td>-81.02519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010.0</td>\n",
       "      <td>000004135</td>\n",
       "      <td>NaN</td>\n",
       "      <td>007530124</td>\n",
       "      <td>PPG INDUSTRIES INC</td>\n",
       "      <td>10800 S 13TH ST</td>\n",
       "      <td>OAK CREEK</td>\n",
       "      <td>WI</td>\n",
       "      <td>53154.0</td>\n",
       "      <td>H</td>\n",
       "      <td>I</td>\n",
       "      <td>32551011.0</td>\n",
       "      <td>509905.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>I</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33340.0</td>\n",
       "      <td>42.84868</td>\n",
       "      <td>-87.92959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010.0</td>\n",
       "      <td>000004358</td>\n",
       "      <td>NaN</td>\n",
       "      <td>441306552</td>\n",
       "      <td>GREENWALD INDUSTRIES</td>\n",
       "      <td>212 MIDDLESEX AVE</td>\n",
       "      <td>CHESTER</td>\n",
       "      <td>CT</td>\n",
       "      <td>6412.0</td>\n",
       "      <td>F</td>\n",
       "      <td>G</td>\n",
       "      <td>33399920.0</td>\n",
       "      <td>399903.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25540.0</td>\n",
       "      <td>41.42210</td>\n",
       "      <td>-72.44318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010.0</td>\n",
       "      <td>000004432</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GUIDA-SEIBERT DAIRY CO</td>\n",
       "      <td>433 PARK ST</td>\n",
       "      <td>NEW BRITAIN</td>\n",
       "      <td>CT</td>\n",
       "      <td>6051.0</td>\n",
       "      <td>G</td>\n",
       "      <td>H</td>\n",
       "      <td>11212001.0</td>\n",
       "      <td>202398.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25540.0</td>\n",
       "      <td>41.66500</td>\n",
       "      <td>-72.76954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   archive_version_year        abi ticker parent_number  \\\n",
       "0                2010.0  000002907    NaN     004556080   \n",
       "1                2010.0  000003178    NaN     389361817   \n",
       "2                2010.0  000004135    NaN     007530124   \n",
       "3                2010.0  000004358    NaN     441306552   \n",
       "4                2010.0  000004432    NaN           NaN   \n",
       "\n",
       "                  company     address_line_1         city state  zipcode  \\\n",
       "0       QUINCY COMPRESSOR   701 N DOBSON AVE  BAY MINETTE    AL  36507.0   \n",
       "1              TRONOX INC    1 KERR MCGEE RD     SAVANNAH    GA  31404.0   \n",
       "2      PPG INDUSTRIES INC    10800 S 13TH ST    OAK CREEK    WI  53154.0   \n",
       "3    GREENWALD INDUSTRIES  212 MIDDLESEX AVE      CHESTER    CT   6412.0   \n",
       "4  GUIDA-SEIBERT DAIRY CO        433 PARK ST  NEW BRITAIN    CT   6051.0   \n",
       "\n",
       "  location_employee_size_code location_sales_volume_code  primary_naics_code  \\\n",
       "0                           F                        NaN          33391202.0   \n",
       "1                           H                          I          32599805.0   \n",
       "2                           H                          I          32551011.0   \n",
       "3                           F                          G          33399920.0   \n",
       "4                           G                          H          11212001.0   \n",
       "\n",
       "   sic_code  business_status_code parent_employee_size_code  \\\n",
       "0       NaN                   3.0                         D   \n",
       "1  509901.0                   2.0                         H   \n",
       "2  509905.0                   2.0                         I   \n",
       "3  399903.0                   2.0                         B   \n",
       "4  202398.0                   9.0                       NaN   \n",
       "\n",
       "  parent_sales_volume_code  cbsa_code  latitude  longitude  \n",
       "0                      NaN    19300.0  30.88473  -87.79219  \n",
       "1                      NaN    42340.0  32.07764  -81.02519  \n",
       "2                      NaN    33340.0  42.84868  -87.92959  \n",
       "3                      NaN    25540.0  41.42210  -72.44318  \n",
       "4                      NaN    25540.0  41.66500  -72.76954  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hq = hq[(hq.business_status_code == 1.0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hq.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hq.to_csv('../../data/companyData/hqPublicAll.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hq.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert into geospatial dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geoHQ = gpd.GeoDataFrame(\n",
    "    hq,\n",
    "    geometry=gpd.points_from_xy(\n",
    "        hq[\"longitude\"],\n",
    "        hq[\"latitude\"],\n",
    "    ),\n",
    "    crs={\"init\":\"EPSG:4326\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geoHQ[geoHQ.archive_version_year == 1997].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the most basic version of the HQ information. BS takes it a step further by filtering for firms where the HQ are responsible for at least a certain percentage of the overall sales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/brianreed/Documents/supplyChain/extremes/extremesCleaningCode'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../data/companyData/infogroup.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-fb7f4252a75d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"../../data/companyData/infogroup.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhqSales\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'unicode_escape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mhqSales\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhqSales\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhqSales\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbusiness_status_code\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# hqSales = hq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoding_errors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         )\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m             )\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../data/companyData/infogroup.csv'"
     ]
    }
   ],
   "source": [
    "file = \"../../data/companyData/infogroup.csv\"\n",
    "hqSales = pd.read_csv(file, encoding = 'unicode_escape')\n",
    "hqSales = hqSales[hqSales.business_status_code == 1.0]\n",
    "\n",
    "# hqSales = hq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overstate the size of a location relative to the parent: put parent at low end and location at high end of ranges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hqSales.loc[hqSales.parent_employee_size_code == 'A', 'parent_employee_size_code'] = 1\n",
    "hqSales.loc[hqSales.parent_employee_size_code == 'B', 'parent_employee_size_code'] = 5\n",
    "hqSales.loc[hqSales.parent_employee_size_code == 'C', 'parent_employee_size_code'] = 10\n",
    "hqSales.loc[hqSales.parent_employee_size_code == 'D', 'parent_employee_size_code'] = 20\n",
    "hqSales.loc[hqSales.parent_employee_size_code == 'E', 'parent_employee_size_code'] = 50\n",
    "hqSales.loc[hqSales.parent_employee_size_code == 'F', 'parent_employee_size_code'] = 100\n",
    "hqSales.loc[hqSales.parent_employee_size_code == 'G', 'parent_employee_size_code'] = 250\n",
    "hqSales.loc[hqSales.parent_employee_size_code == 'H', 'parent_employee_size_code'] = 500\n",
    "hqSales.loc[hqSales.parent_employee_size_code == 'I', 'parent_employee_size_code'] = 1000\n",
    "hqSales.loc[hqSales.parent_employee_size_code == 'J', 'parent_employee_size_code'] = 5000\n",
    "hqSales.loc[hqSales.parent_employee_size_code == 'K', 'parent_employee_size_code'] = 10000\n",
    "\n",
    "\n",
    "hqSales.loc[hqSales.location_employee_size_code == 'A', 'location_employee_size_code'] = 4\n",
    "hqSales.loc[hqSales.location_employee_size_code == 'B', 'location_employee_size_code'] = 9\n",
    "hqSales.loc[hqSales.location_employee_size_code == 'C', 'location_employee_size_code'] = 19\n",
    "hqSales.loc[hqSales.location_employee_size_code == 'D', 'location_employee_size_code'] = 49\n",
    "hqSales.loc[hqSales.location_employee_size_code == 'E', 'location_employee_size_code'] = 99\n",
    "hqSales.loc[hqSales.location_employee_size_code == 'F', 'location_employee_size_code'] = 249\n",
    "hqSales.loc[hqSales.location_employee_size_code == 'G', 'location_employee_size_code'] = 499\n",
    "hqSales.loc[hqSales.location_employee_size_code == 'H', 'location_employee_size_code'] = 999\n",
    "hqSales.loc[hqSales.location_employee_size_code == 'I', 'location_employee_size_code'] = 4999\n",
    "hqSales.loc[hqSales.location_employee_size_code == 'J', 'location_employee_size_code'] = 9999\n",
    "hqSales.loc[hqSales.location_employee_size_code == 'K', 'location_employee_size_code'] = 10000\n",
    "\n",
    "\n",
    "hqSales['location_employee_size_code'] = pd.to_numeric(hqSales['location_employee_size_code'], errors='coerce')\n",
    "hqSales['parent_employee_size_code'] = pd.to_numeric(hqSales['parent_employee_size_code'], errors='coerce')\n",
    "hqSales['employeesAtLocation'] = hqSales['location_employee_size_code']/hqSales['parent_employee_size_code']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hqSales['employeesAtLocation'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(hqSales.employeesAtLocation > 0.75)/hqSales.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter down the location information to firms where we have at least 75% of employees at HQ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geoHQ = geoHQ[hqSales.employeesAtLocation > 0.75].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geoHQ.drop(columns = ['index','geometry']).to_csv('data/geoHQ.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geoHQ = pd.read_csv(\"../../data/geoHQ.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geoHQ.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geoHQ.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compustat1 = pd.read_csv(\"../../data/companyData/compustatChanges_All.csv\").drop(columns = ['Unnamed: 0'])\n",
    "\n",
    "compustat2 = pd.read_csv(\"../../data/companyData/compustatChanges_2010s.csv\").drop(columns = ['Unnamed: 0','naics'])\n",
    "\n",
    "compustat = compustat1.append(compustat2)\n",
    "\n",
    "compustat.rename(columns = {'tic': 'TICKER'}, inplace = True)\n",
    "\n",
    "print(compustat1.columns,compustat2.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(compustat.shape, compustat.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cstatCos = compustat[['year','companyName','TICKER']].drop_duplicates()\n",
    "cstatCos = cstatCos[cstatCos.year > 1996]\n",
    "\n",
    "geoHQ.rename(columns = {'archive_version_year': 'year'},inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geoHQ.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allIG = cstatCos.merge(geoHQ)\n",
    "allIG.to_csv(\"../../data/igHQ.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weather Data\n",
    "## *this is how we process the cmip6Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import netCDF4 as nc\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '../../../../../../../Volumes/backup2/dissData/cmip6Data/hist/pr/pr_day_MIROC6_historical_r7i1p1f1_gn_20100101-20141231.nc'\n",
    "data = xr.open_dataset(file)   #  nc.Dataset(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geoHQ = gpd.GeoDataFrame(\n",
    "    allIG,\n",
    "    geometry=gpd.points_from_xy(\n",
    "        allIG[\"longitude\"],\n",
    "        allIG[\"latitude\"],\n",
    "    ),\n",
    "    crs={\"init\":\"EPSG:4326\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geoHQ['longitude']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_point = data[\"pr\"].sel(lat=50, lon=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(test.temperature[test.year == 2010]).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now go through and make this iterable for the entire list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "data.pr.sel(allIG.iloc[0,:], method='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hqPost2010 = geoHQ[geoHQ.archive_version_year > 2010].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "\n",
    "\n",
    "tempsList = list()\n",
    "for i in range(0,hqPost2010.shape[0]):\n",
    "    nearbyTemps = temps.sel(hqPost2010.loc[i,['latitude','longitude']], method='nearest')\n",
    "    \n",
    "    tempsList.append(list(np.array(nearbyTemps.temperature[nearbyTemps.year == hqPost2010.archive_version_year[i]])))\n",
    "\n",
    "    if (i%100 == 0):\n",
    "        print(i)\n",
    "    \n",
    "print(time.time() - start)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile =  'data/hqDailyTemperatures.pkl'\n",
    "with open(outfile, 'wb') as pickle_file:\n",
    "    pickle.dump(tempsList, pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
