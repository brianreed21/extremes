{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import os\n",
    "import re\n",
    "\n",
    "import collections\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "import geopandas as gpd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import rasterio\n",
    "\n",
    "import spacy\n",
    "\n",
    "import gc\n",
    "\n",
    "\n",
    "\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Data\n",
    "\n",
    "## Changes from year to year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brianreed/opt/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3326: DtypeWarning: Columns (15) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gvkey</th>\n",
       "      <th>datadate</th>\n",
       "      <th>year</th>\n",
       "      <th>qtr</th>\n",
       "      <th>companyName</th>\n",
       "      <th>curcdq</th>\n",
       "      <th>assets</th>\n",
       "      <th>costGoodsSold</th>\n",
       "      <th>totalInv</th>\n",
       "      <th>netIncome</th>\n",
       "      <th>...</th>\n",
       "      <th>assetsLast</th>\n",
       "      <th>netIncomeLast</th>\n",
       "      <th>totalRevenueLast</th>\n",
       "      <th>costGoodsSoldLast</th>\n",
       "      <th>totalInvLast</th>\n",
       "      <th>incomeChange</th>\n",
       "      <th>revenueChange</th>\n",
       "      <th>costChange</th>\n",
       "      <th>inventoryChange</th>\n",
       "      <th>assetsPrev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1004</td>\n",
       "      <td>20010228</td>\n",
       "      <td>2000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>AAR CORP</td>\n",
       "      <td>USD</td>\n",
       "      <td>754.718</td>\n",
       "      <td>159.537</td>\n",
       "      <td>354.479</td>\n",
       "      <td>5.388</td>\n",
       "      <td>...</td>\n",
       "      <td>753.755</td>\n",
       "      <td>10.955</td>\n",
       "      <td>272.331</td>\n",
       "      <td>222.672</td>\n",
       "      <td>318.933</td>\n",
       "      <td>-0.508170</td>\n",
       "      <td>-0.265339</td>\n",
       "      <td>-0.283534</td>\n",
       "      <td>0.111453</td>\n",
       "      <td>753.755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1004</td>\n",
       "      <td>20010531</td>\n",
       "      <td>2000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>AAR CORP</td>\n",
       "      <td>USD</td>\n",
       "      <td>701.854</td>\n",
       "      <td>180.131</td>\n",
       "      <td>320.590</td>\n",
       "      <td>5.706</td>\n",
       "      <td>...</td>\n",
       "      <td>740.998</td>\n",
       "      <td>2.471</td>\n",
       "      <td>225.079</td>\n",
       "      <td>182.440</td>\n",
       "      <td>336.018</td>\n",
       "      <td>1.309187</td>\n",
       "      <td>-0.017772</td>\n",
       "      <td>-0.012656</td>\n",
       "      <td>-0.045914</td>\n",
       "      <td>740.998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1004</td>\n",
       "      <td>20010831</td>\n",
       "      <td>2001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAR CORP</td>\n",
       "      <td>USD</td>\n",
       "      <td>758.503</td>\n",
       "      <td>168.829</td>\n",
       "      <td>340.683</td>\n",
       "      <td>0.486</td>\n",
       "      <td>...</td>\n",
       "      <td>747.543</td>\n",
       "      <td>3.159</td>\n",
       "      <td>241.770</td>\n",
       "      <td>202.661</td>\n",
       "      <td>343.815</td>\n",
       "      <td>-0.846154</td>\n",
       "      <td>-0.160388</td>\n",
       "      <td>-0.166939</td>\n",
       "      <td>-0.009110</td>\n",
       "      <td>747.543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1004</td>\n",
       "      <td>20011130</td>\n",
       "      <td>2001</td>\n",
       "      <td>2.0</td>\n",
       "      <td>AAR CORP</td>\n",
       "      <td>USD</td>\n",
       "      <td>714.208</td>\n",
       "      <td>118.697</td>\n",
       "      <td>265.818</td>\n",
       "      <td>-54.484</td>\n",
       "      <td>...</td>\n",
       "      <td>772.941</td>\n",
       "      <td>4.278</td>\n",
       "      <td>211.335</td>\n",
       "      <td>171.482</td>\n",
       "      <td>344.778</td>\n",
       "      <td>-13.735858</td>\n",
       "      <td>-0.314411</td>\n",
       "      <td>-0.307817</td>\n",
       "      <td>-0.229017</td>\n",
       "      <td>772.941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1004</td>\n",
       "      <td>20020228</td>\n",
       "      <td>2001</td>\n",
       "      <td>3.0</td>\n",
       "      <td>AAR CORP</td>\n",
       "      <td>USD</td>\n",
       "      <td>690.681</td>\n",
       "      <td>118.267</td>\n",
       "      <td>271.342</td>\n",
       "      <td>-2.290</td>\n",
       "      <td>...</td>\n",
       "      <td>754.718</td>\n",
       "      <td>5.388</td>\n",
       "      <td>200.071</td>\n",
       "      <td>159.537</td>\n",
       "      <td>354.479</td>\n",
       "      <td>-1.425019</td>\n",
       "      <td>-0.282970</td>\n",
       "      <td>-0.258686</td>\n",
       "      <td>-0.234533</td>\n",
       "      <td>754.718</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   gvkey  datadate  year  qtr companyName curcdq   assets  costGoodsSold  \\\n",
       "0   1004  20010228  2000  3.0    AAR CORP    USD  754.718        159.537   \n",
       "1   1004  20010531  2000  4.0    AAR CORP    USD  701.854        180.131   \n",
       "2   1004  20010831  2001  1.0    AAR CORP    USD  758.503        168.829   \n",
       "3   1004  20011130  2001  2.0    AAR CORP    USD  714.208        118.697   \n",
       "4   1004  20020228  2001  3.0    AAR CORP    USD  690.681        118.267   \n",
       "\n",
       "   totalInv  netIncome  ...  assetsLast  netIncomeLast totalRevenueLast  \\\n",
       "0   354.479      5.388  ...     753.755         10.955          272.331   \n",
       "1   320.590      5.706  ...     740.998          2.471          225.079   \n",
       "2   340.683      0.486  ...     747.543          3.159          241.770   \n",
       "3   265.818    -54.484  ...     772.941          4.278          211.335   \n",
       "4   271.342     -2.290  ...     754.718          5.388          200.071   \n",
       "\n",
       "  costGoodsSoldLast totalInvLast incomeChange revenueChange  costChange  \\\n",
       "0           222.672      318.933    -0.508170     -0.265339   -0.283534   \n",
       "1           182.440      336.018     1.309187     -0.017772   -0.012656   \n",
       "2           202.661      343.815    -0.846154     -0.160388   -0.166939   \n",
       "3           171.482      344.778   -13.735858     -0.314411   -0.307817   \n",
       "4           159.537      354.479    -1.425019     -0.282970   -0.258686   \n",
       "\n",
       "  inventoryChange  assetsPrev  \n",
       "0        0.111453     753.755  \n",
       "1       -0.045914     740.998  \n",
       "2       -0.009110     747.543  \n",
       "3       -0.229017     772.941  \n",
       "4       -0.234533     754.718  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "changes = pd.read_csv(\"../../data/compustatChanges_all.csv\").drop(columns = ['Unnamed: 0'])\n",
    "\n",
    "changes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gvkey</th>\n",
       "      <th>qtr</th>\n",
       "      <th>assetsLagged</th>\n",
       "      <th>netIncomeLagged</th>\n",
       "      <th>roa_lagged</th>\n",
       "      <th>famafrench</th>\n",
       "      <th>year</th>\n",
       "      <th>earliestYear</th>\n",
       "      <th>ageTercile</th>\n",
       "      <th>sizeTercile</th>\n",
       "      <th>profitTercile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1010</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3422.936770</td>\n",
       "      <td>46.757990</td>\n",
       "      <td>0.013660</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1998</td>\n",
       "      <td>1962</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1010</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3454.132166</td>\n",
       "      <td>18.500640</td>\n",
       "      <td>0.005356</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1998</td>\n",
       "      <td>1962</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1010</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3487.709411</td>\n",
       "      <td>10.470317</td>\n",
       "      <td>0.003002</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1998</td>\n",
       "      <td>1962</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1010</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3448.667709</td>\n",
       "      <td>68.705992</td>\n",
       "      <td>0.019922</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1998</td>\n",
       "      <td>1962</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1010</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4322.135119</td>\n",
       "      <td>260.987674</td>\n",
       "      <td>0.060384</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1999</td>\n",
       "      <td>1962</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gvkey  qtr  assetsLagged  netIncomeLagged  roa_lagged  famafrench  year  \\\n",
       "0   1010  1.0   3422.936770        46.757990    0.013660        26.0  1998   \n",
       "1   1010  2.0   3454.132166        18.500640    0.005356        26.0  1998   \n",
       "2   1010  3.0   3487.709411        10.470317    0.003002        26.0  1998   \n",
       "3   1010  4.0   3448.667709        68.705992    0.019922        26.0  1998   \n",
       "4   1010  1.0   4322.135119       260.987674    0.060384        26.0  1999   \n",
       "\n",
       "   earliestYear  ageTercile  sizeTercile  profitTercile  \n",
       "0          1962           0          2.0            2.0  \n",
       "1          1962           0          2.0            1.0  \n",
       "2          1962           0          2.0            1.0  \n",
       "3          1962           0          2.0            2.0  \n",
       "4          1962           0          2.0            2.0  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "otherControls = pd.read_csv('../../data/companyData/otherControls.csv').\\\n",
    "    drop(columns = {'Unnamed: 0', 'fyearq'}).rename(columns = {'year_toMatchOn': 'year',\n",
    "                                                              'fqtr': 'qtr'})\n",
    "\n",
    "otherControls.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gvkey</th>\n",
       "      <th>qtr</th>\n",
       "      <th>assetsLagged</th>\n",
       "      <th>netIncomeLagged</th>\n",
       "      <th>roa_lagged</th>\n",
       "      <th>famafrench</th>\n",
       "      <th>year</th>\n",
       "      <th>earliestYear</th>\n",
       "      <th>ageTercile</th>\n",
       "      <th>sizeTercile</th>\n",
       "      <th>profitTercile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1010</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3422.936770</td>\n",
       "      <td>46.757990</td>\n",
       "      <td>0.013660</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1998</td>\n",
       "      <td>1962</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1010</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3454.132166</td>\n",
       "      <td>18.500640</td>\n",
       "      <td>0.005356</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1998</td>\n",
       "      <td>1962</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1010</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3487.709411</td>\n",
       "      <td>10.470317</td>\n",
       "      <td>0.003002</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1998</td>\n",
       "      <td>1962</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1010</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3448.667709</td>\n",
       "      <td>68.705992</td>\n",
       "      <td>0.019922</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1998</td>\n",
       "      <td>1962</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1010</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4322.135119</td>\n",
       "      <td>260.987674</td>\n",
       "      <td>0.060384</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1999</td>\n",
       "      <td>1962</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gvkey  qtr  assetsLagged  netIncomeLagged  roa_lagged  famafrench  year  \\\n",
       "0   1010  1.0   3422.936770        46.757990    0.013660        26.0  1998   \n",
       "1   1010  2.0   3454.132166        18.500640    0.005356        26.0  1998   \n",
       "2   1010  3.0   3487.709411        10.470317    0.003002        26.0  1998   \n",
       "3   1010  4.0   3448.667709        68.705992    0.019922        26.0  1998   \n",
       "4   1010  1.0   4322.135119       260.987674    0.060384        26.0  1999   \n",
       "\n",
       "   earliestYear  ageTercile  sizeTercile  profitTercile  \n",
       "0          1962           0          2.0            2.0  \n",
       "1          1962           0          2.0            1.0  \n",
       "2          1962           0          2.0            1.0  \n",
       "3          1962           0          2.0            2.0  \n",
       "4          1962           0          2.0            2.0  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "otherControls.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(890758, 29)\n",
      "(829560, 37)\n"
     ]
    }
   ],
   "source": [
    "print(changes.shape)\n",
    "changes = changes.merge(otherControls)\n",
    "print(changes.shape)\n",
    "\n",
    "\n",
    "industries = changes[['gvkey','famafrench']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "industries.to_csv(\"../../data/companyData/gvkeyIndustries.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''changes.to_csv(\"../../data/companyData/compustatChanges_withControls.csv\")\n",
    "changes.head()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "changes = pd.read_csv(\"../../data/companyData/compustatChanges_withControls.csv\").drop(columns = {'Unnamed: 0',\n",
    "                                                                                                 'Unnamed: 0.1',\n",
    "                                                                                                 'Unnamed: 0.1.1'})\n",
    "changes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put in the calendar quarters and fiscal quarter data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quarters = pd.read_csv(\"../../data/companyData/fiscalYears.csv\")\n",
    "quarters.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(quarters.gvkey.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum((quarters.fyr == 12) | \n",
    "   (quarters.fyr == 3) | \n",
    "   (quarters.fyr == 6) | \n",
    "   (quarters.fyr == 9))/quarters.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quarters = quarters[(quarters.fyr == 12) | \n",
    "   (quarters.fyr == 3) | \n",
    "   (quarters.fyr == 6) | \n",
    "   (quarters.fyr == 9)][['gvkey','datadate','datacqtr','datafqtr','fyr']].reset_index(drop = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quarters.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge the quarter data into the change data, and make sure that the quarters that are used line up with the calendar quarters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "changesCal = changes[changes.gvkey.isin(quarters.gvkey.unique())]\n",
    "\n",
    "changesCal = changesCal.merge(quarters)\n",
    "\n",
    "print(changesCal.shape[0]/changes.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "changesCal.loc[~(changesCal.datacqtr.isna()), 'year'] = changesCal.datacqtr.str.slice(0,4)\n",
    "changesCal.loc[~(changesCal.datacqtr.isna()), 'qtr']  = changesCal.datacqtr.str.slice(5,6)\n",
    "\n",
    "changesCal['DATE'] = pd.to_datetime(changesCal['datadate'])\n",
    "\n",
    "changesCal.loc[(changesCal.datacqtr.isna()), 'year'] = changesCal.DATE.dt.year\n",
    "changesCal.loc[(changesCal.datacqtr.isna()), 'qtr']  = changesCal.DATE.dt.quarter\n",
    "\n",
    "changesCal['year'] = changesCal.year.astype('int64')\n",
    "changesCal['qtr']  = changesCal.qtr.astype('int64')\n",
    "\n",
    "print(changesCal.shape,changesCal.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "changesCal.to_csv(\"../../data/companyData/compustatChanges_withControls.csv\")\n",
    "changesCal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "changesCal = pd.read_csv(\"../../data/companyData/compustatChanges_withControls.csv\")\n",
    "changesCal.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compustat and ABI Linking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gvKey_abiLinkingTable = pd.read_csv('../../data/companyData/linkingTable.csv').drop(columns = ['Unnamed: 0'])\n",
    "\n",
    "base_columns = gvKey_abiLinkingTable.columns \n",
    "customer_columns = \"customer_\" + base_columns\n",
    "supplier_columns = \"supplier_\" + base_columns\n",
    "\n",
    "\n",
    "\n",
    "hasMatch = gvKey_abiLinkingTable.gvkey.unique()\n",
    "\n",
    "gvKey_abiLinkingTable.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get all change data together\n",
    "Get the linking table and merge the abi labels into the change df. \n",
    "\n",
    "Then, merge the location data into the change data and get as complete a record of companies as possible given the HQ data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gvKey_abiLinkingTable = pd.read_csv('../../data/companyData/linkingTable.csv').drop(columns = ['Unnamed: 0'])\n",
    "\n",
    "changes = pd.read_csv(\"../../data/companyData/compustatChanges_withControls.csv\").drop(columns = ['Unnamed: 0'])\n",
    "print(changes.shape, changes.head())\n",
    "\n",
    "\n",
    "changesABI = changes.merge(gvKey_abiLinkingTable, on ='gvkey').drop(columns = {'state','city'})\n",
    "print(changesABI.shape, changesABI.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now merge in the hq information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "canadian = ['ON', 'AB','QC', 'BC', 'NS', 'NF', 'SK', 'MB', 'NB']\n",
    "changes = changes[~(changes.state.isin(canadian)) & ~changes.state.isna()]\n",
    "\n",
    "changes['addzip'] = changes.addzip.astype('str').str.slice(0,5)\n",
    "\n",
    "changes.state.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hq = pd.read_csv(\"../../data/ig_uniqueHQs_multLocations.csv\").\\\n",
    "    drop(columns = {'Unnamed: 0'}).\\\n",
    "    rename(columns = {'archive_version_year': 'year'})\n",
    "\n",
    "hq['year'] = hq.year.astype('int64')\n",
    "\n",
    "igChanges = changesABI.merge(hq)\n",
    "print(igChanges.shape, igChanges.head())\n",
    "\n",
    "\n",
    "hq.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "igChanges.to_csv(\"../../data/companyData/igData.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we have zip information in the following forms (from most to least examples):\n",
    "    - changes: all compustat companies, from the compustat address system\n",
    "    - igChanges: subset of compustat companies, from the ig merge\n",
    "    - subset of compustat companies that have SC information and survived the ig merge\n",
    "    \n",
    "We could potentially look at the subset of compustat companies for which we have SC information, usign the compustat address system as well.\n",
    "\n",
    "For now: follow similar trajectory as before but add in weather data for all cstat companies and all ig-merged companies.\n",
    "\n",
    "First: pull all zips that are mentioned in changes and igChanges and use this to get the weather data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "changes = changes[(~changes.addzip.isna()) & (changes.addzip != 'nan')]\n",
    "relevantZips = changes.addzip.astype('int64').append(igChanges.zipcode).unique()\n",
    "\n",
    "changes.rename(columns = {'addzip': 'zipcode'}, inplace = True)\n",
    "changes.drop(columns = {'cik',\n",
    "     'datadate','costat', 'add1', 'add2', 'city', 'sic', 'state'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(relevantZips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# relevantZips = allCustomerData.zipcode.append(allSupplierData.zipcode).unique()\n",
    "outfile =  '../../data/companyData/relevantZips.pkl'\n",
    "with open(outfile, 'wb') as pickle_file:\n",
    "    pkl.dump(relevantZips, pickle_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "igChanges = pd.read_csv(\"../../data/companyData/igData.csv\").\\\n",
    "    drop(columns = {'Unnamed: 0'})\n",
    "igChanges.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../data/stockReturns.pkl', 'rb') as f:\n",
    "    stocks = pkl.load(f)[['date','gvkey','RET']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stocks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(stocks.gvkey.isna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks = stocks[stocks.date.dt.year > 2008]\n",
    "\n",
    "stocks['qtr']  = stocks.date.dt.quarter\n",
    "stocks['year'] = stocks.date.dt.year\n",
    "\n",
    "stocks = stocks[~stocks.gvkey.isna()]\n",
    "stocks['gvkey'] = stocks['gvkey'].astype(int)\n",
    "stocks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "igChanges.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "companyControls = igChanges[['gvkey','year','qtr','famafrench','ageTercile','sizeTercile','profitTercile','zipcode']]\n",
    "companyControls.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stocks.dtypes, companyControls.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocksWithControls = stocks.merge(companyControls)\n",
    "print(stocksWithControls.shape,stocks.shape,companyControls.shape)\n",
    "stocksWithControls.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del stocks\n",
    "del companyControls\n",
    "del igChanges\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annualWeather = pd.read_csv(\"../../data/companyData/stockWeather_annual.csv\").\\\n",
    "    drop(columns = {'Unnamed: 0'})\n",
    "\n",
    "annualWeather = annualWeather[~annualWeather.temp_annualLast5.isna()].reset_index(drop = True)\n",
    "\n",
    "annualWeather['date'] = pd.to_datetime(annualWeather['date'],\n",
    "                                   format = \"%Y%m%d\")\n",
    "\n",
    "annualWeather.rename(columns = {'ZIP': 'zipcode'}, inplace = True)\n",
    "print(annualWeather.dtypes)\n",
    "annualWeather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "allWeather = pd.read_csv(\"../../data/companyData/stockWeather_zipQuarterQuants.csv\").\\\n",
    "    drop(columns = {'Unnamed: 0'})\n",
    "\n",
    "allWeather = allWeather[~allWeather.temp_zipQuarterLast5.isna()].reset_index(drop = True)\n",
    "\n",
    "allWeather['date'] = pd.to_datetime(allWeather['date'],\n",
    "                                   format = \"%Y-%m-%d\")\n",
    "\n",
    "allWeather.rename(columns = {'ZIP': 'zipcode'}, inplace = True)\n",
    "print(allWeather.dtypes)\n",
    "allWeather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocksWithControlsWeather = stocksWithControls.merge(allWeather).merge(annualWeather)\n",
    "print(stocksWithControlsWeather.shape,allWeather.shape)\n",
    "\n",
    "stocksWithControlsWeather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocksWithControlsWeather.to_csv(\"../../data/2+32+100+600sfgcompanyData/stocksWithControlsWeather.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(stocksWithControlsWeather.RET.isna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocksWithControlsWeather = pd.read_csv(\"../../data/companyData/stocksWithControlsWeather.csv\").drop(columns = {'Unnamed: 0'})\n",
    "stocksWithControlsWeather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(stocksWithControlsWeather.gvkey.isna())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weather Data\n",
    "First do this on the HQ zipcodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allWeather = pd.read_csv(\"../../data/companyData/revised_allWeatherBins_2009to2019.csv\").\\\n",
    "    drop(columns = {\"Unnamed: 0\"})\n",
    "\n",
    "allWeather['yearQtr'] = allWeather.year + (allWeather.qtr - 1)/4\n",
    "\n",
    "col = allWeather.pop(\"yearQtr\")\n",
    "allWeather.insert(0, col.name, col)\n",
    "\n",
    "lag1 = allWeather.copy()\n",
    "lag1['yearQtr'] += 0.25\n",
    "for colname in lag1.columns[4:]:\n",
    "    lag1.rename(columns = {colname: 'lag1_' + colname}, inplace = True)\n",
    "lag1.drop(columns = {'year','qtr'},inplace = True)\n",
    "\n",
    "    \n",
    "lag2 = allWeather.copy()\n",
    "lag2['yearQtr'] += 0.5\n",
    "for colname in lag2.columns[4:]:\n",
    "    lag2.rename(columns = {colname: 'lag2_' + colname}, inplace = True)\n",
    "lag2.drop(columns = {'year','qtr'},inplace = True)\n",
    "\n",
    "\n",
    "lag3 = allWeather.copy()\n",
    "lag3['yearQtr'] += 0.75\n",
    "for colname in lag3.columns[4:]:\n",
    "    lag3.rename(columns = {colname: 'lag3_' + colname}, inplace = True)\n",
    "lag3.drop(columns = {'year','qtr'},inplace = True)\n",
    "\n",
    "\n",
    "lag4 = allWeather.copy()\n",
    "lag4['yearQtr'] += 1\n",
    "for colname in lag4.columns[4:]:\n",
    "    lag4.rename(columns = {colname: 'lag4_' + colname}, inplace = True)\n",
    "lag4.drop(columns = {'year','qtr'},inplace = True)\n",
    "\n",
    "\n",
    "print(allWeather.shape)\n",
    "\n",
    "allWeather_withLags = allWeather.merge(lag1).merge(lag2).merge(lag3).merge(lag4)\n",
    "\n",
    "print(allWeather_withLags.year.value_counts())\n",
    "\n",
    "allWeather_withLags.to_csv(\"../../data/companyData/allWeather_withLags.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do this across all zips, for the establishment records. We'll put this into a different format right after, and then change the columns and whatnot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allWeather = pd.read_csv(\"../../data/companyData/revised_allWeatherBins_2009to2019_allZips.csv\").\\\n",
    "    drop(columns = {\"Unnamed: 0\", 'Unnamed: 0.1'})\n",
    "\n",
    "allWeather['yearQtr'] = allWeather.year + (allWeather.qtr - 1)/4\n",
    "\n",
    "col = allWeather.pop(\"yearQtr\")\n",
    "allWeather.insert(0, col.name, col)\n",
    "\n",
    "lag1 = allWeather.copy()\n",
    "lag1['yearQtr'] += 0.25\n",
    "for colname in lag1.columns[4:]:\n",
    "    lag1.rename(columns = {colname: 'lag1_' + colname}, inplace = True)\n",
    "lag1.drop(columns = {'year','qtr'},inplace = True)\n",
    "\n",
    "    \n",
    "lag2 = allWeather.copy()\n",
    "lag2['yearQtr'] += 0.5\n",
    "for colname in lag2.columns[4:]:\n",
    "    lag2.rename(columns = {colname: 'lag2_' + colname}, inplace = True)\n",
    "lag2.drop(columns = {'year','qtr'},inplace = True)\n",
    "\n",
    "\n",
    "lag3 = allWeather.copy()\n",
    "lag3['yearQtr'] += 0.75\n",
    "for colname in lag3.columns[4:]:\n",
    "    lag3.rename(columns = {colname: 'lag3_' + colname}, inplace = True)\n",
    "lag3.drop(columns = {'year','qtr'},inplace = True)\n",
    "\n",
    "\n",
    "lag4 = allWeather.copy()\n",
    "lag4['yearQtr'] += 1\n",
    "for colname in lag4.columns[4:]:\n",
    "    lag4.rename(columns = {colname: 'lag4_' + colname}, inplace = True)\n",
    "lag4.drop(columns = {'year','qtr'},inplace = True)\n",
    "\n",
    "\n",
    "print(allWeather.shape)\n",
    "\n",
    "allWeather_withLags = allWeather.merge(lag1).merge(lag2).merge(lag3).merge(lag4)\n",
    "\n",
    "print(allWeather_withLags.year.value_counts())\n",
    "\n",
    "allWeather_withLags.to_csv(\"../../data/companyData/allWeather_withLags_allZips.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now do the same for the industry-specific weather."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allWeather = pd.read_csv(\"../../../../../../../Volumes/backup2/dissData/prism/allWeatherBins_2010.2019.csv\").\\\n",
    "allWeather_byInd = pd.read_csv(\"../../data/companyData/revised_allWeatherBins_2009to2019_byInd.csv\").\\\n",
    "    drop(columns = {\"Unnamed: 0\"})\n",
    "'''[['famafrench','zipcode','yearQuarter', \n",
    "                                    'temp_ffquant_0.95','temp_indQuarterquant_0.95',\n",
    "                                   'temp5Days_ffquant_0.95', 'temp5Days_indQuarterquant_0.95',\n",
    "                                   'precip_ffquant_0.95', 'precip_indQuarterquant_0.95',\n",
    "                                   'precip5Days_ffquant_0.95', 'precip5Days_indQuarterquant_0.95']]\n",
    "'''\n",
    "allWeather_byInd['year'] = allWeather_byInd.yearQuarter.str.slice(0,4).astype('int64')\n",
    "allWeather_byInd['qtr']  = allWeather_byInd.yearQuarter.str.slice(5,6).astype('int64')\n",
    "allWeather_byInd['yearQtr'] = allWeather_byInd.year + (allWeather_byInd.qtr - 1)/4\n",
    "\n",
    "allWeather_byInd = allWeather_byInd.astype({'year':       'category',\n",
    "                         'qtr':        'category',\n",
    "                         'zipcode':    'category',\n",
    "                         'famafrench': 'category'})\n",
    "\n",
    "changes['zipcode'] = changes['zipcode'].astype({'zipcode': 'int64'})\n",
    "\n",
    "changes = changes.astype({'year':       'category',\n",
    "                          'qtr':        'category',\n",
    "                          'zipcode':    'category',\n",
    "                          'famafrench': 'category'})\n",
    "\n",
    "col = allWeather_byInd.pop(\"year\")\n",
    "allWeather_byInd.insert(0, col.name, col)\n",
    "\n",
    "col = allWeather_byInd.pop(\"qtr\")\n",
    "allWeather_byInd.insert(0, col.name, col)\n",
    "\n",
    "\n",
    "col = allWeather_byInd.pop(\"yearQtr\")\n",
    "allWeather_byInd.insert(0, col.name, col)\n",
    "\n",
    "allWeather_byInd.drop(columns = {'yearQuarter'}, inplace = True)\n",
    "\n",
    "print(allWeather_byInd.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lag1 = allWeather_byInd.copy()\n",
    "lag1['yearQtr'] += 0.25\n",
    "for colname in lag1.columns[5:]:\n",
    "    lag1.rename(columns = {colname: 'lag1_' + colname}, inplace = True)\n",
    "lag1.drop(columns = {'year','qtr'},inplace = True)\n",
    "lag1 = lag1.astype({'yearQtr':       'category'})\n",
    "\n",
    "    \n",
    "lag2 = allWeather_byInd.copy()\n",
    "lag2['yearQtr'] += 0.5\n",
    "for colname in lag2.columns[5:]:\n",
    "    lag2.rename(columns = {colname: 'lag2_' + colname}, inplace = True)\n",
    "lag2.drop(columns = {'year','qtr'},inplace = True)\n",
    "lag2 = lag2.astype({'yearQtr':       'category'})\n",
    "\n",
    "\n",
    "lag3 = allWeather_byInd.copy()\n",
    "lag3['yearQtr'] += 0.75\n",
    "for colname in lag3.columns[5:]:\n",
    "    lag3.rename(columns = {colname: 'lag3_' + colname}, inplace = True)\n",
    "lag3.drop(columns = {'year','qtr'},inplace = True)\n",
    "lag3 = lag3.astype({'yearQtr':       'category'})\n",
    "\n",
    "\n",
    "lag4 = allWeather_byInd.copy()\n",
    "lag4['yearQtr'] += 1\n",
    "for colname in lag4.columns[5:]:\n",
    "    lag4.rename(columns = {colname: 'lag4_' + colname}, inplace = True)\n",
    "lag4.drop(columns = {'year','qtr'},inplace = True)\n",
    "lag4 = lag4.astype({'yearQtr':       'category'})\n",
    "\n",
    "\n",
    "allWeather_byInd = allWeather_byInd.astype({'yearQtr':       'category'})\n",
    "\n",
    "\n",
    "print(allWeather_byInd.shape)\n",
    "\n",
    "\n",
    "allWeather_byInd.head()\n",
    "\n",
    "\n",
    "'''allWeather_byInd_withLags = allWeather_byInd.merge(lag1).merge(lag2).merge(lag3).merge(lag4)\n",
    "\n",
    "allWeather_byInd_withLags.year.value_counts()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allWeather_byInd_withLags = allWeather_byInd.merge(lag1).merge(lag2).merge(lag3).merge(lag4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allWeather_byInd_withLags.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allWeather_byInd_withLags.to_csv(\"../../data/companyData/allWeather_byInd_withLags.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del allWeather_byInd\n",
    "del lag1\n",
    "del lag2\n",
    "del lag3\n",
    "del lag4\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allWeather_byInd_withLags = pd.read_csv(\"../../data/companyData/allWeather_byInd_withLags.csv\")\n",
    "allWeather_byInd_withLags.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Locations\n",
    "Create a separate definition of weather based not on HQ but on employee-weighted establishment footprint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fractions = pd.read_csv('../../data/companyData/fractionEmployees_byEstablishment.csv').\\\n",
    "    drop(columns = {\"Unnamed: 0\", 'latitude','longitude'}).rename(columns = {'archive_version_year': 'year',\n",
    "                                                    'parent_number': 'abi'})\n",
    "\n",
    "fractions['year']    = fractions.year.astype('int64')\n",
    "fractions['zipcode'] = fractions.zipcode.astype('int64')\n",
    "fractions.head()\n",
    "\n",
    "gvKey_abiLinkingTable = pd.read_csv('../../data/companyData/linkingTable.csv').drop(columns = ['Unnamed: 0'])\n",
    "\n",
    "print(gvKey_abiLinkingTable.abi)\n",
    "\n",
    "gvKey_abiLinkingTable.head()\n",
    "\n",
    "fractions = fractions[['year','abi','zipcode','locationFracOfEmployees']].merge(gvKey_abiLinkingTable[['abi','gvkey']])\n",
    "\n",
    "fractions = fractions.astype({'year':       'category',\n",
    "                           'zipcode':    'category'})\n",
    "\n",
    "fractions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fractionsWithWeather = fractions.merge(allWeather_withLags_allZips) \n",
    "fractionsWithWeather.drop(columns = {'abi','zipcode'}, inplace = True)\n",
    "\n",
    "print(fractionsWithWeather.shape)\n",
    "fractionsWithWeather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fractionsWithWeather[fractionsWithWeather.gvkey == 1004]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del allWeather_withLags\n",
    "del fractions\n",
    "del gvKey_abiLinkingTable\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in fractionsWithWeather.columns[4:]:\n",
    "    fractionsWithWeather[col] = fractionsWithWeather[col] * fractionsWithWeather.locationFracOfEmployees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = fractionsWithWeather.groupby(['gvkey','year','qtr']).sum().reset_index()\n",
    "g.drop(columns = {'locationFracOfEmployees'}, inplace = True)\n",
    "\n",
    "for colname in g.columns[3:]:\n",
    "    g.rename(columns = {colname: 'empWt_' + colname}, inplace = True)\n",
    "\n",
    "g.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.to_csv(\"../../data/companyData/weatherByEstablishment.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "establishmentZips = fractions.zipcode.unique()\n",
    "len(establishmentZips)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create the original weather with lags dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allWeather_withLags = pd.read_csv(\"../../data/companyData/allWeather_withLags.csv\").\\\n",
    "    drop(columns = {\"Unnamed: 0\", 'yearQtr'})\n",
    "\n",
    "averages = pd.read_csv(\"../../data/companyData/quarterlyStatsByZip.csv\").\\\n",
    "    drop(columns = {\"Unnamed: 0\"}).rename(columns = {'ZIP': 'zipcode'})\n",
    "\n",
    "\n",
    "averages['qtr'] = averages.quarter.str.slice(1,2).astype('float')\n",
    "averages.drop(columns = {'quarter'}, inplace = True) \n",
    "\n",
    "print(len(averages.zipcode.unique()))\n",
    "\n",
    "averages.head()\n",
    "\n",
    "allWeather_withLags       = allWeather_withLags.astype({'year':       'category',\n",
    "                           'qtr':        'category',\n",
    "                           'zipcode':    'category'})\n",
    "averages                  = averages.astype({'qtr':        'category',\n",
    "                           'zipcode':    'category'})\n",
    "\n",
    "allWeather_byInd_withLags = pd.read_csv(\"../../data/companyData/allWeather_byInd_withLags.csv\").\\\n",
    "    drop(columns = {\"Unnamed: 0\", 'yearQtr'})\n",
    "allWeather_byInd_withLags = allWeather_byInd_withLags.astype({'year':       'category',\n",
    "                           'qtr':        'category',\n",
    "                           'zipcode':    'category'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create direct effects database. Merge weather to full cstat database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allWeather_withLags.zipcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "changes.zipcode = changes.zipcode.astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changes['zipcode']  = changes['zipcode'].astype('int64')\n",
    "changesWithWeather = changes.merge(allWeather_withLags).merge(allWeather_byInd_withLags).merge(averages).merge(g)\n",
    "print(changes.shape,changesWithWeather.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "changesWithWeather.to_csv(\"../../data/companyData/cstatWithWeather.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge weather to the ig-cstat database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "igChangesWithWeather = igChanges.merge(allWeather_withLags).merge(allWeather_byInd_withLags).merge(averages).merge(g)\n",
    "igChangesWithWeather.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "igChangesWithWeather.to_csv(\"../../data/companyData/igWithWeather.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "igChangesWithWeather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "igChangesWithWeather['temp_zipquant_0.95'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "igChangesWithWeather['temp5Days_ffquant_0.95'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indirect\n",
    "Introduce the SC Data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this does a little bit of a test on the reporting requirements. \n",
    "# number \n",
    "\n",
    "'''c_linksTest = pd.read_csv(\"../../data/companyData/compustatSCLinked.csv\")[['srcdate','gvkey','cgvkey']]\n",
    "c_linksTest['year'] = c_linksTest.srcdate.astype('str').str.slice(0,4).astype('int64')\n",
    "\n",
    "bs = c_linksTest[c_linksTest.year < 2014]\n",
    "print(\"Customers per supplier, 1978-2013 Pd: \", len(bs.cgvkey.unique())/len(bs.gvkey.unique()))\n",
    "\n",
    "bs2 = c_linksTest[c_linksTest.year > 2010]\n",
    "print(\"Customers per supplier, Recent Pd: \", len(bs2.cgvkey.unique())/len(bs2.gvkey.unique()))'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>supplier_gvkey</th>\n",
       "      <th>customer_gvkey</th>\n",
       "      <th>salecs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>2002-01-01</td>\n",
       "      <td>1013</td>\n",
       "      <td>2136</td>\n",
       "      <td>111.056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>2004-01-01</td>\n",
       "      <td>1013</td>\n",
       "      <td>2136</td>\n",
       "      <td>104.312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>2005-01-01</td>\n",
       "      <td>1013</td>\n",
       "      <td>2136</td>\n",
       "      <td>146.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>2006-01-01</td>\n",
       "      <td>1013</td>\n",
       "      <td>2136</td>\n",
       "      <td>205.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>2007-01-01</td>\n",
       "      <td>1013</td>\n",
       "      <td>2136</td>\n",
       "      <td>236.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         year  supplier_gvkey  customer_gvkey   salecs\n",
       "70 2002-01-01            1013            2136  111.056\n",
       "71 2004-01-01            1013            2136  104.312\n",
       "72 2005-01-01            1013            2136  146.000\n",
       "73 2006-01-01            1013            2136  205.000\n",
       "74 2007-01-01            1013            2136  236.000"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_links = pd.read_csv(\"../../data/companyData/compustatSCLinked.csv\") # pd.read_csv(\"../../data/companyData/compustatSCLinked.csv\")\n",
    "\n",
    "c_links['year'] = c_links.srcdate.astype('str').str.slice(0,4).astype('int64')\n",
    "\n",
    "c_links = c_links[c_links.year > 1999][['year','gvkey','cgvkey','salecs']].\\\n",
    "    rename(columns = {'cgvkey': 'customer_gvkey','gvkey': 'supplier_gvkey'})\n",
    "\n",
    "c_links['year'] = pd.to_datetime(c_links.year, format = '%Y')\n",
    "\n",
    "\n",
    "c_links.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16812, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>supplier_gvkey</th>\n",
       "      <th>customer_gvkey</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1013</td>\n",
       "      <td>2136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1013</td>\n",
       "      <td>9899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1021</td>\n",
       "      <td>61494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1021</td>\n",
       "      <td>25880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1048</td>\n",
       "      <td>11552</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   supplier_gvkey  customer_gvkey\n",
       "0            1013            2136\n",
       "1            1013            9899\n",
       "2            1021           61494\n",
       "3            1021           25880\n",
       "4            1048           11552"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "supplierCombos = c_links[['supplier_gvkey', 'customer_gvkey']].drop_duplicates().reset_index(drop = True)\n",
    "\n",
    "print(supplierCombos.shape)\n",
    "\n",
    "supplierCombos.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll follow Barrot Sauvagnat in assuming that a supplier relationship holds for every year between the first and last year in which a customer is reported. This is going to take a little bit of work. We'll try it like this: \n",
    "- subset dataframe to a specific supplier-customer pair\n",
    "- fill in data for every year that's missing\n",
    "\n",
    "Then, apply this row-wise to all rows of the unique supplierCombos df above using: https://stackoverflow.com/questions/61942138/apply-function-row-wise-to-pandas-dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillYear(supplier, customer, scData = c_links):\n",
    "    c_linksTemp = scData[(scData.supplier_gvkey == supplier) & \\\n",
    "                      (scData.customer_gvkey == customer)].reset_index(drop = True)\n",
    "    \n",
    "    # if there are na values and non-na values for the same supplier-cust combination, then \n",
    "    # select for only the non-na values, by (1) replacing na with negative, (2) 1\n",
    "    c_linksTemp['salecs'] = c_linksTemp['salecs'].fillna(-5)\n",
    "    c_linksTemp = c_linksTemp.loc[c_linksTemp.reset_index().groupby(['year','supplier_gvkey', 'customer_gvkey'])['salecs'].idxmax()]\n",
    "\n",
    "    \n",
    "    # now: find the start and end of the data series\n",
    "    first = c_linksTemp.year.min()\n",
    "    last  = c_linksTemp.year.max()\n",
    "\n",
    "    c_linksTemp = c_linksTemp.set_index('year') \n",
    "\n",
    "    c_linksTemp = c_linksTemp.reindex(pd.date_range(first, last, freq = 'YS')).\\\n",
    "        reset_index().rename(columns = {'index': 'year'})\n",
    "\n",
    "    # and impute all values within the series\n",
    "    c_linksTemp = c_linksTemp.groupby(c_linksTemp.year.dt.time).ffill()\n",
    "    \n",
    "    return(c_linksTemp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>supplier_gvkey</th>\n",
       "      <th>customer_gvkey</th>\n",
       "      <th>salecs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2002-01-01</td>\n",
       "      <td>1013.0</td>\n",
       "      <td>2136.0</td>\n",
       "      <td>111.056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2003-01-01</td>\n",
       "      <td>1013.0</td>\n",
       "      <td>2136.0</td>\n",
       "      <td>111.056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2004-01-01</td>\n",
       "      <td>1013.0</td>\n",
       "      <td>2136.0</td>\n",
       "      <td>104.312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2005-01-01</td>\n",
       "      <td>1013.0</td>\n",
       "      <td>2136.0</td>\n",
       "      <td>146.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2006-01-01</td>\n",
       "      <td>1013.0</td>\n",
       "      <td>2136.0</td>\n",
       "      <td>205.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2007-01-01</td>\n",
       "      <td>1013.0</td>\n",
       "      <td>2136.0</td>\n",
       "      <td>236.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2008-01-01</td>\n",
       "      <td>1013.0</td>\n",
       "      <td>2136.0</td>\n",
       "      <td>240.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2009-01-01</td>\n",
       "      <td>1013.0</td>\n",
       "      <td>2136.0</td>\n",
       "      <td>176.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>1013.0</td>\n",
       "      <td>2136.0</td>\n",
       "      <td>146.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        year  supplier_gvkey  customer_gvkey   salecs\n",
       "0 2002-01-01          1013.0          2136.0  111.056\n",
       "1 2003-01-01          1013.0          2136.0  111.056\n",
       "2 2004-01-01          1013.0          2136.0  104.312\n",
       "3 2005-01-01          1013.0          2136.0  146.000\n",
       "4 2006-01-01          1013.0          2136.0  205.000\n",
       "5 2007-01-01          1013.0          2136.0  236.000\n",
       "6 2008-01-01          1013.0          2136.0  240.000\n",
       "7 2009-01-01          1013.0          2136.0  176.000\n",
       "8 2010-01-01          1013.0          2136.0  146.000"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fillYear(supplierCombos.supplier_gvkey[0], supplierCombos.customer_gvkey[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(65270, 4)\n",
      "(68771, 4)\n",
      "72.3937520980835\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(c_links.shape)\n",
    "c_linksImpd_list = supplierCombos.apply(lambda row: fillYear(row['supplier_gvkey'], row['customer_gvkey']), axis = 1)\n",
    "c_linksImpd_df   = pd.concat(list(c_linksImpd_list))\n",
    "print(c_linksImpd_df.shape)\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_linksImpd_df['year'] = c_linksImpd_df.year.dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        gvkey  famafrench\n",
      "0        1004        42.0\n",
      "1        1010        26.0\n",
      "2        1013        37.0\n",
      "3        1019        35.0\n",
      "4        1021        12.0\n",
      "...       ...         ...\n",
      "25237  345920        21.0\n",
      "25238  345980        44.0\n",
      "25239  347085        35.0\n",
      "25240  351491        24.0\n",
      "25241  351590        24.0\n",
      "\n",
      "[25242 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "industries = pd.read_csv(\"../../data/companyData/gvkeyIndustries.csv\").drop(columns = {'Unnamed: 0'})\n",
    "print(industries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(68771, 4)\n",
      "   year  supplier_gvkey  customer_gvkey   salecs\n",
      "0  2002          1013.0          2136.0  111.056\n",
      "1  2003          1013.0          2136.0  111.056\n",
      "2  2004          1013.0          2136.0  104.312\n",
      "3  2005          1013.0          2136.0  146.000\n",
      "4  2006          1013.0          2136.0  205.000\n",
      "   year  supplier_gvkey  customer_gvkey   salecs  customer_famafrench  \\\n",
      "0  2002          1013.0          2136.0  111.056                 33.0   \n",
      "1  2003          1013.0          2136.0  111.056                 33.0   \n",
      "2  2004          1013.0          2136.0  104.312                 33.0   \n",
      "3  2005          1013.0          2136.0  146.000                 33.0   \n",
      "4  2006          1013.0          2136.0  205.000                 33.0   \n",
      "\n",
      "   supplier_famafrench  \n",
      "0                 37.0  \n",
      "1                 37.0  \n",
      "2                 37.0  \n",
      "3                 37.0  \n",
      "4                 37.0   (66561, 6)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'hasMatch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-133-b2ea2a8c424d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_links\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupplier_gvkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhasMatch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mc_links\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcustomer_gvkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhasMatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'hasMatch' is not defined"
     ]
    }
   ],
   "source": [
    "c_links = c_linksImpd_df.copy()\n",
    "\n",
    "print(c_links.shape)\n",
    "\n",
    "print(c_links.head())\n",
    "\n",
    "industries.columns = ['customer_gvkey','customer_famafrench']\n",
    "\n",
    "c_links = c_links.merge(industries)\n",
    "\n",
    "industries.columns = ['supplier_gvkey','supplier_famafrench']\n",
    "\n",
    "c_links = c_links.merge(industries)\n",
    "print(c_links.head(), c_links.shape)\n",
    "\n",
    "\n",
    "c_links.to_csv(\"../../data/companyData/c_links.csv\")\n",
    "\n",
    "\n",
    "# sum(c_links.supplier_gvkey.isin(hasMatch) | c_links.customer_gvkey.isin(hasMatch))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now see if it's common to have one in and one out of the industries of interest. \n",
    "\n",
    "For now, let's keep all the different industry types.\n",
    "\n",
    "We can always filter later if we need to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################\n",
    "# merge in customer information\n",
    "gvKey_abiLinkingTable.columns = customer_columns\n",
    "\n",
    "print(c_links.shape)\n",
    "c_linksMerge1 = c_links.merge(gvKey_abiLinkingTable, on ='customer_gvkey')\n",
    "print(c_links.shape,c_linksMerge1.shape)\n",
    "\n",
    "\n",
    "\n",
    "#########################\n",
    "# and merge in supplier \n",
    "gvKey_abiLinkingTable.columns = supplier_columns\n",
    "\n",
    "print(c_links.shape)\n",
    "c_linksMerge2 = c_linksMerge1.merge(gvKey_abiLinkingTable, on ='supplier_gvkey')\n",
    "print(c_links.shape,c_linksMerge2.shape)\n",
    "\n",
    "c_linksMerge2.to_csv(\"../../data/companyData/clinks_IG_selected.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is probably because: (1) companies are not in North America, or (2) companies are not in the physical goods industries we're interested in. We can verify this though: look at c_links where both the customer and supplier are in the dataset of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chq     = pd.read_csv(\"../../data/chq.csv\",dtype={'cstatZipcode': 'object'}).drop(columns = {'Unnamed: 0'})\n",
    "\n",
    "c_linkTest = c_links[c_links.customer_gvkey.isin(chq.gvkey.unique()) & \\\n",
    "                     c_links.supplier_gvkey.isin(chq.gvkey.unique())]\n",
    "\n",
    "print(\"Percent of firms with a match: \", c_linksMerge2.shape[0]/c_linkTest.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's entirely possible that we have too small of a sample from the 2010s alone. Let's just try it though and see how it goes.\n",
    "\n",
    "First, make a sample with the companies on three years of either side of when it reports another customer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeOneEitherSide(df): \n",
    "    yrPlus1 = df.copy(); yrPlus1['year'] += 1\n",
    "    # yrPlus2 = df.copy(); yrPlus2['year'] += 1\n",
    "    # yrPlus3 = df.copy(); yrPlus3['year'] += 1\n",
    "    \n",
    "    yrMinus1 = df.copy(); yrMinus1['year'] -= 1\n",
    "    # yrMinus2 = df.copy(); yrMinus2['year'] -= 1\n",
    "    # yrMinus3 = df.copy(); yrMinus3['year'] -= 1\n",
    "    \n",
    "    all = pd.concat([yrPlus1,yrMinus1]) # pd.concat([yrPlus1,yrPlus2,yrPlus3,yrMinus1,yrMinus2,yrMinus3])\n",
    "    \n",
    "    return(all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scTableCustomers = c_linksMerge2.copy()[['year','customer_gvkey','customer_abi']].drop_duplicates()\n",
    "scTableSuppliers = c_linksMerge2.copy()[['year','supplier_gvkey','supplier_abi']].drop_duplicates()\n",
    "\n",
    "allCustomerData = makeOneEitherSide(scTableCustomers)\n",
    "allCustomerData.columns = ['year','gvkey','abi']\n",
    "\n",
    "\n",
    "allSupplierData = makeOneEitherSide(scTableSuppliers)\n",
    "allSupplierData.columns = ['year','gvkey','abi']\n",
    "\n",
    "allAbi = allCustomerData.abi.append(allSupplierData.abi).drop_duplicates()\n",
    "\n",
    "hqsOnly = pd.read_csv(\"../../data/ig_uniqueHQs.csv\").drop(columns = {'Unnamed: 0'})\n",
    "\n",
    "hq = pd.read_csv(\"../../data/ig_uniqueHQs_multLocations.csv\").\\\n",
    "    drop(columns = {'Unnamed: 0'}).\\\n",
    "    rename(columns = {'archive_version_year': 'year'})\n",
    "\n",
    "hq['year'] = hq.year.astype('int64')\n",
    "\n",
    "hqRelevant = hq[hq.abi.isin(allAbi)]\n",
    "\n",
    "\n",
    "allSupplierData = allSupplierData.merge(hqRelevant).drop_duplicates()\n",
    "allCustomerData = allCustomerData.merge(hqRelevant).drop_duplicates()\n",
    "\n",
    "print(allSupplierData.head())\n",
    "\n",
    "allCustomerData.to_csv(\"../../data/companyData/allCustomerData.csv\")\n",
    "allSupplierData.to_csv(\"../../data/companyData/allSupplierData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Customer and Supplier pairings and merge with change data\n",
    "### Can pick up here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allSupplierData = pd.read_csv(\"../../data/companyData/allSupplierData.csv\").drop(columns = ['Unnamed: 0'])\n",
    "allCustomerData = pd.read_csv(\"../../data/companyData/allCustomerData.csv\").drop(columns = ['Unnamed: 0'])\n",
    "\n",
    "changes = pd.read_csv(\"../../data/companyData/compustatChanges_withControls.csv\").drop(columns = ['Unnamed: 0'])\n",
    "changes.head()\n",
    "suppliers = changes.merge(allSupplierData[['year','gvkey','zipcode','employeesAtLocation']])\n",
    "print(suppliers.shape)\n",
    "\n",
    "customers = changes.merge(allCustomerData[['year','gvkey','zipcode','employeesAtLocation']])\n",
    "print(customers.head())\n",
    "\n",
    "print(allCustomerData.shape,allSupplierData.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get first-hop SC data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_links = pd.read_csv(\"../../data/companyData/clinks_IG_selected.csv\").drop(columns = {'Unnamed: 0'})\n",
    "c_links.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_links['suppliers'] = 1\n",
    "custExp = c_links[['year', 'customer_gvkey', 'salecs','suppliers']].groupby(['year','customer_gvkey']).sum().\\\n",
    "    reset_index().rename(columns = {'salecs': 'totalExp'})\n",
    "\n",
    "custExp.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of firms with no exp information and multiple suppliers: \", \\\n",
    "          sum(custExp[custExp.totalExp == 0].suppliers > 1))\n",
    "print(\"Number of firms with no exp information and >5 suppliers: \", \\\n",
    "          sum(custExp[custExp.totalExp == 0].suppliers > 5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of these firms have expenditure information. We can look at:\n",
    "    - Expenditure-weighted (just do equal shares if no exp information)\n",
    "    - Largest supplier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customerDB = c_links[['year','customer_gvkey','supplier_gvkey','salecs']].\\\n",
    "    merge(custExp).rename(columns = {'customer_gvkey': 'gvkey'}).drop_duplicates()\n",
    "print(customerDB.shape)\n",
    "\n",
    "customerDB.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customersWithWeather = customers.merge(allWeather_withLags).merge(averages).merge(allWeather_byInd_withLags)\n",
    "customersWithWeather.shape\n",
    "\n",
    "suppliersWithWeather = suppliers.merge(allWeather_withLags).merge(averages).merge(allWeather_byInd_withLags)\n",
    "suppliersWithWeather.shape\n",
    "\n",
    "suppliersWithWeather.to_csv(\"../../data/companyData/suppliersWithWeather.csv\")\n",
    "customersWithWeather.to_csv(\"../../data/companyData/customersWithWeather.csv\")\n",
    "\n",
    "'''suppliersWithWeather = pd.read_csv(\"../../data/companyData/suppliersWithWeather.csv\").drop(columns = {'Unnamed: 0'})\n",
    "customersWithWeather = pd.read_csv(\"../../data/companyData/customersWithWeather.csv\").drop(columns = {'Unnamed: 0'})'''\n",
    "\n",
    "frames = [customersWithWeather, suppliersWithWeather]\n",
    "\n",
    "allCompanies = pd.concat(frames).drop_duplicates()\n",
    "\n",
    "print(allCompanies.shape)\n",
    "\n",
    "allCompanies.to_csv(\"../../data/companyData/allCompaniesWithWeather.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Biggest Supplier\n",
    "Focus on weather of biggest supplier.\n",
    "\n",
    "First find the max by supplier. Add back in any rows with only 1 supplier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customerDB.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/15705630/get-the-rows-which-have-the-max-value-in-groups-using-groupby\n",
    "idx = customerDB.groupby(['year','gvkey']).salecs.\\\n",
    "    transform(max) == customerDB.salecs\n",
    "largestSuppliers = customerDB[idx].reset_index(drop = True)\n",
    "print(largestSuppliers.shape)\n",
    "\n",
    "# find companies who only have one other supplier\n",
    "singleSuppliers = customerDB[customerDB.suppliers == 1].reset_index(drop = True)\n",
    "print(singleSuppliers.shape)\n",
    "\n",
    "# find largest suppliers of different companies\n",
    "largestSuppliers = largestSuppliers.append(singleSuppliers).drop_duplicates()\n",
    "print(largestSuppliers.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customerDB[['year','gvkey']][customerDB.year > 2009].drop_duplicates().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(largestSuppliers.gvkey.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in suppliersWithWeather.columns:\n",
    "    print(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevantVars = [x for x in suppliersWithWeather.columns if (('year' in x) | \n",
    "                                                 ('qtr' in x) |\n",
    "                                                 ('gvkey' in x) |\n",
    "                                                 ('_' in x)) & \n",
    "                                                ~('roa_lagged' in x) & \n",
    "                                                ~('yearQtr' in x)]\n",
    "\n",
    "suppliers_toMerge = suppliersWithWeather[relevantVars]\n",
    "\n",
    "\n",
    "for colname in suppliers_toMerge.columns[3:]:\n",
    "    suppliers_toMerge.rename(columns = {colname: 'supplier_' + colname}, inplace = True)\n",
    "\n",
    "    \n",
    "suppliers_toMerge.rename(columns = {'gvkey': 'supplier_gvkey'},inplace = True)    \n",
    "\n",
    "print(suppliers_toMerge.columns)\n",
    "\n",
    "\n",
    "'''suppliers_toMerge = suppliersWithWeather[['year','qtr','gvkey','tmax_quant_1.0','precip_quant_1.0']].\\\n",
    "    rename(columns = {'gvkey': 'supplier_gvkey',\n",
    "                      'tmax_quant_1.0': 'supplier_tmax_quant_1.0',\n",
    "                      'precip_quant_1.0': 'supplier_precip_quant_1.0'})'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customersWithWeather.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(supplierWtdAvgWeather.gvkey.unique()) - set(suppliers_toMerge.gvkey.unique()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "largestSuppliers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "largestSuppliersWithWeather = customersWithWeather.merge(largestSuppliers[['year', 'gvkey', 'supplier_gvkey']]).merge(suppliers_toMerge)\n",
    "largestSuppliersWithWeather.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "largestSuppliersWithWeather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "largestSuppliersWithWeather.to_csv(\"../../data/companyData/largestSuppliersWithWeather.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "largestSuppliersWithWeather.suppliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "largestSuppliersWithWeather = pd.read_csv(\"../../data/companyData/largestSuppliersWithWeather.csv\")\n",
    "largestSuppliersWithWeather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "largestSuppliersWithWeather.columns[0:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sales-Weighted Average\n",
    "If a company doesn't have sales-specific information, then assume equal shares. This doesn't happen for too many of the companies, thankfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customerDB = c_links[['year','customer_gvkey','supplier_gvkey','salecs']].\\\n",
    "    merge(custExp).rename(columns = {'customer_gvkey': 'gvkey'}).drop_duplicates()\n",
    "\n",
    "customerDB['salesWeight'] = customerDB.salecs/customerDB.totalExp\n",
    "\n",
    "customerDB.fillna(1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now merge this with the supplier weather data, and use the sales weights to find a sales-weighted average of the weather conditions for the suppliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevantVars = [x for x in suppliersWithWeather.columns if (('year' in x) | \n",
    "                                                 ('qtr' in x) |\n",
    "                                                 ('gvkey' in x) |\n",
    "                                                 ('_' in x)) & \n",
    "                                                ~('roa_lagged' in x) & \n",
    "                                                ~('yearQtr' in x)]\n",
    "\n",
    "suppliers_toMerge = suppliersWithWeather[relevantVars]\n",
    "\n",
    "\n",
    "for colname in suppliers_toMerge.columns[3:]:\n",
    "    suppliers_toMerge.rename(columns = {colname: 'supplier_' + colname}, inplace = True)\n",
    "\n",
    "    \n",
    "suppliers_toMerge.rename(columns = {'gvkey': 'supplier_gvkey'},inplace = True)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suppliers_toMerge.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of the supplier weather columns, multiply the variable by the fraction of sales attributable to that relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supplierWeather = customerDB[['year','gvkey','supplier_gvkey','salesWeight']].merge(suppliers_toMerge)\n",
    "\n",
    "for col in supplierWeather.columns[5:]:\n",
    "        supplierWeather[col]   = supplierWeather.salesWeight*supplierWeather[col]\n",
    "        \n",
    "        \n",
    "\n",
    "supplierWeather.drop(columns = {'supplier_gvkey','salesWeight'}, inplace = True)\n",
    "\n",
    "\n",
    "print(supplierWeather.head())\n",
    "\n",
    "\n",
    "\n",
    "# [['year','qtr','gvkey','supplier_tmax_quant_1.0','supplier_precip_quant_1.0']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supplierWtdAvgWeather = supplierWeather.groupby(['year','qtr','gvkey']).sum().reset_index().drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supplierWtdAvgWeather.gvkey.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge the supplier weighted average weather data with the customer data that has weather as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customersWithWeather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wtdAvgSuppliers = customersWithWeather.merge(supplierWtdAvgWeather)\n",
    "\n",
    "wtdAvgSuppliers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wtdAvgSuppliers.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wtdAvgSuppliers.to_csv(\"../../data/companyData/wtdAvgSuppliers.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wtdAvgSuppliers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wtdAvgSuppliers.columns[wtdAvgSuppliers.columns.str.contains('Tercile')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
