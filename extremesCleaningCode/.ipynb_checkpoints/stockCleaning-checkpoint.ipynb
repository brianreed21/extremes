{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning File\n",
    "Get the basic company information here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import os\n",
    "import re\n",
    "\n",
    "import collections\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "import geopandas as gpd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from difflib import get_close_matches\n",
    "\n",
    "from fuzzywuzzy import process\n",
    "from fuzzywuzzy import fuzz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock price data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"../../data/crsp_raw.csv\"\n",
    "raw = pd.read_csv(file, encoding = 'unicode_escape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's follow Evan's crsp cleaning and linking process.\n",
    "\n",
    "1. Drop firms not traded on NYSE or NASDAQ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_exch = raw[ (raw['PRIMEXCH'] != 'Q') & (raw['PRIMEXCH'] != 'N') ].index\n",
    "raw.drop(other_exch, inplace=True)\n",
    "raw.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Drop entries with missing return or volume information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.dropna(subset=['VOL', 'RET','date'],inplace=True)\n",
    "raw['VOL'] = raw['VOL'].astype('int')\n",
    "raw.drop(raw[raw['RET']=='C'].index,inplace=True)\n",
    "raw['RET'] = raw['RET'].astype('float')\n",
    "raw['date'] = raw['date'].astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Drop tickers with average daily trading volume less than 100K shares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv = raw[['VOL','TICKER']].groupby(['TICKER']).mean()\n",
    "low_vol = adv.drop(adv[adv['VOL']>=100000].index)\n",
    "low_vol_index = raw[raw['TICKER'].isin(low_vol.index)].index\n",
    "raw.drop(low_vol_index,inplace=True)\n",
    "raw.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Drop tickers that traded for less than 20% of the period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndays = len(raw.date.unique())\n",
    "obs = raw['TICKER'].value_counts()\n",
    "rare_obs = obs[obs<0.2*ndays]\n",
    "rare_index = raw[raw['TICKER'].isin(rare_obs.index)].index\n",
    "raw.drop(rare_index,inplace=True)\n",
    "raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = raw.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge in GVKEY information for linking with compustat.\n",
    "\n",
    "gv_cik will come in hand with another merge maybe; but to get to compustat, looks like we just need gvkey - permco."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the keys seem to be used twice. Let's see if they're re-used when a company has gone out of business."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gv_cik = pd.read_csv(\"data/cik_gvkey.csv\",dtype={'cik':str})[['cik','gvkey']]\n",
    "gv_permco = pd.read_csv(\"../../data/cik_permco.csv\",dtype={'cik':str})\n",
    "# [['gvkey','LPERMCO']].rename(columns = {'LPERMCO': 'PERMCO'}).drop_duplicates()\n",
    "\n",
    "gv_permco.loc[gv_permco.LINKENDDT == 'E', 'LINKENDDT'] = '20210101'\n",
    "gv_permco['existsCurrently'] = pd.DatetimeIndex(pd.to_datetime(gv_permco.LINKENDDT.astype(str), format='%Y%m%d')).year\n",
    "\n",
    "gv_permco = gv_permco[gv_permco.existsCurrently > 2010]\n",
    "print(gv_permco.shape)\n",
    "print(gv_permco.head())\n",
    "\n",
    "gv_permco = gv_permco[['gvkey','LPERMCO','conm']].rename(columns = {'LPERMCO': 'PERMCO'}).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for company in gv_permco[gv_permco.PERMCO.duplicated()].conm:\n",
    "    print(company)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop the duplicated entries. We may want to revisit this later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gv_permco = gv_permco[~gv_permco.PERMCO.isin(list(gv_permco.PERMCO[gv_permco.PERMCO.duplicated()]))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now just merge the raw return information with this company information so we can link everything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawMergeable = pd.merge(raw,gv_permco,on='PERMCO',how = 'left')\n",
    "rawMergeable.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawMergeable = rawMergeable.drop(['RETX'],axis = 1)\n",
    "rawMergeable['date'] = pd.to_datetime(rawMergeable['date'].astype(str), format='%Y%m%d')\n",
    "rawMergeable['year'] = pd.DatetimeIndex(rawMergeable['date']).year\n",
    "rawMergeable.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile =  '../../data/stockReturns.pkl'\n",
    "with open(outfile, 'wb') as pickle_file:\n",
    "    pickle.dump(rawMergeable, pickle_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawMergeable.year.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crsp2010s = crsp[['date','year','PERMNO','COMNAM','PRC']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(crsp.RET == crsp.RETX)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
