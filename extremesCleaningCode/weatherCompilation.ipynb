{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import os\n",
    "import re\n",
    "\n",
    "import collections\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "import geopandas as gpd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from difflib import get_close_matches\n",
    "\n",
    "from fuzzywuzzy import process\n",
    "from fuzzywuzzy import fuzz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weather Data\n",
    "First do this on the HQ zipcodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allWeather = pd.read_csv(\"../../data/companyData/revised_allWeatherBins_2009to2019.csv\").\\\n",
    "    drop(columns = {\"Unnamed: 0\"})\n",
    "\n",
    "allWeather['yearQtr'] = allWeather.year + (allWeather.qtr - 1)/4\n",
    "\n",
    "col = allWeather.pop(\"yearQtr\")\n",
    "allWeather.insert(0, col.name, col)\n",
    "\n",
    "lag1 = allWeather.copy()\n",
    "lag1['yearQtr'] += 0.25\n",
    "for colname in lag1.columns[4:]:\n",
    "    lag1.rename(columns = {colname: 'lag1_' + colname}, inplace = True)\n",
    "lag1.drop(columns = {'year','qtr'},inplace = True)\n",
    "\n",
    "    \n",
    "lag2 = allWeather.copy()\n",
    "lag2['yearQtr'] += 0.5\n",
    "for colname in lag2.columns[4:]:\n",
    "    lag2.rename(columns = {colname: 'lag2_' + colname}, inplace = True)\n",
    "lag2.drop(columns = {'year','qtr'},inplace = True)\n",
    "\n",
    "\n",
    "lag3 = allWeather.copy()\n",
    "lag3['yearQtr'] += 0.75\n",
    "for colname in lag3.columns[4:]:\n",
    "    lag3.rename(columns = {colname: 'lag3_' + colname}, inplace = True)\n",
    "lag3.drop(columns = {'year','qtr'},inplace = True)\n",
    "\n",
    "\n",
    "lag4 = allWeather.copy()\n",
    "lag4['yearQtr'] += 1\n",
    "for colname in lag4.columns[4:]:\n",
    "    lag4.rename(columns = {colname: 'lag4_' + colname}, inplace = True)\n",
    "lag4.drop(columns = {'year','qtr'},inplace = True)\n",
    "\n",
    "\n",
    "print(allWeather.shape)\n",
    "\n",
    "allWeather_withLags = allWeather.merge(lag1).merge(lag2).merge(lag3).merge(lag4)\n",
    "\n",
    "print(allWeather_withLags.year.value_counts())\n",
    "\n",
    "allWeather_withLags.to_csv(\"../../data/companyData/allWeather_withLags.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do this across all zips, for the establishment records. We'll put this into a different format right after, and then change the columns and whatnot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allWeather = pd.read_csv(\"../../data/companyData/revised_allWeatherBins_2009to2019_allZips.csv\").\\\n",
    "    drop(columns = {\"Unnamed: 0\", 'Unnamed: 0.1'})\n",
    "\n",
    "allWeather['yearQtr'] = allWeather.year + (allWeather.qtr - 1)/4\n",
    "\n",
    "col = allWeather.pop(\"yearQtr\")\n",
    "allWeather.insert(0, col.name, col)\n",
    "\n",
    "lag1 = allWeather.copy()\n",
    "lag1['yearQtr'] += 0.25\n",
    "for colname in lag1.columns[4:]:\n",
    "    lag1.rename(columns = {colname: 'lag1_' + colname}, inplace = True)\n",
    "lag1.drop(columns = {'year','qtr'},inplace = True)\n",
    "\n",
    "    \n",
    "lag2 = allWeather.copy()\n",
    "lag2['yearQtr'] += 0.5\n",
    "for colname in lag2.columns[4:]:\n",
    "    lag2.rename(columns = {colname: 'lag2_' + colname}, inplace = True)\n",
    "lag2.drop(columns = {'year','qtr'},inplace = True)\n",
    "\n",
    "\n",
    "lag3 = allWeather.copy()\n",
    "lag3['yearQtr'] += 0.75\n",
    "for colname in lag3.columns[4:]:\n",
    "    lag3.rename(columns = {colname: 'lag3_' + colname}, inplace = True)\n",
    "lag3.drop(columns = {'year','qtr'},inplace = True)\n",
    "\n",
    "\n",
    "lag4 = allWeather.copy()\n",
    "lag4['yearQtr'] += 1\n",
    "for colname in lag4.columns[4:]:\n",
    "    lag4.rename(columns = {colname: 'lag4_' + colname}, inplace = True)\n",
    "lag4.drop(columns = {'year','qtr'},inplace = True)\n",
    "\n",
    "\n",
    "print(allWeather.shape)\n",
    "\n",
    "allWeather_withLags = allWeather.merge(lag1).merge(lag2).merge(lag3).merge(lag4)\n",
    "\n",
    "print(allWeather_withLags.year.value_counts())\n",
    "\n",
    "allWeather_withLags.to_csv(\"../../data/companyData/allWeather_withLags_allZips.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add in the few new definitions we've started on here: bins by week/month/quarter, and days 90+."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allWeather = pd.read_csv(\"../../data/companyData/latestExtremes.csv\").\\\n",
    "    drop(columns = {\"Unnamed: 0\"})\n",
    "allWeather.rename(columns = {'quarter': 'qtr'}, inplace = True)\n",
    "\n",
    "allWeather['yearQtr'] = allWeather.year + (allWeather.qtr - 1)/4\n",
    "\n",
    "col = allWeather.pop(\"yearQtr\")\n",
    "allWeather.insert(0, col.name, col)\n",
    "\n",
    "lag1 = allWeather.copy()\n",
    "lag1['yearQtr'] += 0.25\n",
    "for colname in lag1.columns[4:]:\n",
    "    lag1.rename(columns = {colname: 'lag1_' + colname}, inplace = True)\n",
    "lag1.drop(columns = {'year','qtr'},inplace = True)\n",
    "\n",
    "    \n",
    "lag2 = allWeather.copy()\n",
    "lag2['yearQtr'] += 0.5\n",
    "for colname in lag2.columns[4:]:\n",
    "    lag2.rename(columns = {colname: 'lag2_' + colname}, inplace = True)\n",
    "lag2.drop(columns = {'year','qtr'},inplace = True)\n",
    "\n",
    "\n",
    "lag3 = allWeather.copy()\n",
    "lag3['yearQtr'] += 0.75\n",
    "for colname in lag3.columns[4:]:\n",
    "    lag3.rename(columns = {colname: 'lag3_' + colname}, inplace = True)\n",
    "lag3.drop(columns = {'year','qtr'},inplace = True)\n",
    "\n",
    "\n",
    "lag4 = allWeather.copy()\n",
    "lag4['yearQtr'] += 1\n",
    "for colname in lag4.columns[4:]:\n",
    "    lag4.rename(columns = {colname: 'lag4_' + colname}, inplace = True)\n",
    "lag4.drop(columns = {'year','qtr'},inplace = True)\n",
    "\n",
    "\n",
    "print(allWeather.shape)\n",
    "\n",
    "allWeather_withLags = allWeather.merge(lag1).merge(lag2).merge(lag3).merge(lag4)\n",
    "\n",
    "print(allWeather_withLags.year.value_counts())\n",
    "\n",
    "allWeather_withLags.to_csv(\"../../data/companyData/allWeather_withLags_new.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now do the same for the industry-specific weather."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allWeather = pd.read_csv(\"../../../../../../../Volumes/backup2/dissData/prism/allWeatherBins_2010.2019.csv\").\\\n",
    "allWeather_byInd = pd.read_csv(\"../../data/companyData/revised_allWeatherBins_2009to2019_byInd.csv\").\\\n",
    "    drop(columns = {\"Unnamed: 0\"})\n",
    "'''[['famafrench','zipcode','yearQuarter', \n",
    "                                    'temp_ffquant_0.95','temp_indQuarterquant_0.95',\n",
    "                                   'temp5Days_ffquant_0.95', 'temp5Days_indQuarterquant_0.95',\n",
    "                                   'precip_ffquant_0.95', 'precip_indQuarterquant_0.95',\n",
    "                                   'precip5Days_ffquant_0.95', 'precip5Days_indQuarterquant_0.95']]\n",
    "'''\n",
    "allWeather_byInd['year'] = allWeather_byInd.yearQuarter.str.slice(0,4).astype('int64')\n",
    "allWeather_byInd['qtr']  = allWeather_byInd.yearQuarter.str.slice(5,6).astype('int64')\n",
    "allWeather_byInd['yearQtr'] = allWeather_byInd.year + (allWeather_byInd.qtr - 1)/4\n",
    "\n",
    "allWeather_byInd = allWeather_byInd.astype({'year':       'category',\n",
    "                         'qtr':        'category',\n",
    "                         'zipcode':    'category',\n",
    "                         'famafrench': 'category'})\n",
    "\n",
    "changes['zipcode'] = changes['zipcode'].astype({'zipcode': 'int64'})\n",
    "\n",
    "changes = changes.astype({'year':       'category',\n",
    "                          'qtr':        'category',\n",
    "                          'zipcode':    'category',\n",
    "                          'famafrench': 'category'})\n",
    "\n",
    "col = allWeather_byInd.pop(\"year\")\n",
    "allWeather_byInd.insert(0, col.name, col)\n",
    "\n",
    "col = allWeather_byInd.pop(\"qtr\")\n",
    "allWeather_byInd.insert(0, col.name, col)\n",
    "\n",
    "\n",
    "col = allWeather_byInd.pop(\"yearQtr\")\n",
    "allWeather_byInd.insert(0, col.name, col)\n",
    "\n",
    "allWeather_byInd.drop(columns = {'yearQuarter'}, inplace = True)\n",
    "\n",
    "print(allWeather_byInd.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lag1 = allWeather_byInd.copy()\n",
    "lag1['yearQtr'] += 0.25\n",
    "for colname in lag1.columns[5:]:\n",
    "    lag1.rename(columns = {colname: 'lag1_' + colname}, inplace = True)\n",
    "lag1.drop(columns = {'year','qtr'},inplace = True)\n",
    "lag1 = lag1.astype({'yearQtr':       'category'})\n",
    "\n",
    "    \n",
    "lag2 = allWeather_byInd.copy()\n",
    "lag2['yearQtr'] += 0.5\n",
    "for colname in lag2.columns[5:]:\n",
    "    lag2.rename(columns = {colname: 'lag2_' + colname}, inplace = True)\n",
    "lag2.drop(columns = {'year','qtr'},inplace = True)\n",
    "lag2 = lag2.astype({'yearQtr':       'category'})\n",
    "\n",
    "\n",
    "lag3 = allWeather_byInd.copy()\n",
    "lag3['yearQtr'] += 0.75\n",
    "for colname in lag3.columns[5:]:\n",
    "    lag3.rename(columns = {colname: 'lag3_' + colname}, inplace = True)\n",
    "lag3.drop(columns = {'year','qtr'},inplace = True)\n",
    "lag3 = lag3.astype({'yearQtr':       'category'})\n",
    "\n",
    "\n",
    "lag4 = allWeather_byInd.copy()\n",
    "lag4['yearQtr'] += 1\n",
    "for colname in lag4.columns[5:]:\n",
    "    lag4.rename(columns = {colname: 'lag4_' + colname}, inplace = True)\n",
    "lag4.drop(columns = {'year','qtr'},inplace = True)\n",
    "lag4 = lag4.astype({'yearQtr':       'category'})\n",
    "\n",
    "\n",
    "allWeather_byInd = allWeather_byInd.astype({'yearQtr':       'category'})\n",
    "\n",
    "\n",
    "print(allWeather_byInd.shape)\n",
    "\n",
    "\n",
    "allWeather_byInd.head()\n",
    "\n",
    "\n",
    "'''allWeather_byInd_withLags = allWeather_byInd.merge(lag1).merge(lag2).merge(lag3).merge(lag4)\n",
    "\n",
    "allWeather_byInd_withLags.year.value_counts()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allWeather_byInd_withLags = allWeather_byInd.merge(lag1).merge(lag2).merge(lag3).merge(lag4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allWeather_byInd_withLags.to_csv(\"../../data/companyData/allWeather_byInd_withLags.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allWeather_byInd_withLags = pd.read_csv(\"../../data/companyData/allWeather_byInd_withLags.csv\")\n",
    "allWeather_byInd_withLags.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del allWeather_byInd\n",
    "del lag1\n",
    "del lag2\n",
    "del lag3\n",
    "del lag4\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now get the streak data. Make sure it's 0/1 for whether there was a streak."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allWeather = pd.read_csv(\"../../data/companyData/stockWeather_zipQuarterQuants.csv\").\\\n",
    "    drop(columns = {'Unnamed: 0'})\n",
    "\n",
    "allWeather = allWeather[~allWeather.temp_zipQuarterLast5.isna()].reset_index(drop = True)\n",
    "\n",
    "allWeather['date'] = pd.to_datetime(allWeather['date'],\n",
    "                                   format = \"%Y-%m-%d\")\n",
    "\n",
    "allWeather['hotStreak']   = (allWeather['temp_zipQuarterLast5'] == 5)*1\n",
    "allWeather['wetStreak'] = (allWeather['precip_zipQuarterLast5'] == 5)*1\n",
    "\n",
    "allWeather.rename(columns = {'ZIP': 'zipcode'}, inplace = True)\n",
    "print(allWeather.dtypes)\n",
    "\n",
    "allWeather['year'] = allWeather.date.dt.year\n",
    "allWeather['quarter'] = allWeather.date.dt.quarter\n",
    "\n",
    "\n",
    "allWeather.drop(columns = {'date','temp_zipQuarterLast5','precip_zipQuarterLast5'}, inplace = True)\n",
    "\n",
    "streaks = allWeather.groupby(['zipcode','year','quarter']).sum().reset_index()\n",
    "\n",
    "streaks['hotStreak'] = (streaks['hotStreak'] > 0)*1\n",
    "streaks['wetStreak'] = (streaks['wetStreak'] > 0)*1\n",
    "\n",
    "streaks.rename(columns = {'quarter': 'qtr'}, inplace = True)\n",
    "streaks.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "streaks['yearQtr'] = streaks.year + (streaks.qtr - 1)/4\n",
    "\n",
    "col = streaks.pop(\"yearQtr\")\n",
    "streaks.insert(0, col.name, col)\n",
    "\n",
    "lag1 = streaks.copy()\n",
    "lag1['yearQtr'] += 0.25\n",
    "for colname in lag1.columns[4:]:\n",
    "    lag1.rename(columns = {colname: 'lag1_' + colname}, inplace = True)\n",
    "lag1.drop(columns = {'year','qtr'},inplace = True)\n",
    "\n",
    "    \n",
    "lag2 = streaks.copy()\n",
    "lag2['yearQtr'] += 0.5\n",
    "for colname in lag2.columns[4:]:\n",
    "    lag2.rename(columns = {colname: 'lag2_' + colname}, inplace = True)\n",
    "lag2.drop(columns = {'year','qtr'},inplace = True)\n",
    "\n",
    "\n",
    "lag3 = streaks.copy()\n",
    "lag3['yearQtr'] += 0.75\n",
    "for colname in lag3.columns[4:]:\n",
    "    lag3.rename(columns = {colname: 'lag3_' + colname}, inplace = True)\n",
    "lag3.drop(columns = {'year','qtr'},inplace = True)\n",
    "\n",
    "\n",
    "lag4 = streaks.copy()\n",
    "lag4['yearQtr'] += 1\n",
    "for colname in lag4.columns[4:]:\n",
    "    lag4.rename(columns = {colname: 'lag4_' + colname}, inplace = True)\n",
    "lag4.drop(columns = {'year','qtr'},inplace = True)\n",
    "\n",
    "\n",
    "print(streaks.shape)\n",
    "\n",
    "streaks_withLags = streaks.merge(lag1).merge(lag2).merge(lag3).merge(lag4)\n",
    "\n",
    "print(streaks_withLags.year.value_counts())\n",
    "\n",
    "streaks_withLags.to_csv(\"../../data/companyData/streaks_withLags.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "streaks_withLags = pd.read_csv(\"../../data/companyData/streaks_withLags.csv\")\n",
    "streaks_withLags.year.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "streaks_withLags.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now the severe weather."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipQuarters = pd.read_csv(\"../../data/companyData/allWeather_withLags_new.csv\")[['zipcode','year','qtr']].drop_duplicates()\n",
    "\n",
    "\n",
    "zipQuarters_2009 = zipQuarters.copy()\n",
    "zipQuarters_2009 = zipQuarters[zipQuarters.year == 2010]\n",
    "zipQuarters_2009['year'] = zipQuarters_2009['year'] - 1\n",
    "\n",
    "zipQuarters = zipQuarters_2009.append(zipQuarters)\n",
    "\n",
    "\n",
    "zipQuarters.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipQuarters.year.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thunderstorms = pd.read_csv(\"../../data/companyData/thunderstormWinds.csv\").\\\n",
    "    drop(columns = {'Unnamed: 0', 'STCOUNTYFP'})\n",
    "\n",
    "thunderstorms['year'] =  thunderstorms['yearQtr'].str.slice(0,4).astype('int64')\n",
    "\n",
    "print(thunderstorms.year.min())\n",
    "\n",
    "thunderstorms.head()\n",
    "\n",
    "\n",
    "thunderstorms['qtr']  =  thunderstorms['yearQtr'].str.slice(5,6).astype('int64')\n",
    "thunderstorms.drop(columns = {'yearQtr'}, inplace = True)\n",
    "thunderstorms = thunderstorms[(thunderstorms.year > 2008) & (thunderstorms.year < 2020)]\n",
    "\n",
    "print(thunderstorms.shape)\n",
    "\n",
    "thunderstorms = zipQuarters.merge(thunderstorms, how = 'left')\n",
    "thunderstorms = thunderstorms.fillna(0)\n",
    "print(zipQuarters.shape, thunderstorms.shape)\n",
    "\n",
    "thunderstorms.year.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thunderstorms = thunderstorms.groupby(['zipcode','year','qtr']).sum().reset_index()\n",
    "\n",
    "thunderstorms['propAboveTenThou']     = (thunderstorms['propAboveTenThou'] > 0)*1\n",
    "thunderstorms['propAboveHundredThou'] = (thunderstorms['propAboveHundredThou'] > 0)*1\n",
    "thunderstorms['propAboveMilli']       = (thunderstorms['propAboveMilli'] > 0)*1\n",
    "\n",
    "\n",
    "thunderstorms.year.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thunderstorms['yearQtr'] = thunderstorms.year + (thunderstorms.qtr - 1)/4\n",
    "\n",
    "col = thunderstorms.pop(\"year\")\n",
    "thunderstorms.insert(0, col.name, col)\n",
    "\n",
    "col = thunderstorms.pop(\"qtr\")\n",
    "thunderstorms.insert(0, col.name, col)\n",
    "\n",
    "col = thunderstorms.pop(\"yearQtr\")\n",
    "thunderstorms.insert(0, col.name, col)\n",
    "\n",
    "col = thunderstorms.pop(\"zipcode\")\n",
    "thunderstorms.insert(0, col.name, col)\n",
    "\n",
    "thunderstorms = thunderstorms.astype({'zipcode':    'category'})\n",
    "\n",
    "\n",
    "lag1 = thunderstorms.copy()\n",
    "lag1['yearQtr'] += 0.25\n",
    "for colname in lag1.columns[4:]:\n",
    "    lag1.rename(columns = {colname: 'lag1_' + colname}, inplace = True)\n",
    "lag1.drop(columns = {'year','qtr'},inplace = True)\n",
    "lag1 = lag1.astype({'yearQtr':    'category'})\n",
    "\n",
    "\n",
    "\n",
    "lag2 = thunderstorms.copy()\n",
    "lag2['yearQtr'] += 0.5\n",
    "for colname in lag2.columns[4:]:\n",
    "    lag2.rename(columns = {colname: 'lag2_' + colname}, inplace = True)\n",
    "lag2.drop(columns = {'year','qtr'},inplace = True)\n",
    "lag2 = lag2.astype({'yearQtr':    'category'})\n",
    "\n",
    "\n",
    "lag3 = thunderstorms.copy()\n",
    "lag3['yearQtr'] += 0.75\n",
    "for colname in lag3.columns[4:]:\n",
    "    lag3.rename(columns = {colname: 'lag3_' + colname}, inplace = True)\n",
    "lag3.drop(columns = {'year','qtr'},inplace = True)\n",
    "lag3 = lag3.astype({'yearQtr':    'category'})\n",
    "\n",
    "lag4 = thunderstorms.copy()\n",
    "lag4['yearQtr'] += 1\n",
    "for colname in lag4.columns[4:]:\n",
    "    lag4.rename(columns = {colname: 'lag4_' + colname}, inplace = True)\n",
    "lag4.drop(columns = {'year','qtr'},inplace = True)\n",
    "lag4 = lag4.astype({'yearQtr':    'category'})\n",
    "\n",
    "\n",
    "thunderstorms = thunderstorms.astype({'yearQtr':    'category'})\n",
    "\n",
    "thunderstorms_withLags = thunderstorms.merge(lag1).merge(lag2).merge(lag3).merge(lag4)\n",
    "print(thunderstorms_withLags.year.value_counts())\n",
    "\n",
    "thunderstorms_withLags.to_csv(\"../../data/companyData/thunderstorms_withLags.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(thunderstorms_withLags.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Locations\n",
    "Create a separate definition of weather based not on HQ but on employee-weighted establishment footprint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fractions = pd.read_csv('../../data/companyData/fractionEmployees_byEstablishment.csv').\\\n",
    "    drop(columns = {\"Unnamed: 0\", 'latitude','longitude'}).rename(columns = {'archive_version_year': 'year',\n",
    "                                                    'parent_number': 'abi'})\n",
    "\n",
    "fractions['year']    = fractions.year.astype('int64')\n",
    "fractions['zipcode'] = fractions.zipcode.astype('int64')\n",
    "fractions.head()\n",
    "\n",
    "gvKey_abiLinkingTable = pd.read_csv('../../data/companyData/linkingTable.csv').drop(columns = ['Unnamed: 0'])\n",
    "\n",
    "print(gvKey_abiLinkingTable.abi)\n",
    "\n",
    "gvKey_abiLinkingTable.head()\n",
    "\n",
    "fractions = fractions[['year','abi','zipcode','locationFracOfEmployees']].merge(gvKey_abiLinkingTable[['abi','gvkey']])\n",
    "\n",
    "fractions = fractions.astype({'year':       'category',\n",
    "                           'zipcode':    'category'})\n",
    "\n",
    "fractions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fractions.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fractions_byZip = fractions[['gvkey','year','zipcode','locationFracOfEmployees']]\n",
    "fractions_byZip['year'] =  fractions_byZip['year'].astype('int64')\n",
    "\n",
    "fractions_byZip = fractions_byZip[(fractions_byZip.year > 2008) & (fractions_byZip.year < 2020)]\n",
    "\n",
    "print(fractions_byZip.shape)\n",
    "\n",
    "fractions_byZip.to_csv(\"../../data/companyData/fractions_byZip.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fractionsWithWeather = fractions.merge(allWeather_withLags_allZips) \n",
    "fractionsWithWeather.drop(columns = {'abi','zipcode'}, inplace = True)\n",
    "\n",
    "print(fractionsWithWeather.shape)\n",
    "fractionsWithWeather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fractionsWithWeather[fractionsWithWeather.gvkey == 1004]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del allWeather_withLags\n",
    "del fractions\n",
    "del gvKey_abiLinkingTable\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in fractionsWithWeather.columns[4:]:\n",
    "    fractionsWithWeather[col] = fractionsWithWeather[col] * fractionsWithWeather.locationFracOfEmployees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = fractionsWithWeather.groupby(['gvkey','year','qtr']).sum().reset_index()\n",
    "g.drop(columns = {'locationFracOfEmployees'}, inplace = True)\n",
    "\n",
    "for colname in g.columns[3:]:\n",
    "    g.rename(columns = {colname: 'empWt_' + colname}, inplace = True)\n",
    "\n",
    "g.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.to_csv(\"../../data/companyData/weatherByEstablishment.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "establishmentZips = fractions.zipcode.unique()\n",
    "len(establishmentZips)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
