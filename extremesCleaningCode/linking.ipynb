{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import os\n",
    "import re\n",
    "\n",
    "import collections\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "import geopandas as gpd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import rasterio\n",
    "\n",
    "import spacy\n",
    "  \n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Full IG Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"../../data/companyData/infogroup2010s.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "\n",
    "df = dd.read_csv(file, assume_missing=True, \n",
    "                 dtype={'parent_number': 'object','parent_employee_size_code': 'object',\n",
    "                       'parent_sales_volume_code': 'object',\n",
    "                       'abi': 'object'}, low_memory = False)\n",
    "df = df[df.business_status_code == 1.0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hq = df[['abi','company']].drop_duplicates().compute(num_workers = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hq.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the abi numbers seem to be duplicated; it looks like they might be primarily for different government agencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hq.company.value_counts()[hq.company.value_counts() > 10].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hq.company.isin(toDiscard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toDiscard = hq.company.value_counts()[hq.company.value_counts() > 1].index\n",
    "for company in toDiscard:\n",
    "    print(company)\n",
    "\n",
    "hq = hq[~hq.company.isin(toDiscard)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we have a unique record of every company - hq here. Some of these may well be duplicate entries for a given company, for the cases in which we have a company that has multiple hq.\n",
    "\n",
    "Let's stash it so that we don't have to go through the above ^^ again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hq.to_csv(\"../../data/ig2010s_uniqueHQs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hq = pd.read_csv(\"../../data/ig2010s_uniqueHQs.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grab Compustat Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the company dataset and check.\n",
    "\n",
    "The legal name and the given name are slightly different, but basically the same modulo punctuation and case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chq = pd.read_csv(\"../../data/companyData/compustatChanges_2010s.csv\").drop(columns = {'Unnamed: 0'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chq.columns,chq.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subset this to focus on firms in: ag, mining, construction, manufacturing, wholesale and retail, and transportation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chq = chq[(chq.naics.astype('str').str.slice(0,2).isin(['11','21','22','23','31','32',\n",
    "                                                         '33','42','44','45','48','49']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chq.head(),chq.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chq = chq[['gvkey','companyName']].drop_duplicates()\n",
    "chq.rename(columns = {'companyName': 'company'},inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only two of these company names appear 2x, which is good. There are ~20,000 companies in this sample.\n",
    "\n",
    "Let's go through a little bit of a process here:\n",
    "- Find the exact matches.\n",
    "- Get a similarity measure between ; ideally something vectorized / something in matrix math.\n",
    "- Find the top 10 matches for the remaining ones.\n",
    "- Do some mix and match and see if there's any threshold at which matches become similar ``enough'' to say this is okay and good to go.\n",
    "\n",
    "\n",
    "We might be able to use the fact that all of the addresses should be the same after some given point, as the compustat addresses are only the most recent ones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chq.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try a few different ways to match these up.\n",
    "\n",
    "First, let's find the exact matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "easyMerge = chq.merge(hq)\n",
    "print(easyMerge.shape,easyMerge.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chqUnmatched = chq[~chq.company.isin(easyMerge.company)].reset_index()\n",
    "chqUnmatched.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a generic cleaning function that strips out all company names, any punctuation in the name, and makes everything lower case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanText(text):\n",
    "    text = text.\\\n",
    "    replace(\" CORP\",\"\").replace(\" CO\",\"\").replace(\" INC\",\"\").\\\n",
    "    replace(\" LTD\",\"\").replace(\" -CL A\",\"\").\\\n",
    "    replace(\" -LP\",\"\").replace(\" LP\",\"\").\\\n",
    "    replace(\"-OLD\",\"\").replace(\" LLC\",\"\").\\\n",
    "    replace(\" -CL B\",\"\").replace(\" -CL i\",\"\").replace(\" -CL\",\"\").\\\n",
    "    replace(\"-REDH\",\"\").replace(\" CP\",\"\").\\\n",
    "    replace(\"-ADR\",\"\").replace(\" PLC\",\"\").lower().replace(r'[^\\w\\s]+', '')\n",
    "    \n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chqUnmatched['company'] = list(map(cleanText, chqUnmatched.company))\n",
    "hq['company']           = list(map(cleanText, hq.company))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allCompaniesCStat = list(map(nlp, chqUnmatched.company))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allCompaniesIG = list(map(nlp, hq.company))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile =  '../../data/allCompaniesIG_embeddings.pkl'\n",
    "with open(outfile, 'wb') as pickle_file:\n",
    "    pkl.dump(allCompaniesIG, pickle_file)\n",
    "    \n",
    "outfile =  '../../data/allCompaniesCStat_embeddings.pkl'\n",
    "with open(outfile, 'wb') as pickle_file:\n",
    "    pkl.dump(allCompaniesCStat, pickle_file)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMatrix(companyEmbeddings):\n",
    "    companyArray = []\n",
    "    \n",
    "    for companies in companyEmbeddings:\n",
    "        companyArray.append([companies.vector])\n",
    "    \n",
    "    companyArray = np.concatenate(companyArray)\n",
    "    \n",
    "    return(companyArray)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cstat = getMatrix(allCompaniesCStat)\n",
    "ig = getMatrix(allCompaniesIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ig.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allSimilarities = cosine_similarity(cstat,ig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row n here has the similarity between the nth company name in compustat and the IG company corresp to that column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allSimilarities[0:5,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find indices of companies in IG most similar to each company in CStat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 50\n",
    "largestElements = (-allSimilarities).argsort(axis=1)[:, :n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "companyMatches = pd.DataFrame()\n",
    "companyMatches['cstatCompanies'] = chqUnmatched.company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "companyMatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(companyMatches.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,companyMatches.shape[0]):\n",
    "    # print(list(np.array(hq.company)[largestElements[i]]))\n",
    "    companyMatches.at[i,'closestMatch'] = np.array(hq.company)[largestElements[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "companyMatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "companyMatches.to_csv(\"../../data/companyData/closestMatch.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Other ideas here: try out the levenshtein distance; try to match just on the first word"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
