{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import os\n",
    "import re\n",
    "\n",
    "import scipy\n",
    "\n",
    "import collections\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "import geopandas as gpd\n",
    "\n",
    "import numpy as np\n",
    " \n",
    "from difflib import get_close_matches\n",
    "\n",
    "from fuzzywuzzy import process\n",
    "from fuzzywuzzy import fuzz\n",
    "from sklearn import linear_model\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from linearmodels import PanelOLS, FamaMacBeth\n",
    "from scipy import stats\n",
    "\n",
    "import itertools\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from numpy.linalg import matrix_rank\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makePlots(results, industries, filePrefix, yLim, numCol = 2, padding = 1, xdim = 20, ydim = 40):\n",
    "    \n",
    "    # loop over outcome variables and weather definitions\n",
    "    weatherVars = results.weatherVar.unique()\n",
    "    outcomeVars = results.outcomeVar.unique()\n",
    "\n",
    "\n",
    "    for outcome in outcomeVars:\n",
    "        for weather in weatherVars:\n",
    "            # choose the elective parts of this - number of columns and the range of the axes\n",
    "            numCols = numCol\n",
    "            yLims   = yLim\n",
    "\n",
    "            rowNum = len(industries) // numCols + padding\n",
    "            colNum = numCols\n",
    "\n",
    "            fig, ax = plt.subplots(rowNum, colNum, sharex='all', sharey='all',\n",
    "                                  figsize=(xdim,ydim),\n",
    "                                  constrained_layout=True)\n",
    "\n",
    "            fig.suptitle('Direct Effects: ' + outcome + ' ~ ' + weather, fontsize=36)\n",
    "\n",
    "\n",
    "\n",
    "            i = 0\n",
    "            for ind in industries:\n",
    "                rowIndex = i // numCols \n",
    "                colIndex = i % numCols\n",
    "\n",
    "\n",
    "                i   = i + 1\n",
    "\n",
    "\n",
    "                rev = results[(results.outcomeVar == outcome) & (results.weatherVar == weather) & \n",
    "                             (results.industry == ind)].reset_index()\n",
    "                # indName = rev.industryName.unique()[0]\n",
    "                x   = [0,1,2,3,4]\n",
    "                y   = [rev.lag0,rev.lag1,rev.lag2,rev.lag3,rev.lag4]\n",
    "\n",
    "\n",
    "                errors = [rev.bse0,rev.bse1,rev.bse2,rev.bse3,rev.bse4]\n",
    "\n",
    "\n",
    "                ax[rowIndex, colIndex].errorbar(x,y,yerr = errors, fmt = '.k')\n",
    "                ax[rowIndex, colIndex].xaxis.grid(False)\n",
    "                ax[rowIndex, colIndex].yaxis.grid(False)\n",
    "                ax[rowIndex, colIndex].axhline(y=0)\n",
    "                ax[rowIndex, colIndex].set_ylim([-yLims, yLims])\n",
    "\n",
    "                ax[rowIndex, colIndex].yaxis.set_ticks(np.arange(-yLims, yLims + yLims, yLims/2))\n",
    "                ax[rowIndex, colIndex].xaxis.set_ticks(np.arange(0.0, 5.0, 1.0))\n",
    "\n",
    "                ax[rowIndex, colIndex].tick_params(axis='both', labelsize = 16)\n",
    "                ax[rowIndex, colIndex].set_title(ind, fontsize = 24)\n",
    "\n",
    "            fig.savefig(filePrefix + outcome + weather + '.png')\n",
    "            fig.show()\n",
    "\n",
    "\n",
    "                # ax[rowIndex, colIndex].\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots\n",
    "All direct effects - as result of number of days of extremes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_csv(\"../../allIndustryResults.csv\").drop(columns = {'Unnamed: 0'})\n",
    "industries = results.industry.unique()\n",
    "yLim   = 0.01\n",
    "numCol = 3\n",
    "padding = 1\n",
    "xdim = 20\n",
    "ydim = 40\n",
    "filePrefix = 'dirEffects'\n",
    "\n",
    "makePlots(results, industries, filePrefix, yLim)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grab Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/brianreed/Documents/supplyChain/extremes/extremesAnalysisCode'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brianreed/opt/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3326: DtypeWarning: Columns (15) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60807, 873)\n"
     ]
    }
   ],
   "source": [
    "goodsData = pd.read_csv(\"../../data/companyData/goodsData_igData.csv\").drop(columns = {'Unnamed: 0'})\n",
    "goodsData = goodsData.rename(columns = {'precip_zipQuarterquant_0.95': 'precip_zipQuarterquant_Extreme',\n",
    "                                        'lag1_precip_zipQuarterquant_0.95': 'lag1_precip_zipQuarterquant_Extreme',\n",
    "                                        'lag2_precip_zipQuarterquant_0.95': 'lag2_precip_zipQuarterquant_Extreme',\n",
    "                                        'lag3_precip_zipQuarterquant_0.95': 'lag3_precip_zipQuarterquant_Extreme',\n",
    "                    'precip_annualquant_0.95': 'precip_annualquant_Extreme',\n",
    "                                        'lag1_precip_annualquant_0.95': 'lag1_precip_annualquant_Extreme',\n",
    "                                        'lag2_precip_annualquant_0.95': 'lag2_precip_annualquant_Extreme',\n",
    "                                        'lag3_precip_annualquant_0.95': 'lag3_precip_annualquant_Extreme',\n",
    "                    'precip5Days_zipQuarterquant_0.95': 'precip5Days_zipQuarterquant_Extreme',\n",
    "                                       'lag1_precip5Days_zipQuarterquant_0.95': 'lag1_precip5Days_zipQuarterquant_Extreme',\n",
    "                                       'lag2_precip5Days_zipQuarterquant_0.95': 'lag2_precip5Days_zipQuarterquant_Extreme',\n",
    "                                       'lag3_precip5Days_zipQuarterquant_0.95': 'lag3_precip5Days_zipQuarterquant_Extreme',\n",
    "                    'temp_zipQuarterquant_0.95': 'temp_zipQuarterquant_Extreme',\n",
    "                                       'lag1_temp_zipQuarterquant_0.95': 'lag1_temp_zipQuarterquant_Extreme',\n",
    "                                       'lag2_temp_zipQuarterquant_0.95': 'lag2_temp_zipQuarterquant_Extreme',\n",
    "                                       'lag3_temp_zipQuarterquant_0.95': 'lag3_temp_zipQuarterquant_Extreme',\n",
    "                    'temp5Days_zipQuarterquant_0.95': 'temp5Days_zipQuarterquant_Extreme',\n",
    "                                       'lag1_temp5Days_zipQuarterquant_0.95': 'lag1_temp5Days_zipQuarterquant_Extreme',\n",
    "                                       'lag2_temp5Days_zipQuarterquant_0.95': 'lag2_temp5Days_zipQuarterquant_Extreme',\n",
    "                                       'lag3_temp5Days_zipQuarterquant_0.95': 'lag3_temp5Days_zipQuarterquant_Extreme',\n",
    "                    'temp_annualquant_0.95': 'temp_annualquant_Extreme',\n",
    "                                       'lag1_temp_annualquant_0.95': 'lag1_temp_annualquant_Extreme',\n",
    "                                       'lag2_temp_annualquant_0.95': 'lag2_temp_annualquant_Extreme',\n",
    "                                       'lag3_temp_annualquant_0.95': 'lag3_temp_annualquant_Extreme',\n",
    "                    'empWt_temp_zipQuarterquant_0.95': 'empWt_temp_zipQuarterquant_Extreme',\n",
    "                                        'empWt_lag1_temp_zipQuarterquant_0.95': 'empWt_lag1_temp_zipQuarterquant_Extreme',\n",
    "                                        'empWt_lag2_temp_zipQuarterquant_0.95': 'empWt_lag2_temp_zipQuarterquant_Extreme',\n",
    "                                        'empWt_lag3_temp_zipQuarterquant_0.95': 'empWt_lag3_temp_zipQuarterquant_Extreme'\n",
    "                                       })\n",
    "print(goodsData.shape)\n",
    "\n",
    "firms = goodsData['gvkey']\n",
    "\n",
    "goodsData = goodsData[~goodsData.lnRev.isna() & ~goodsData.lnCost.isna()] # & ~goodsData.lnCostNormd.isna()]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Direct Effects\n",
    "Look at the effects on the suppliers when they're affected directly.\n",
    "\n",
    "## Complete Dataset\n",
    "### At HQs\n",
    "\n",
    "The below gives us the full, clustered standard errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, do the basics: days of extreme precipitation and (separately) extreme temperature, with 3 lags. We include a balance of time and industry-specific controls, fewer than are in the other regressions but generally allowing for a time trend, firm-specific trends, industry-seasonal trends, and profit, size, and age characteristics. We don't have time-specific trends across firms or industries but it's not clear that these would really change over the 10 years of the sample.\n",
    "\n",
    "\n",
    "\n",
    "There are a couple of background facts that I'm relying on here: \n",
    "- the 1x year, 1x5 years, etc variables might be too rare to really pick up an effect.\n",
    "- it's possible that lower tiers, or less extreme extremes, might matter too. may want to try to pick up a lower threshold as well. \n",
    "- the normalized variables (divided by lagged assets) seem to be more sensitive / response than just growth and just log-levels. this is likely because of something like the fact that this helps equalize for differences in the size of the firms in a way that neither log nor growth does. \n",
    "\n",
    "\n",
    "\n",
    "there are a couple of things to remember with these results:\n",
    "- the company size/age/profitability terciles don't make a lick of difference\n",
    "- precipitation seems to matter, period, for cumulative number of days\n",
    "- temperature might need a longer streak for the effect to happen\n",
    "\n",
    "\n",
    "\n",
    "a few things come out more in the heterogeneity analyses:\n",
    "- it seems like the local-relative extremes matter especially at the upper ends of the distributions. this is a little counterintuitive but i think the story is something like the following: we expect that places with higher average temperatures would have higher ''95th percentile events'', and places with lower average temperatures might have lower ''95th percentile events'', that might actually not be that extreme. \n",
    "- we would expect the heatBin:extremeTemp(Precip) measure to show an opposite result if the extreme definition is an absolute one and not a relative one (larger effect in places with lower normal temps (precip) // lower effect in places with higher normal temps (precip)) because it's closer to their baseline & closer to what they might expect.\n",
    "- there's not much with the industry-specific results? it could be that the data are currently too diffuse or too small to really \n",
    "\n",
    "\n",
    "\n",
    "questions:\n",
    "- are there other moments of distributions or other ways to measure shifts in extremes?\n",
    "- how should i best approach the industry-specific regressions? - separate regressions or interaction terms?\n",
    "- what mechanisms should i consider? bs consider the role of \"input specificity\", as judged by patents or r&d. ps consider a few different ones: materiality, defined by value of physical assets/value of total assets; industry specificity; and expectation. \n",
    "    - are there any \"climate mechanisms\" i can examine here, other than just expectations?\n",
    "    - how can we adapt or incorporate the scc here?\n",
    "\n",
    "\n",
    "\n",
    "things to push forward on:\n",
    "- targeting specific industries: either with different lag tiers, or with \n",
    "- indirect regressions!\n",
    "- stock regressions\n",
    "- extreme convective storms\n",
    "- counts in disclosures\n",
    "\n",
    "\n",
    "\n",
    "things that are probably very relevant that i should keep experimenting with:\n",
    "- measures of concentration: establishment weights, percent of firm w/in 10% (or honestly 70%+) of hq\n",
    "- extreme temp as 90+, maybe some flood-relative measure of extreme rain?\n",
    "\n",
    "\n",
    "First, total days of heat and rain.\n",
    "\n",
    "\n",
    "\n",
    "*AT SOME POINT, WE CAN ADD ADDTL COLUMNS FOR OTHER VARIABLES OF INTEREST TO THIS AS WELL: cost & profit, maybe also stocks [if we do a quarter before, quarter after] thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107.34912300109863\n",
      "                                       coeffs     pvals\n",
      "precip_zipQuarterquant_Extreme      -0.002074  0.001179\n",
      "lag1_precip_zipQuarterquant_Extreme -0.001398  0.029075\n",
      "lag2_precip_zipQuarterquant_Extreme -0.001086  0.089402\n",
      "lag3_precip_zipQuarterquant_Extreme -0.001152  0.072004\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "\n",
    "precipMod = smf.ols(formula = 'lnRevNormd ~ precip_zipQuarterquant_Extreme + lag1_precip_zipQuarterquant_Extreme + lag2_precip_zipQuarterquant_Extreme + lag3_precip_zipQuarterquant_Extreme + C(indGroup):C(qtr) + C(yearQtr) + C(gvkey) + C(ageTercile) + C(profitTercile) + C(sizeTercile)', data = goodsData).fit()\n",
    "\n",
    "print(time.time() - start) \n",
    "\n",
    "# convert this into a much more condensed version\n",
    "coeffs = pd.DataFrame(precipMod.params,   columns = ['coeffs'])\n",
    "pvalues = pd.DataFrame(precipMod.pvalues, columns = ['pvals'])\n",
    "\n",
    "coeffs = coeffs[coeffs.index.str.contains('precip')]\n",
    "pvalues = pvalues[pvalues.index.str.contains('precip')]\n",
    "\n",
    "results = pd.concat([coeffs,pvalues],axis = 1)\n",
    "\n",
    "\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105.9068820476532\n",
      "                                     coeffs     pvals\n",
      "temp_zipQuarterquant_Extreme       0.000386  0.362568\n",
      "lag1_temp_zipQuarterquant_Extreme  0.000512  0.234403\n",
      "lag2_temp_zipQuarterquant_Extreme  0.000434  0.305695\n",
      "lag3_temp_zipQuarterquant_Extreme  0.001207  0.003906\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "\n",
    "tempMod = smf.ols(formula = 'lnRevNormd ~ temp_zipQuarterquant_Extreme + lag1_temp_zipQuarterquant_Extreme + lag2_temp_zipQuarterquant_Extreme + lag3_temp_zipQuarterquant_Extreme + C(indGroup):C(qtr) + C(yearQtr) + C(gvkey) + C(ageTercile) + C(profitTercile) + C(sizeTercile)', data = goodsData).fit()\n",
    "\n",
    "print(time.time() - start) \n",
    "\n",
    "# convert this into a much more condensed version\n",
    "coeffs = pd.DataFrame(tempMod.params,   columns = ['coeffs'])\n",
    "pvalues = pd.DataFrame(tempMod.pvalues, columns = ['pvals'])\n",
    "\n",
    "coeffs = coeffs[coeffs.index.str.contains('temp')]\n",
    "pvalues = pvalues[pvalues.index.str.contains('temp')]\n",
    "\n",
    "results = pd.concat([coeffs,pvalues],axis = 1)\n",
    "\n",
    "\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at \"sustained\" heat and rain. We can look at incidence of a heatwave or sustained temperatures above a given amount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102.49911689758301\n",
      "                                            coeffs     pvals\n",
      "precip5Days_zipQuarterquant_Extreme      -0.001207  0.136952\n",
      "lag1_precip5Days_zipQuarterquant_Extreme -0.001510  0.062159\n",
      "lag2_precip5Days_zipQuarterquant_Extreme -0.000606  0.453068\n",
      "lag3_precip5Days_zipQuarterquant_Extreme -0.001582  0.049325\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "\n",
    "precip5DaysMod = smf.ols(formula = 'lnRevNormd ~ precip5Days_zipQuarterquant_Extreme + lag1_precip5Days_zipQuarterquant_Extreme + lag2_precip5Days_zipQuarterquant_Extreme + lag3_precip5Days_zipQuarterquant_Extreme + C(indGroup):C(qtr) + C(yearQtr) + C(gvkey) + C(ageTercile) + C(profitTercile) + C(sizeTercile)', data = goodsData).fit()\n",
    "\n",
    "print(time.time() - start) \n",
    "\n",
    "# convert this into a much more condensed version\n",
    "coeffs = pd.DataFrame(precip5DaysMod.params,   columns = ['coeffs'])\n",
    "pvalues = pd.DataFrame(precip5DaysMod.pvalues, columns = ['pvals'])\n",
    "\n",
    "coeffs = coeffs[coeffs.index.str.contains('precip')]\n",
    "pvalues = pvalues[pvalues.index.str.contains('precip')]\n",
    "\n",
    "results = pd.concat([coeffs,pvalues],axis = 1)\n",
    "\n",
    "\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105.95902276039124\n",
      "                                          coeffs     pvals\n",
      "temp5Days_zipQuarterquant_Extreme      -0.001796  0.101108\n",
      "lag1_temp5Days_zipQuarterquant_Extreme -0.002152  0.050241\n",
      "lag2_temp5Days_zipQuarterquant_Extreme -0.003043  0.006116\n",
      "lag3_temp5Days_zipQuarterquant_Extreme -0.000803  0.468141\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "\n",
    "temp5DaysMod = smf.ols(formula = 'lnRevNormd ~ temp5Days_zipQuarterquant_Extreme + lag1_temp5Days_zipQuarterquant_Extreme + lag2_temp5Days_zipQuarterquant_Extreme + lag3_temp5Days_zipQuarterquant_Extreme + C(indGroup):C(qtr) + C(yearQtr) + C(gvkey) + C(ageTercile) + C(profitTercile) + C(sizeTercile)', data = goodsData).fit()\n",
    "\n",
    "print(time.time() - start) \n",
    "\n",
    "# convert this into a much more condensed version\n",
    "coeffs  = pd.DataFrame(temp5DaysMod.params,  columns = ['coeffs'])\n",
    "pvalues = pd.DataFrame(temp5DaysMod.pvalues, columns = ['pvals'])\n",
    "\n",
    "coeffs  = coeffs[coeffs.index.str.contains('temp')]\n",
    "pvalues = pvalues[pvalues.index.str.contains('temp')]\n",
    "\n",
    "results = pd.concat([coeffs,pvalues],axis = 1)\n",
    "\n",
    "\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breakouts by tercile\n",
    "\n",
    "See how the effect varies in places that are background hot // background wet.\n",
    "\n",
    "Sort of inspired by the BS2016 tercile approach, we divide each place into terciles. I THINK (double check this) that this is based on annual average temperature and precipitation. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105.90068006515503\n",
      "                                                      coeffs     pvals\n",
      "C(precipTercile)[T.2]                               0.049555  0.057615\n",
      "C(precipTercile)[T.3]                               0.074487  0.006760\n",
      "precip_zipQuarterquant_Extreme                     -0.001436  0.136472\n",
      "C(precipTercile)[T.2]:precip_zipQuarterquant_Ex...  0.000104  0.944961\n",
      "C(precipTercile)[T.3]:precip_zipQuarterquant_Ex... -0.001781  0.230543\n",
      "lag1_precip_zipQuarterquant_Extreme                 0.000706  0.464992\n",
      "C(precipTercile)[T.2]:lag1_precip_zipQuarterqua... -0.003525  0.017027\n",
      "C(precipTercile)[T.3]:lag1_precip_zipQuarterqua... -0.003745  0.012471\n",
      "lag2_precip_zipQuarterquant_Extreme                -0.000563  0.562460\n",
      "C(precipTercile)[T.2]:lag2_precip_zipQuarterqua...  0.000806  0.576831\n",
      "C(precipTercile)[T.3]:lag2_precip_zipQuarterqua... -0.001887  0.218126\n",
      "lag3_precip_zipQuarterquant_Extreme                -0.000554  0.563287\n",
      "C(precipTercile)[T.2]:lag3_precip_zipQuarterqua... -0.002214  0.142305\n",
      "C(precipTercile)[T.3]:lag3_precip_zipQuarterqua...  0.000176  0.908015\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "\n",
    "precipModTercile = smf.ols(formula = 'lnRevNormd ~ C(precipTercile)*(precip_zipQuarterquant_Extreme + lag1_precip_zipQuarterquant_Extreme + lag2_precip_zipQuarterquant_Extreme + lag3_precip_zipQuarterquant_Extreme) + C(indGroup):C(qtr) + C(yearQtr) + C(gvkey) + C(ageTercile) + C(profitTercile) + C(sizeTercile)', data = goodsData).fit()\n",
    "\n",
    "print(time.time() - start) \n",
    "\n",
    "# convert this into a much more condensed version\n",
    "coeffs  = pd.DataFrame(precipModTercile.params,  columns = ['coeffs'])\n",
    "pvalues = pd.DataFrame(precipModTercile.pvalues, columns = ['pvals'])\n",
    "\n",
    "coeffs  = coeffs[coeffs.index.str.contains('precip')]\n",
    "pvalues = pvalues[pvalues.index.str.contains('precip')]\n",
    "\n",
    "results = pd.concat([coeffs,pvalues],axis = 1)\n",
    "\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110.59080696105957\n",
      "                                                      coeffs     pvals\n",
      "C(tempTercile)[T.2]                                -0.037440  0.061516\n",
      "C(tempTercile)[T.3]                                -0.011779  0.599312\n",
      "temp_zipQuarterquant_Extreme                       -0.000425  0.638552\n",
      "C(tempTercile)[T.2]:temp_zipQuarterquant_Extreme    0.001445  0.217247\n",
      "C(tempTercile)[T.3]:temp_zipQuarterquant_Extreme    0.000868  0.420447\n",
      "lag1_temp_zipQuarterquant_Extreme                   0.001015  0.241426\n",
      "C(tempTercile)[T.2]:lag1_temp_zipQuarterquant_E... -0.000301  0.769986\n",
      "C(tempTercile)[T.3]:lag1_temp_zipQuarterquant_E... -0.001074  0.340839\n",
      "lag2_temp_zipQuarterquant_Extreme                   0.000820  0.293456\n",
      "C(tempTercile)[T.2]:lag2_temp_zipQuarterquant_E... -0.000932  0.350436\n",
      "C(tempTercile)[T.3]:lag2_temp_zipQuarterquant_E...  0.000232  0.835740\n",
      "lag3_temp_zipQuarterquant_Extreme                  -0.000423  0.628594\n",
      "C(tempTercile)[T.2]:lag3_temp_zipQuarterquant_E...  0.003232  0.002360\n",
      "C(tempTercile)[T.3]:lag3_temp_zipQuarterquant_E...  0.001051  0.329372\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "\n",
    "tempModTercile = smf.ols(formula = 'lnRevNormd ~ C(tempTercile)*(temp_zipQuarterquant_Extreme + lag1_temp_zipQuarterquant_Extreme + lag2_temp_zipQuarterquant_Extreme + lag3_temp_zipQuarterquant_Extreme) + C(indGroup):C(qtr) + C(yearQtr) + C(gvkey) + C(ageTercile) + C(profitTercile) + C(sizeTercile)', data = goodsData).fit()\n",
    "\n",
    "print(time.time() - start) \n",
    "\n",
    "# convert this into a much more condensed version\n",
    "coeffs  = pd.DataFrame(tempModTercile.params,  columns = ['coeffs'])\n",
    "pvalues = pd.DataFrame(tempModTercile.pvalues, columns = ['pvals'])\n",
    "\n",
    "coeffs  = coeffs[coeffs.index.str.contains('temp')]\n",
    "pvalues = pvalues[pvalues.index.str.contains('temp')]\n",
    "\n",
    "results = pd.concat([coeffs,pvalues],axis = 1)\n",
    "\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try the sustained effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105.98802304267883\n",
      "                                                      coeffs     pvals\n",
      "C(precipTercile)[T.2]                               0.009927  0.549393\n",
      "C(precipTercile)[T.3]                              -0.004962  0.777395\n",
      "precip5Days_zipQuarterquant_Extreme                -0.000844  0.449366\n",
      "C(precipTercile)[T.2]:precip5Days_zipQuarterqua... -0.001808  0.187008\n",
      "C(precipTercile)[T.3]:precip5Days_zipQuarterqua...  0.000621  0.648737\n",
      "lag1_precip5Days_zipQuarterquant_Extreme           -0.002311  0.046708\n",
      "C(precipTercile)[T.2]:lag1_precip5Days_zipQuart...  0.001632  0.273114\n",
      "C(precipTercile)[T.3]:lag1_precip5Days_zipQuart...  0.000793  0.591631\n",
      "lag2_precip5Days_zipQuarterquant_Extreme           -0.001094  0.353321\n",
      "C(precipTercile)[T.2]:lag2_precip5Days_zipQuart...  0.001613  0.276528\n",
      "C(precipTercile)[T.3]:lag2_precip5Days_zipQuart... -0.000201  0.893416\n",
      "lag3_precip5Days_zipQuarterquant_Extreme           -0.000961  0.390169\n",
      "C(precipTercile)[T.2]:lag3_precip5Days_zipQuart... -0.001928  0.157934\n",
      "C(precipTercile)[T.3]:lag3_precip5Days_zipQuart...  0.000003  0.998121\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "\n",
    "precip5DaysModTercile = smf.ols(formula = 'lnRevNormd ~ C(precipTercile)*(precip5Days_zipQuarterquant_Extreme + lag1_precip5Days_zipQuarterquant_Extreme + lag2_precip5Days_zipQuarterquant_Extreme + lag3_precip5Days_zipQuarterquant_Extreme) + C(indGroup):C(qtr) + C(yearQtr) + C(gvkey) + C(ageTercile) + C(profitTercile) + C(sizeTercile)', data = goodsData).fit()\n",
    "\n",
    "print(time.time() - start) \n",
    "\n",
    "# convert this into a much more condensed version\n",
    "coeffs  = pd.DataFrame(precip5DaysModTercile.params,  columns = ['coeffs'])\n",
    "pvalues = pd.DataFrame(precip5DaysModTercile.pvalues, columns = ['pvals'])\n",
    "\n",
    "coeffs  = coeffs[coeffs.index.str.contains('precip')]\n",
    "pvalues = pvalues[pvalues.index.str.contains('precip')]\n",
    "\n",
    "results = pd.concat([coeffs,pvalues],axis = 1)\n",
    "\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103.5402500629425\n",
      "                                                      coeffs     pvals\n",
      "C(tempTercile)[T.2]                                -0.037943  0.004561\n",
      "C(tempTercile)[T.3]                                -0.049328  0.013328\n",
      "temp5Days_zipQuarterquant_Extreme                  -0.002586  0.045335\n",
      "C(tempTercile)[T.2]:temp5Days_zipQuarterquant_E...  0.001072  0.273194\n",
      "C(tempTercile)[T.3]:temp5Days_zipQuarterquant_E...  0.001028  0.456556\n",
      "lag1_temp5Days_zipQuarterquant_Extreme             -0.003903  0.005098\n",
      "C(tempTercile)[T.2]:lag1_temp5Days_zipQuarterqu...  0.001772  0.174366\n",
      "C(tempTercile)[T.3]:lag1_temp5Days_zipQuarterqu...  0.003443  0.034688\n",
      "lag2_temp5Days_zipQuarterquant_Extreme             -0.001324  0.362130\n",
      "C(tempTercile)[T.2]:lag2_temp5Days_zipQuarterqu... -0.002912  0.046377\n",
      "C(tempTercile)[T.3]:lag2_temp5Days_zipQuarterqu... -0.002137  0.206312\n",
      "lag3_temp5Days_zipQuarterquant_Extreme             -0.002867  0.031902\n",
      "C(tempTercile)[T.2]:lag3_temp5Days_zipQuarterqu...  0.003563  0.001133\n",
      "C(tempTercile)[T.3]:lag3_temp5Days_zipQuarterqu...  0.002354  0.098311\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "\n",
    "temp5DaysModTercile = smf.ols(formula = 'lnRevNormd ~ C(tempTercile)*(temp5Days_zipQuarterquant_Extreme + lag1_temp5Days_zipQuarterquant_Extreme + lag2_temp5Days_zipQuarterquant_Extreme + lag3_temp5Days_zipQuarterquant_Extreme) + C(indGroup):C(qtr) + C(yearQtr) + C(gvkey) + C(ageTercile) + C(profitTercile) + C(sizeTercile)', data = goodsData).fit()\n",
    "\n",
    "print(time.time() - start) \n",
    "\n",
    "# convert this into a much more condensed version\n",
    "coeffs  = pd.DataFrame(temp5DaysModTercile.params,  columns = ['coeffs'])\n",
    "pvalues = pd.DataFrame(temp5DaysModTercile.pvalues, columns = ['pvals'])\n",
    "\n",
    "coeffs  = coeffs[coeffs.index.str.contains('temp')]\n",
    "pvalues = pvalues[pvalues.index.str.contains('temp')]\n",
    "\n",
    "results = pd.concat([coeffs,pvalues],axis = 1)\n",
    "\n",
    "\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temperature\n",
    "It seems like we're getting a pretty strong signal on precipitation: more precipitation is bad, and it's bad even (especially?) in places where background level of precipitation is high, maybe because the most extreme tail of it is that much more extreme in these places. We have a little bit more work to do with temperature. \n",
    "\n",
    "From the above, we find the following:\n",
    "    - Temperature does NOT seem to matter on a 1-day fluctuation basis. \n",
    "    - Temperature DOES seem to matter on a 5-day moving average case.\n",
    "    \n",
    "We can seem to look at the following:\n",
    "    - Total days above 90F (another extreme; maybe interact with quartiles of avg temperature too)\n",
    "    - Y/N for whether there was a 7-day streak above 90F, matching PS.\n",
    "    - Weeks, months, qtr at different t'hold\n",
    "        - Maybe try different bins as well.\n",
    "\n",
    "\n",
    "First, try the total number of days that are at least 90F. Weird result is that more days above 90 is associated with better results here. REVISIT THIS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107.82512164115906\n",
      "                   coeffs     pvals\n",
      "days90Plus       0.000883  0.002083\n",
      "lag1_days90Plus  0.000794  0.005429\n",
      "lag2_days90Plus  0.000655  0.022759\n",
      "lag3_days90Plus  0.000818  0.004621\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "\n",
    "tempDaysAbove90Mod = smf.ols(formula = 'lnRevNormd ~ days90Plus + lag1_days90Plus + lag2_days90Plus + lag3_days90Plus + C(indGroup):C(qtr) + C(yearQtr) + C(gvkey) + C(ageTercile) + C(profitTercile) + C(sizeTercile)', data = goodsData).fit()\n",
    "\n",
    "print(time.time() - start) \n",
    "\n",
    "# convert this into a much more condensed version\n",
    "coeffs  = pd.DataFrame(tempDaysAbove90Mod.params,  columns = ['coeffs'])\n",
    "pvalues = pd.DataFrame(tempDaysAbove90Mod.pvalues, columns = ['pvals'])\n",
    "\n",
    "coeffs  = coeffs[coeffs.index.str.contains('days90')]\n",
    "pvalues = pvalues[pvalues.index.str.contains('days90')]\n",
    "\n",
    "results = pd.concat([coeffs,pvalues],axis = 1)\n",
    "\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look at the breakdown by days that are normally below, at, or above average, we see the strongest result is in places that are normally below average. This is a drop of almost 4\\%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94.70704102516174\n",
      "                                       coeffs     pvals\n",
      "days90Plus                          -0.039787  0.013798\n",
      "C(tempTercile)[T.2]:days90Plus       0.040358  0.012655\n",
      "C(tempTercile)[T.3]:days90Plus       0.040573  0.012013\n",
      "lag1_days90Plus                      0.000852  0.111201\n",
      "C(tempTercile)[T.2]:lag1_days90Plus -0.000152  0.768731\n",
      "C(tempTercile)[T.3]:lag1_days90Plus  0.000278  0.666997\n",
      "lag2_days90Plus                     -0.000130  0.827730\n",
      "C(tempTercile)[T.2]:lag2_days90Plus  0.000950  0.158896\n",
      "C(tempTercile)[T.3]:lag2_days90Plus  0.000717  0.395120\n",
      "lag3_days90Plus                      0.002621  0.058465\n",
      "C(tempTercile)[T.2]:lag3_days90Plus -0.001893  0.203349\n",
      "C(tempTercile)[T.3]:lag3_days90Plus -0.001692  0.227867\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "\n",
    "tempDaysAbove90Mod = smf.ols(formula = 'lnRevNormd ~ C(tempTercile)*(days90Plus + lag1_days90Plus + lag2_days90Plus + lag3_days90Plus) + C(indGroup):C(qtr) + C(yearQtr) + C(gvkey) + C(ageTercile) + C(profitTercile) + C(sizeTercile)', data = goodsData).fit()\n",
    "\n",
    "print(time.time() - start) \n",
    "\n",
    "coeffs  = pd.DataFrame(tempDaysAbove90Mod.params,  columns = ['coeffs'])\n",
    "pvalues = pd.DataFrame(tempDaysAbove90Mod.pvalues, columns = ['pvals'])\n",
    "\n",
    "coeffs  = coeffs[coeffs.index.str.contains('days90')]\n",
    "pvalues = pvalues[pvalues.index.str.contains('days90')]\n",
    "\n",
    "results = pd.concat([coeffs,pvalues],axis = 1)\n",
    "\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try the same things by streaks. The effect sizes are large, but not statistically significantly estimated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119.95602703094482\n",
      "                     coeffs     pvals\n",
      "streak90Plus      -0.021078  0.238399\n",
      "lag1_streak90Plus -0.011678  0.511472\n",
      "lag2_streak90Plus -0.008739  0.624497\n",
      "lag3_streak90Plus -0.001942  0.913540\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "\n",
    "tempStreakAbove90Mod = smf.ols(formula = 'lnRevNormd ~ streak90Plus + lag1_streak90Plus + lag2_streak90Plus + lag3_streak90Plus + C(indGroup):C(qtr) + C(yearQtr) + C(gvkey) + C(ageTercile) + C(profitTercile) + C(sizeTercile)', data = goodsData).fit()\n",
    "\n",
    "print(time.time() - start) \n",
    "\n",
    "coeffs  = pd.DataFrame(tempStreakAbove90Mod.params,  columns = ['coeffs'])\n",
    "pvalues = pd.DataFrame(tempStreakAbove90Mod.pvalues, columns = ['pvals'])\n",
    "\n",
    "coeffs  = coeffs[coeffs.index.str.contains('streak90')]\n",
    "pvalues = pvalues[pvalues.index.str.contains('streak90')]\n",
    "\n",
    "results = pd.concat([coeffs,pvalues],axis = 1)\n",
    "\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113.52526903152466\n",
      "                                         coeffs     pvals\n",
      "streak90Plus                          -0.028383  0.353261\n",
      "C(tempTercile)[T.2]:streak90Plus      -0.000389  0.993034\n",
      "C(tempTercile)[T.3]:streak90Plus       0.016328  0.702954\n",
      "lag1_streak90Plus                      0.010102  0.740533\n",
      "C(tempTercile)[T.2]:lag1_streak90Plus -0.035661  0.404653\n",
      "C(tempTercile)[T.3]:lag1_streak90Plus -0.034964  0.428799\n",
      "lag2_streak90Plus                      0.046157  0.129009\n",
      "C(tempTercile)[T.2]:lag2_streak90Plus -0.047172  0.296078\n",
      "C(tempTercile)[T.3]:lag2_streak90Plus -0.111516  0.008230\n",
      "lag3_streak90Plus                      0.015551  0.605256\n",
      "C(tempTercile)[T.2]:lag3_streak90Plus -0.039146  0.371044\n",
      "C(tempTercile)[T.3]:lag3_streak90Plus -0.022306  0.604505\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "\n",
    "tempStreakAbove90Mod_intxn = smf.ols(formula = 'lnRevNormd ~  C(tempTercile)*(streak90Plus + lag1_streak90Plus + lag2_streak90Plus + lag3_streak90Plus) + C(indGroup):C(qtr) + C(yearQtr) + C(gvkey) + C(ageTercile) + C(profitTercile) + C(sizeTercile)', data = goodsData).fit()\n",
    "\n",
    "print(time.time() - start) \n",
    "\n",
    "coeffs  = pd.DataFrame(tempStreakAbove90Mod_intxn.params,  columns = ['coeffs'])\n",
    "pvalues = pd.DataFrame(tempStreakAbove90Mod_intxn.pvalues, columns = ['pvals'])\n",
    "\n",
    "coeffs  = coeffs[coeffs.index.str.contains('streak90')]\n",
    "pvalues = pvalues[pvalues.index.str.contains('streak90')]\n",
    "\n",
    "results = pd.concat([coeffs,pvalues],axis = 1)\n",
    "\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try the things by weeks, month, quarter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116.61620664596558\n",
      "                          coeffs     pvals\n",
      "temp_zipWeek95_99       0.002928  0.125013\n",
      "lag1_temp_zipWeek95_99  0.002965  0.127086\n",
      "lag2_temp_zipWeek95_99  0.002855  0.138335\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "#  + lag1_temp_zipWeek95_99 + lag2_temp_zipWeek95_99 + lag3_temp_zipWeek95_99\n",
    "# \n",
    "\n",
    "tempWeekMod = smf.ols(formula = 'lnRevNormd ~  (temp_zipWeek95_99 + lag1_temp_zipWeek95_99 + lag2_temp_zipWeek95_99 ) + C(indGroup):C(qtr) + C(yearQtr) + C(gvkey) + C(ageTercile) + C(profitTercile) + C(sizeTercile)', data = goodsData).fit()\n",
    "\n",
    "print(time.time() - start) \n",
    "\n",
    "coeffs  = pd.DataFrame(tempWeekMod.params,  columns = ['coeffs'])\n",
    "pvalues = pd.DataFrame(tempWeekMod.pvalues, columns = ['pvals'])\n",
    "\n",
    "coeffs  = coeffs[coeffs.index.str.contains('temp')]\n",
    "pvalues = pvalues[pvalues.index.str.contains('temp')]\n",
    "\n",
    "results = pd.concat([coeffs,pvalues],axis = 1)\n",
    "\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we break this down by the background temperature of the place, though, it seems like we find a similar effect in the coldest places: a warm week in the coldest places is the most negative, in the quarter concurrent with when it's warmest.\n",
    "\n",
    "\n",
    "[is this the same effect? other places, did we not see a positive effect of slightly warmer weather in cooler places?]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110.50980377197266\n",
      "                                              coeffs     pvals\n",
      "C(tempTercile)[T.2]                        -0.006719  0.624232\n",
      "C(tempTercile)[T.3]                        -0.003850  0.825409\n",
      "temp_zipWeek95_99                          -0.006341  0.106442\n",
      "C(tempTercile)[T.2]:temp_zipWeek95_99       0.012628  0.012025\n",
      "C(tempTercile)[T.3]:temp_zipWeek95_99       0.011278  0.020001\n",
      "lag1_temp_zipWeek95_99                      0.003608  0.342254\n",
      "C(tempTercile)[T.2]:lag1_temp_zipWeek95_99 -0.002525  0.603116\n",
      "C(tempTercile)[T.3]:lag1_temp_zipWeek95_99  0.000892  0.857246\n",
      "lag2_temp_zipWeek95_99                      0.005767  0.102441\n",
      "C(tempTercile)[T.2]:lag2_temp_zipWeek95_99 -0.000077  0.986818\n",
      "C(tempTercile)[T.3]:lag2_temp_zipWeek95_99 -0.007942  0.105213\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "#  + lag1_temp_zipWeek95_99 + lag2_temp_zipWeek95_99 + lag3_temp_zipWeek95_99\n",
    "# + C(ageTercile) + C(profitTercile) + C(sizeTercile)\n",
    "\n",
    "tempWeekMod_intxn = smf.ols(formula = 'lnRevNormd ~  C(tempTercile)*(temp_zipWeek95_99 + lag1_temp_zipWeek95_99 + lag2_temp_zipWeek95_99 ) + C(indGroup):C(qtr) + C(yearQtr) + C(gvkey) + C(ageTercile) + C(profitTercile) + C(sizeTercile) ', data = goodsData).fit()\n",
    "\n",
    "print(time.time() - start) \n",
    "\n",
    "coeffs  = pd.DataFrame(tempWeekMod_intxn.params,  columns = ['coeffs'])\n",
    "pvalues = pd.DataFrame(tempWeekMod_intxn.pvalues, columns = ['pvals'])\n",
    "\n",
    "coeffs  = coeffs[coeffs.index.str.contains('temp')]\n",
    "pvalues = pvalues[pvalues.index.str.contains('temp')]\n",
    "\n",
    "results = pd.concat([coeffs,pvalues],axis = 1)\n",
    "\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try months now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114.2045030593872\n",
      "                           coeffs     pvals\n",
      "temp_zipMonth95_99       0.009830  0.023806\n",
      "lag1_temp_zipMonth95_99  0.004806  0.280005\n",
      "lag2_temp_zipMonth95_99  0.013350  0.002527\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "#  + lag1_temp_zipMonth95_99 + lag2_temp_zipMonth95_99 + lag3_temp_zipMonth95_99\n",
    "# \n",
    "\n",
    "tempMonthMod = smf.ols(formula = 'lnRevNormd ~  (temp_zipMonth95_99 + lag1_temp_zipMonth95_99 + lag2_temp_zipMonth95_99 ) + C(indGroup):C(qtr) + C(yearQtr) + C(gvkey) + C(ageTercile) + C(profitTercile) + C(sizeTercile)', data = goodsData).fit()\n",
    "\n",
    "print(time.time() - start) \n",
    "\n",
    "coeffs  = pd.DataFrame(tempMonthMod.params,  columns = ['coeffs'])\n",
    "pvalues = pd.DataFrame(tempMonthMod.pvalues, columns = ['pvals'])\n",
    "\n",
    "coeffs  = coeffs[coeffs.index.str.contains('temp')]\n",
    "pvalues = pvalues[pvalues.index.str.contains('temp')]\n",
    "\n",
    "results = pd.concat([coeffs,pvalues],axis = 1)\n",
    "\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108.40949201583862\n",
      "                                               coeffs     pvals\n",
      "C(tempTercile)[T.2]                         -0.004046  0.735738\n",
      "C(tempTercile)[T.3]                         -0.001589  0.923088\n",
      "temp_zipMonth95_99                          -0.001667  0.832368\n",
      "C(tempTercile)[T.2]:temp_zipMonth95_99       0.019297  0.054603\n",
      "C(tempTercile)[T.3]:temp_zipMonth95_99       0.012500  0.238812\n",
      "lag1_temp_zipMonth95_99                      0.004461  0.566858\n",
      "C(tempTercile)[T.2]:lag1_temp_zipMonth95_99 -0.003163  0.761903\n",
      "C(tempTercile)[T.3]:lag1_temp_zipMonth95_99  0.003602  0.734986\n",
      "lag2_temp_zipMonth95_99                      0.013744  0.074669\n",
      "C(tempTercile)[T.2]:lag2_temp_zipMonth95_99  0.008131  0.450774\n",
      "C(tempTercile)[T.3]:lag2_temp_zipMonth95_99 -0.007822  0.458455\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "#  + lag1_temp_zipMonth95_99 + lag2_temp_zipMonth95_99 + lag3_temp_zipMonth95_99\n",
    "# + C(ageTercile) + C(profitTercile) + C(sizeTercile)\n",
    "\n",
    "tempMonthMod_intxn = smf.ols(formula = 'lnRevNormd ~  C(tempTercile)*(temp_zipMonth95_99 + lag1_temp_zipMonth95_99 + lag2_temp_zipMonth95_99 ) + C(indGroup):C(qtr) + C(yearQtr) + C(gvkey) + C(ageTercile) + C(profitTercile) + C(sizeTercile) ', data = goodsData).fit()\n",
    "\n",
    "print(time.time() - start) \n",
    "\n",
    "coeffs  = pd.DataFrame(tempMonthMod_intxn.params,  columns = ['coeffs'])\n",
    "pvalues = pd.DataFrame(tempMonthMod_intxn.pvalues, columns = ['pvals'])\n",
    "\n",
    "coeffs  = coeffs[coeffs.index.str.contains('temp')]\n",
    "pvalues = pvalues[pvalues.index.str.contains('temp')]\n",
    "\n",
    "results = pd.concat([coeffs,pvalues],axis = 1)\n",
    "\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And quarters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114.30202984809875\n",
      "                             coeffs     pvals\n",
      "temp_zipQuarter95_99       0.013951  0.068572\n",
      "lag1_temp_zipQuarter95_99  0.008178  0.292307\n",
      "lag2_temp_zipQuarter95_99  0.022527  0.004156\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "#  + lag1_temp_zipWeek95_99 + lag2_temp_zipWeek95_99 + lag3_temp_zipWeek95_99\n",
    "# + C(ageTercile) + C(profitTercile) + C(sizeTercile)\n",
    "\n",
    "tempQuarterMod = smf.ols(formula = 'lnRevNormd ~  (temp_zipQuarter95_99 + lag1_temp_zipQuarter95_99 + lag2_temp_zipQuarter95_99 ) + C(indGroup):C(qtr) + C(yearQtr) + C(gvkey) + C(ageTercile) + C(profitTercile) + C(sizeTercile) ', data = goodsData).fit()\n",
    "\n",
    "print(time.time() - start) \n",
    "\n",
    "coeffs  = pd.DataFrame(tempQuarterMod.params,  columns = ['coeffs'])\n",
    "pvalues = pd.DataFrame(tempQuarterMod.pvalues, columns = ['pvals'])\n",
    "\n",
    "coeffs  = coeffs[coeffs.index.str.contains('temp')]\n",
    "pvalues = pvalues[pvalues.index.str.contains('temp')]\n",
    "\n",
    "results = pd.concat([coeffs,pvalues],axis = 1)\n",
    "\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113.19785404205322\n",
      "                                                 coeffs     pvals\n",
      "C(tempTercile)[T.2]                            0.005795  0.614856\n",
      "C(tempTercile)[T.3]                           -0.000258  0.987331\n",
      "temp_zipQuarter90_95                          -0.011533  0.359505\n",
      "C(tempTercile)[T.2]:temp_zipQuarter90_95       0.007451  0.646007\n",
      "C(tempTercile)[T.3]:temp_zipQuarter90_95       0.026969  0.098400\n",
      "lag1_temp_zipQuarter90_95                      0.011373  0.312643\n",
      "C(tempTercile)[T.2]:lag1_temp_zipQuarter90_95 -0.009584  0.546676\n",
      "C(tempTercile)[T.3]:lag1_temp_zipQuarter90_95 -0.005831  0.717145\n",
      "lag2_temp_zipQuarter90_95                      0.010494  0.356890\n",
      "C(tempTercile)[T.2]:lag2_temp_zipQuarter90_95  0.004977  0.760370\n",
      "C(tempTercile)[T.3]:lag2_temp_zipQuarter90_95 -0.006950  0.669921\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "#  + lag1_temp_zipWeek95_99 + lag2_temp_zipWeek95_99 + lag3_temp_zipWeek95_99\n",
    "# + C(ageTercile) + C(profitTercile) + C(sizeTercile)\n",
    "\n",
    "tempQuarterMod_intxn = smf.ols(formula = 'lnRevNormd ~  C(tempTercile)*(temp_zipQuarter90_95 + lag1_temp_zipQuarter90_95 + lag2_temp_zipQuarter90_95 ) + C(indGroup):C(qtr) + C(yearQtr) + C(gvkey) + C(ageTercile) + C(profitTercile) + C(sizeTercile) ', data = goodsData).fit()\n",
    "\n",
    "print(time.time() - start) \n",
    "\n",
    "coeffs  = pd.DataFrame(tempQuarterMod_intxn.params,  columns = ['coeffs'])\n",
    "pvalues = pd.DataFrame(tempQuarterMod_intxn.pvalues, columns = ['pvals'])\n",
    "\n",
    "coeffs  = coeffs[coeffs.index.str.contains('temp')]\n",
    "pvalues = pvalues[pvalues.index.str.contains('temp')]\n",
    "\n",
    "results = pd.concat([coeffs,pvalues],axis = 1)\n",
    "\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107.34912300109863\n",
      "                                       coeffs     pvals\n",
      "precip_zipQuarterquant_Extreme      -0.002074  0.001179\n",
      "lag1_precip_zipQuarterquant_Extreme -0.001398  0.029075\n",
      "lag2_precip_zipQuarterquant_Extreme -0.001086  0.089402\n",
      "lag3_precip_zipQuarterquant_Extreme -0.001152  0.072004\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "\n",
    "precipMod = smf.ols(formula = 'lnRevNormd ~ precip_zipQuarterquant_Extreme + lag1_precip_zipQuarterquant_Extreme + lag2_precip_zipQuarterquant_Extreme + lag3_precip_zipQuarterquant_Extreme + C(indGroup):C(qtr) + C(yearQtr) + C(gvkey) + C(ageTercile) + C(profitTercile) + C(sizeTercile)', data = goodsData).fit()\n",
    "\n",
    "print(time.time() - start) \n",
    "\n",
    "# convert this into a much more condensed version\n",
    "coeffs = pd.DataFrame(precipMod.params,   columns = ['coeffs'])\n",
    "pvalues = pd.DataFrame(precipMod.pvalues, columns = ['pvals'])\n",
    "\n",
    "coeffs = coeffs[coeffs.index.str.contains('precip')]\n",
    "pvalues = pvalues[pvalues.index.str.contains('precip')]\n",
    "\n",
    "results = pd.concat([coeffs,pvalues],axis = 1)\n",
    "\n",
    "\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "#  + lag1_temp_zipWeek95_99 + lag2_temp_zipWeek95_99 + lag3_temp_zipWeek95_99\n",
    "# + C(ageTercile) + C(profitTercile) + C(sizeTercile)\n",
    "\n",
    "tempWeekMod = smf.ols(formula = 'lnRevNormd ~  tempTercile*(temp_zipQuarter95_99 + lag1_temp_zipQuarter95_99 + lag2_temp_zipQuarter95_99 + lag3_temp_zipQuarter95_99) + C(indGroup):C(qtr) + C(yearQtr) + C(gvkey) ', data = goodsData).fit()\n",
    "\n",
    "print(time.time() - start) \n",
    "\n",
    "tempWeekMod.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "#  + lag1_temp_zipWeek95_99 + lag2_temp_zipWeek95_99 + lag3_temp_zipWeek95_99\n",
    "# + C(ageTercile) + C(profitTercile) + C(sizeTercile)\n",
    "\n",
    "tempWeekMod = smf.ols(formula = 'lnRevNormd ~  (precip_zipWeek95_99 + lag1_precip_zipWeek95_99 + lag2_precip_zipWeek95_99 + lag3_precip_zipWeek95_99) + C(indGroup):C(qtr) + C(yearQtr) + C(gvkey) ', data = goodsData).fit()\n",
    "\n",
    "print(time.time() - start) \n",
    "\n",
    "tempWeekMod.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional Tests\n",
    "Now try a few other ones here. \n",
    "- Streak of days above 95th percentile, temperature and rain.\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "\n",
    "precipStreakMod = smf.ols(formula   = 'lnRevNormd ~ C(wetStreak) + C(lag1_wetStreak) + C(lag2_wetStreak) + C(lag3_wetStreak) + C(indGroup):C(qtr) + C(yearQtr) + C(gvkey) + C(ageTercile) + C(profitTercile) + C(sizeTercile)', data = goodsData)\n",
    "precipStreakRes = precipStreakMod.fit() # cov_type  = 'cluster',cov_kwds={'groups': firms},use_t=True)\n",
    "\n",
    "\n",
    "print(time.time() - start) \n",
    "\n",
    "precipStreakRes.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "\n",
    "tempStreakMod = smf.ols(formula   = 'lnRevNormd ~ C(hotStreak) + C(lag1_hotStreak) + C(lag2_hotStreak) + C(lag3_hotStreak) + C(indGroup):C(qtr) + C(yearQtr) + C(gvkey) + C(ageTercile) + C(profitTercile) + C(sizeTercile)', data = goodsData)\n",
    "tempStreakRes = tempStreakMod.fit() # cov_type  = 'cluster',cov_kwds={'groups': firms},use_t=True)\n",
    "\n",
    "\n",
    "print(time.time() - start) \n",
    "\n",
    "tempStreakRes.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try with the different breakout categories of what's coming together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "\n",
    "precipCatMod = smf.ols(formula   = 'lnRevNormd ~ C(wetDaysCat) + C(lag1_wetDaysCat) + C(lag2_wetDaysCat) + C(lag3_wetDaysCat) + C(indGroup):C(qtr) + C(yearQtr) + C(gvkey) + C(ageTercile) + C(profitTercile) + C(sizeTercile)', data = goodsData)\n",
    "precipCatRes = precipCatMod.fit() # cov_type  = 'cluster',cov_kwds={'groups': firms},use_t=True)\n",
    "\n",
    "\n",
    "print(time.time() - start) \n",
    "\n",
    "precipCatRes.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "\n",
    "tempCatMod = smf.ols(formula   = 'lnRevNormd ~ C(hotDaysCat) + C(lag1_hotDaysCat) + C(lag2_hotDaysCat) + C(lag3_hotDaysCat) + C(indGroup):C(qtr) + C(yearQtr) + C(gvkey) + C(ageTercile) + C(profitTercile) + C(sizeTercile)', data = goodsData)\n",
    "tempCatRes = tempCatMod.fit() # cov_type  = 'cluster',cov_kwds={'groups': firms},use_t=True)\n",
    "\n",
    "\n",
    "print(time.time() - start) \n",
    "\n",
    "tempCatRes.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try playing with temperature a little bit more. Look at:\n",
    "    - interaction with concentration\n",
    "    - establishment-weighted vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "\n",
    "tempStreakConcMod = smf.ols(formula   = 'lnRevNormd ~ C(firmConcTercile)*(C(hotDaysCat) + C(lag1_hotDaysCat) + C(lag2_hotDaysCat) + C(lag3_hotDaysCat)) + C(indGroup):C(qtr) + C(yearQtr) + C(gvkey) + C(ageTercile) + C(profitTercile) + C(sizeTercile)', \n",
    "                           data = goodsData)\n",
    "tempStreakConcRes = tempStreakConcMod.fit() # cov_type  = 'cluster',cov_kwds={'groups': firms},use_t=True)\n",
    "\n",
    "\n",
    "print(time.time() - start) \n",
    "\n",
    "tempStreakConcRes.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try the temperature as defined by super super hot days, anywhere in the country - 95th percentile anywhere. This will only happen in a few places in , or at least, there will be some geographic skew. But we can control for that by looking at the effect of hot temps given different baselines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "\n",
    "tempModAnnual_noControls = smf.ols(formula   = 'lnRevNormd ~ temp_annualquant_Extreme + lag1_temp_annualquant_Extreme + lag2_temp_annualquant_Extreme + lag3_temp_annualquant_Extreme + C(indGroup):C(qtr) + C(yearQtr) + C(gvkey)', data = goodsData)\n",
    "tempResAnnual_noControls = tempModAnnual_noControls.fit(cov_type  = 'cluster',cov_kwds={'groups': firms},use_t=True)\n",
    "\n",
    "\n",
    "print(time.time() - start) \n",
    "\n",
    "tempResAnnual_noControls.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try the standard interactions, controlling for the background climate in given places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look at the below, we see that the places that are normally coolest are negatively impacted by extreme extremes. Specifically, using an across-the-country cutoff for temperature, we have that the biggest negative effect happens in the places that are normally the lowest-temperature.\n",
    "\n",
    "This gives some promise that we might find an effect of temperature in some places, depending on expectation or baseline climate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "\n",
    "tempEstMod_annual = smf.ols(formula   = 'lnRevNormd ~ C(tempTercile)*(temp_annualquant_Extreme + lag1_temp_annualquant_Extreme + lag2_temp_annualquant_Extreme + lag3_temp_annualquant_Extreme) + C(indGroup):C(qtr) + C(yearQtr) + C(gvkey) + C(ageTercile) + C(profitTercile) + C(sizeTercile)', \n",
    "                           data = goodsData)\n",
    "\n",
    "\n",
    "tempResMod_annual = tempEstMod_annual.fit() # cov_type  = 'cluster',cov_kwds={'groups': firms},use_t=True)\n",
    "\n",
    "\n",
    "print(time.time() - start) \n",
    "\n",
    "tempResMod_annual.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try it by precipitation quartile for comparison's sake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "\n",
    "precipEstMod_annual = smf.ols(formula   = 'lnRevNormd ~ C(precipTercile)*(precip_annualquant_Extreme + lag1_precip_annualquant_Extreme + lag2_precip_annualquant_Extreme + lag3_precip_annualquant_Extreme) + C(indGroup):C(qtr) + C(yearQtr) + C(gvkey) + C(ageTercile) + C(profitTercile) + C(sizeTercile)', \n",
    "                           data = goodsData)\n",
    "\n",
    "\n",
    "precipResMod_annual = precipEstMod_annual.fit() # cov_type  = 'cluster',cov_kwds={'groups': firms},use_t=True)\n",
    "\n",
    "\n",
    "print(time.time() - start) \n",
    "\n",
    "precipResMod_annual.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's make sure we have the originals, the OGs, for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "\n",
    "tempEstMod_zipQuarter = smf.ols(formula   = 'lnRevNormd ~ C(tempTercile)*(temp_zipQuarterquant_Extreme + lag1_temp_zipQuarterquant_Extreme + lag2_temp_zipQuarterquant_Extreme + lag3_temp_zipQuarterquant_Extreme) + C(indGroup):C(qtr) + C(yearQtr) + C(gvkey) + C(ageTercile) + C(profitTercile) + C(sizeTercile)', \n",
    "                           data = goodsData)\n",
    "\n",
    "\n",
    "tempResMod_zipQuarter = tempEstMod_zipQuarter.fit() # cov_type  = 'cluster',cov_kwds={'groups': firms},use_t=True)\n",
    "\n",
    "\n",
    "print(time.time() - start) \n",
    "\n",
    "tempResMod_zipQuarter.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "\n",
    "precipEstMod_zipQuarter = smf.ols(formula   = 'lnRevNormd ~ C(precipTercile)*(precip_zipQuarterquant_Extreme + lag1_precip_zipQuarterquant_Extreme + lag2_precip_zipQuarterquant_Extreme + lag3_precip_zipQuarterquant_Extreme) + C(indGroup):C(qtr) + C(yearQtr) + C(gvkey) + C(ageTercile) + C(profitTercile) + C(sizeTercile)', \n",
    "                           data = goodsData)\n",
    "\n",
    "\n",
    "precipResMod_zipQuarter = precipEstMod_zipQuarter.fit() # cov_type  = 'cluster',cov_kwds={'groups': firms},use_t=True)\n",
    "\n",
    "\n",
    "print(time.time() - start) \n",
    "\n",
    "precipResMod_zipQuarter.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Industry-Specific"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start to do some of the heterogeneity analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precipMod_byInd       = smf.ols(formula = 'lnRevNormd ~ C(indGroup)*(precip_zipQuarterquant_Extreme + lag1_precip_zipQuarterquant_Extreme + lag2_precip_zipQuarterquant_Extreme + lag3_precip_zipQuarterquant_Extreme) + C(indGroup)*C(qtr) + C(yearQtr) + C(gvkey) + C(ageTercile) + C(profitTercile) + C(sizeTercile)', data = goodsData).fit()\n",
    "coeff = precipMod_byInd.params\n",
    "pvals = precipMod_byInd.pvalues\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precipMod_byInd.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase    = 'precip_zipQuarterquant_Extreme'\n",
    "\n",
    "condition = [s for s in coeff.index if phrase in s]\n",
    "coeffs_ofInt = coeff[condition]\n",
    "pvals_ofInt  = pvals[condition] \n",
    "\n",
    "results = pd.DataFrame()\n",
    "\n",
    "# get coeffs, lags, for each of these\n",
    "lag0   = [s for s in coeffs_ofInt.index if ('lag' not in s)]\n",
    "# lag0   = ['t']*len(lag0)\n",
    "coeff0 = coeffs_ofInt[lag0]\n",
    "pval0  = pvals_ofInt[lag0]\n",
    "lags0  = ['t']*len(lag0)\n",
    "\n",
    "lag1   = [s for s in coeffs_ofInt.index if ('lag1' in s)]\n",
    "coeff1 = coeffs_ofInt[lag1]\n",
    "pval1  = pvals_ofInt[lag1]\n",
    "lags1  = ['t-1']*len(lag0)\n",
    "\n",
    "lag2   = [s for s in coeffs_ofInt.index if ('lag2' in s)]\n",
    "coeff2 = coeffs_ofInt[lag2]\n",
    "pval2  = pvals_ofInt[lag2]\n",
    "lags2  = ['t-2']*len(lag0)\n",
    "\n",
    "lag3   = [s for s in coeffs_ofInt.index if ('lag3' in s)]\n",
    "coeff3 = coeffs_ofInt[lag3]\n",
    "pval3  = pvals_ofInt[lag3]\n",
    "lags3  = ['t-3']*len(lag3)\n",
    "\n",
    "allNames = list(itertools.chain(lag0,lag1,lag2,lag3))\n",
    "intxns   = [char.split(':')[0] for char in allNames]\n",
    "allCoefs = list(itertools.chain(coeff0,coeff1,coeff2,coeff3))  \n",
    "allPVals = list(itertools.chain(pval0,pval1,pval2,pval3))  \n",
    "allLagLabels = list(itertools.chain(lags0,lags1,lags2,lags3))  \n",
    "coefsWithPVals = []\n",
    "\n",
    "for i in range(0,len(allCoefs)):\n",
    "    next = str(\"%.4f\" % allCoefs[i]) + ' (' + str(\"%.2f\" % allPVals[i]) + ')'\n",
    "    coefsWithPVals.append(next)\n",
    "    \n",
    "take2 = pd.DataFrame([intxns,allLagLabels,coefsWithPVals]).T\n",
    "take2.columns = ['indInteraction','allLagLabels','coefsWithPVals']\n",
    "take2.pivot(index='indInteraction', columns='allLagLabels', values='coefsWithPVals').reset_index().to_csv('take2.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try with the total number of industries as described in the other doc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precipTotal_byInd  = smf.ols(formula = 'lnRevNormd ~ C(indGroup)*(extremePrecip) + C(indGroup)*C(qtr) + C(yearQtr) + C(gvkey) + C(ageTercile) + C(profitTercile) + C(sizeTercile)', data = goodsData).fit()\n",
    "coeff              = precipTotal_byInd.params\n",
    "pvals              = precipTotal_byInd.pvalues\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precipTotal_byInd.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase    = 'extremePrecip'\n",
    "\n",
    "condition = [s for s in coeff.index if phrase in s]\n",
    "coeffs_ofInt = coeff[condition]\n",
    "pvals_ofInt  = pvals[condition] \n",
    "\n",
    "\n",
    "results = pd.DataFrame()\n",
    "\n",
    "\n",
    "allNames = coeffs_ofInt.index\n",
    "intxns   = [char.split(':')[0] for char in allNames]\n",
    "allCoefs = list(coeffs_ofInt)  \n",
    "allPVals = list(pvals_ofInt)  \n",
    "coefsWithPVals = []\n",
    "\n",
    "for i in range(0,len(allCoefs)):\n",
    "    next = str(\"%.4f\" % allCoefs[i]) + ' (' + str(\"%.2f\" % allPVals[i]) + ')'\n",
    "    coefsWithPVals.append(next)\n",
    "\n",
    "print(coefsWithPVals)\n",
    "    \n",
    "\n",
    "take3 = pd.DataFrame([intxns,coefsWithPVals]).T\n",
    "take3.columns = ['indInteraction','coefsWithPVals']\n",
    "\n",
    "print(take3)\n",
    "\n",
    "take3.to_csv('take3.csv')\n",
    "\n",
    "'''take2.pivot(index='indInteraction', columns='allLagLabels', values='coefsWithPVals').reset_index().to_csv('take2.csv')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Now try this for each regression separately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the same for temperature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempMod_byInd       = smf.ols(formula = 'lnRevNormd ~ C(indGroup)*(temp_zipQuarterquant_Extreme + lag1_temp_zipQuarterquant_Extreme + lag2_temp_zipQuarterquant_Extreme + lag3_temp_zipQuarterquant_Extreme) + C(indGroup):C(qtr) + C(yearQtr) + C(gvkey) + C(ageTercile) + C(profitTercile) + C(sizeTercile)', data = goodsData)\n",
    "tempMod_byInd_res   = tempMod_byInd.fit(cov_type='cluster',cov_kwds={'groups': firms},use_t=True)\n",
    "\n",
    "\n",
    "tempMod_byInd_res.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try just the concurrent quarter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precipMod_byInd       = smf.ols(formula = 'lnRevNormd ~ C(indGroup)*(precip_zipQuarterquant_Extreme) + C(indGroup):C(qtr) + C(yearQtr) + C(gvkey) + C(ageTercile) + C(profitTercile) + C(sizeTercile)', data = goodsData)\n",
    "precipMod_byInd_res   = precipMod_byInd.fit()\n",
    "\n",
    "\n",
    "precipMod_byInd_res.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try with the categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotCat_byInd       = smf.ols(formula = 'lnRevNormd ~ C(indGroup)*(C(hotDaysCat) + C(lag1_hotDaysCat) + C(lag2_hotDaysCat) + C(lag3_hotDaysCat)) + C(indGroup):C(qtr) + C(yearQtr) + C(gvkey) + C(ageTercile) + C(profitTercile) + C(sizeTercile)', data = goodsData)\n",
    "hotCat_byInd_res   = hotCat_byInd.fit()\n",
    "\n",
    "hotCat_byInd_res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wetCat_byInd       = smf.ols(formula = 'lnRevNormd ~ C(indGroup)*(C(wetDaysCat) + C(lag1_wetDaysCat) + C(lag2_wetDaysCat) + C(lag3_wetDaysCat)) + C(indGroup):C(qtr) + C(yearQtr) + C(gvkey) + C(ageTercile) + C(profitTercile) + C(sizeTercile)', data = goodsData)\n",
    "wetCat_byInd_res   = wetCat_byInd.fit()\n",
    "\n",
    "wetCat_byInd_res.summary()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like if we split hairs by dividing things up the last few quarters, everything starts to go a little haywire. The most generous description is something like, we can't separately identify the effects from different quarters, and there's a lot of fairly collinear effects. There are a few less generous descriptions as well, including that there's not necessarily much signal here. \n",
    "\n",
    "\n",
    "One of the understated pros of all of this is that the r-squared values are all very high - we're getting great identification here. We could potentially expand the data sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things for Larry tomorrow:\n",
    "    - emphasis on, here is the specific regression form. here's why i think it is good/bad\n",
    "    - main precipitation + temperature plot\n",
    "    - a sense of the heterogeneity, by types of place\n",
    "    - a little discussion of what to do about temperature: focus on a higher cutoff, the effects in places that aren't quite used to it, and the effects on firms that have more of their operations concentrated in one place\n",
    "           - the problem with our current definition (zip-quarter) is that for some quarters, we don't have high enough baselines to really register the types of high temperatures \n",
    "           - it seems like there might be more variability in precipitation? or at least, more zipcodes seem to trigger it than trigger the temperature threshold\n",
    "    - some of the industry - intxn results\n",
    "    - some of the specific industry results\n",
    "    - discussino of future results: indirect effect results, stock results, by concentration of firm \n",
    "    - a discussion of the different time frames: the further back, the less insight we have into what businesses are saying about all of this. the different data sources to mention are: disclosures (8-Ks); PRISM; zipcodes; compustat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goodsData.indGroup.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoffVarsYr = ['0.95']  # , ] # ,'1xQtr''1x5Qtrs',\n",
    "weatherVars  = ['precip_'] # , 'temp5Days_', 'precip5Days_'] # , 'precip_']#, , ] #[,]\n",
    "statVarsYr   = ['zipQuarterquant_'] #  , , ]  #,'zipQuarterquant_']\n",
    "outcomeVars  = ['lnRevNormd'] # , 'lnRev', 'lnCost', 'revenueChange', 'costChange']\n",
    "\n",
    "goodsData = goodsData[~goodsData.lnRev.isna() & ~goodsData.lnCost.isna()] # & ~goodsData.lnCostNormd.isna()]\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "results = pd.DataFrame()\n",
    "\n",
    "i = 0\n",
    "for outcomeVar in outcomeVars:\n",
    "    for weatherVar in weatherVars:\n",
    "        for statVar in statVarsYr:                     \n",
    "            for cutoffVar in cutoffVarsYr:\n",
    "                i = i + 1\n",
    "                indVar = weatherVar + statVar + cutoffVar\n",
    "                \n",
    "                \n",
    "                print(outcomeVar, \"~\", indVar)\n",
    "\n",
    "\n",
    "                # find: concurrent ; or lagged supplier data\n",
    "                X = goodsData.loc[:,((goodsData.columns.str.contains(indVar) & ~goodsData.columns.str.contains('empWt_')) | \n",
    "                                                (goodsData.columns.str.contains('indQtr_')) |\n",
    "                                                (goodsData.columns.str.contains('gvkey_')))] #  | \n",
    "                                                (goodsData.columns.str.contains('ageTercile_')) |\n",
    "                                                # (goodsData.columns.str.contains('sizeTercile_')) |\n",
    "                                                # (goodsData.columns.str.contains('profitTercile_')))]\n",
    "                \n",
    "                \n",
    "                X = sm.add_constant(X)\n",
    "\n",
    "                \n",
    "                firms = goodsData['gvkey']\n",
    "        \n",
    "\n",
    "                y = goodsData[outcomeVar]\n",
    "                \n",
    "                \n",
    "                model = sm.OLS(y, X).fit(cov_type='cluster',cov_kwds={'groups': firms},use_t=True)\n",
    "                coeff = model.params[1:     1 + len(goodsData.columns[goodsData.columns.str.contains(indVar) & ~goodsData.columns.str.contains('empWt_')])]\n",
    "                pvals = model.pvalues[1:    1 + len(goodsData.columns[goodsData.columns.str.contains(indVar) & ~goodsData.columns.str.contains('empWt_')])]\n",
    "                errs  = modelResults.bse[1: 1 + len(goodsData.columns[goodsData.columns.str.contains(indVar) & ~goodsData.columns.str.contains('empWt_')])]\n",
    "                # print(model.summary())\n",
    "                print(coeff)\n",
    "                print(pvals)\n",
    "\n",
    "\n",
    "                results.loc[i,'industry'] = ind\n",
    "\n",
    "                results.loc[i,'outcomeVar'] = outcomeVar\n",
    "                results.loc[i,'weatherVar'] = weatherVar\n",
    "\n",
    "                results.loc[i,'lag0']       = coeff[0]\n",
    "                results.loc[i,'lag1']       = coeff[1]\n",
    "                results.loc[i,'lag2']       = coeff[2]\n",
    "                results.loc[i,'lag3']       = coeff[3]\n",
    "                results.loc[i,'lag4']       = coeff[4]\n",
    "                \n",
    "                \n",
    "                results.loc[i,'pval0']      = pvals[0]\n",
    "                results.loc[i,'pval1']      = pvals[1]\n",
    "                results.loc[i,'pval2']      = pvals[2]\n",
    "                results.loc[i,'pval3']      = pvals[3]\n",
    "                results.loc[i,'pval4']      = pvals[4]\n",
    "                \n",
    "                \n",
    "                results.loc[i,'bse0']       = errs[0]\n",
    "                results.loc[i,'bse1']       = errs[1]\n",
    "                results.loc[i,'bse2']       = errs[2]\n",
    "                results.loc[i,'bse3']       = errs[3]\n",
    "                results.loc[i,'bse4']       = errs[4]\n",
    "\n",
    "                                \n",
    "                # results.to_csv(\"../../data/utilitiesResults_rightInds_noCtrls.csv\")\n",
    "                \n",
    "                print( time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weatherVars  = ['hotStreak', 'wetStreak'] # , 'temp5Days_', 'precip5Days_'] # , 'precip_']#, , ] #[,]\n",
    "outcomeVars  = ['lnRevNormd', 'lnCostNormd'] # , 'lnRev', 'lnCost', 'revenueChange', 'costChange']\n",
    "\n",
    "goodsData = goodsData[~goodsData.lnRev.isna() & ~goodsData.lnCost.isna()] # & ~goodsData.lnCostNormd.isna()]\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "results = pd.DataFrame()\n",
    "\n",
    "i = 0\n",
    "for outcomeVar in outcomeVars:\n",
    "    for weatherVar in weatherVars:\n",
    "        i = i + 1\n",
    "        indVar = weatherVar\n",
    "\n",
    "\n",
    "        print(outcomeVar, \"~\", indVar)\n",
    "\n",
    "\n",
    "        # find: concurrent ; or lagged supplier data\n",
    "        X = goodsData.loc[:,((goodsData.columns.str.contains(indVar) & ~goodsData.columns.str.contains('empWt_')) | \n",
    "                                        (goodsData.columns.str.contains('indQtr_')) |\n",
    "                                        (goodsData.columns.str.contains('gvkey_')))] #  | \n",
    "                                        # (goodsData.columns.str.contains('ageTercile_')) |\n",
    "                                        # (goodsData.columns.str.contains('sizeTercile_')) |\n",
    "                                        # (goodsData.columns.str.contains('profitTercile_')))]\n",
    "\n",
    "\n",
    "        X = sm.add_constant(X)\n",
    "        print(X.columns)\n",
    "\n",
    "        firms = goodsData['gvkey']\n",
    "\n",
    "\n",
    "        y = goodsData[outcomeVar]\n",
    "\n",
    "\n",
    "        model = sm.OLS(y, X).fit(cov_type='cluster',cov_kwds={'groups': firms},use_t=True)\n",
    "        coeff = model.params[1:     1 + len(goodsData.columns[goodsData.columns.str.contains(indVar) & ~goodsData.columns.str.contains('empWt_')])]\n",
    "        pvals = model.pvalues[1:    1 + len(goodsData.columns[goodsData.columns.str.contains(indVar) & ~goodsData.columns.str.contains('empWt_')])]\n",
    "        errs  = modelResults.bse[1: 1 + len(goodsData.columns[goodsData.columns.str.contains(indVar) & ~goodsData.columns.str.contains('empWt_')])]\n",
    "        # print(model.summary())\n",
    "        print(coeff)\n",
    "        print(pvals)\n",
    "\n",
    "\n",
    "        results.loc[i,'industry'] = ind\n",
    "\n",
    "        results.loc[i,'outcomeVar'] = outcomeVar\n",
    "        results.loc[i,'weatherVar'] = weatherVar\n",
    "\n",
    "        results.loc[i,'lag0']       = coeff[0]\n",
    "        results.loc[i,'lag1']       = coeff[1]\n",
    "        results.loc[i,'lag2']       = coeff[2]\n",
    "        results.loc[i,'lag3']       = coeff[3]\n",
    "        results.loc[i,'lag4']       = coeff[4]\n",
    "\n",
    "\n",
    "        results.loc[i,'pval0']      = pvals[0]\n",
    "        results.loc[i,'pval1']      = pvals[1]\n",
    "        results.loc[i,'pval2']      = pvals[2]\n",
    "        results.loc[i,'pval3']      = pvals[3]\n",
    "        results.loc[i,'pval4']      = pvals[4]\n",
    "\n",
    "\n",
    "        results.loc[i,'bse0']       = errs[0]\n",
    "        results.loc[i,'bse1']       = errs[1]\n",
    "        results.loc[i,'bse2']       = errs[2]\n",
    "        results.loc[i,'bse3']       = errs[3]\n",
    "        results.loc[i,'bse4']       = errs[4]\n",
    "\n",
    "\n",
    "        # results.to_csv(\"../../data/utilitiesResults_rightInds_noCtrls.csv\")\n",
    "\n",
    "        print( time.time() - start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(\"../../data/utilitiesResults_rightInds.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Employment-Wtd Weather\n",
    "Run the regressions using the emp-wtd data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoffVar   = '0.95'\n",
    "weatherVar  = 'precip_'\n",
    "statVar  = 'zipquant_'\n",
    "outcomeVar  = 'lnRevNormd'\n",
    "\n",
    "indVar = weatherVar + statVar + cutoffVar\n",
    "\n",
    "\n",
    "goodsData.columns[goodsData.columns.str.contains(indVar) & goodsData.columns.str.contains('empWt_')] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoffVar   = '0.95'\n",
    "weatherVar  = 'precip_'\n",
    "statVarYr  = 'zipquant_'\n",
    "outcomeVar  = 'lnRevNormd'\n",
    "\n",
    "ind = 2\n",
    "\n",
    "\n",
    "##################\n",
    "filename = '../../data/companyData/igData_ind' + str(ind) + '.csv'           \n",
    "goodsData = pd.read_csv(filename).drop(columns = {'Unnamed: 0'})\n",
    "\n",
    "\n",
    "indVar = weatherVar + statVar + cutoffVar\n",
    "\n",
    "\n",
    "print(outcomeVar, \"~\", indVar)\n",
    "\n",
    "\n",
    "# find: concurrent ; or lagged supplier data\n",
    "X = goodsData.loc[:,((goodsData.columns.str.contains(indVar) & goodsData.columns.str.contains('empWt_')) | \n",
    "                                (goodsData.columns.str.contains('indQtr_')) |\n",
    "                                (goodsData.columns.str.contains('gvkey_'))  | \n",
    "                                (goodsData.columns.str.contains('ageTercile_')) |\n",
    "                                (goodsData.columns.str.contains('sizeTercile_')) |\n",
    "                                (goodsData.columns.str.contains('profitTercile_')))]\n",
    "\n",
    "\n",
    "print(X.columns)\n",
    "\n",
    "firms = goodsData['gvkey']\n",
    "\n",
    "\n",
    "y = goodsData[outcomeVar]\n",
    "\n",
    "\n",
    "model = sm.OLS(y, X).fit(cov_type='cluster',cov_kwds={'groups': firms},use_t=True)\n",
    "pvals = model.pvalues[0:len(goodsData.columns[goodsData.columns.str.contains(indVar)])]\n",
    "coeff =  model.params[0:len(goodsData.columns[goodsData.columns.str.contains(indVar)])]\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Industry-Specific\n",
    "Go through every famafrench industry and run the regressions above. First do this by days of extremes at hqs.\n",
    "\n",
    "### HQs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goodsData = pd.read_csv(\"../../data/companyData/goodsData_igData.csv\").drop(columns = {'Unnamed: 0'})\n",
    "\n",
    "industries = goodsData.indGroup.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoffVarsYr = ['0.95'] \n",
    "weatherVars  = ['precip_'] # , 'temp_'] \n",
    "statVarsYr   = ['zipQuarterquant_']\n",
    "outcomeVars  = ['lnRevNormd'] # , 'lnCostNormd']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "results = pd.DataFrame()\n",
    "\n",
    "i = 0\n",
    "\n",
    "for ind in industries:\n",
    "    print('##########################################################')\n",
    "    print(ind)\n",
    "    filename = '../../data/companyData/igData_ind' + str(ind) + '.csv'           \n",
    "    goodsData = pd.read_csv(filename).drop(columns = {'Unnamed: 0'})\n",
    "    if goodsData.shape[0] > 0:\n",
    "    \n",
    "        for outcomeVar in outcomeVars:\n",
    "            for weatherVar in weatherVars:\n",
    "                for statVar in statVarsYr:                     \n",
    "                    for cutoffVar in cutoffVarsYr:\n",
    "\n",
    "                        i = i + 1\n",
    "\n",
    "\n",
    "                        indVar = weatherVar + statVar + cutoffVar\n",
    "\n",
    "\n",
    "                        print(outcomeVar, \"~\", indVar)\n",
    "\n",
    "\n",
    "                        # find: concurrent ; or lagged supplier data\n",
    "                        X = goodsData.loc[:,(goodsData.columns.str.contains(indVar) & ~goodsData.columns.str.contains('empWt_') & ~goodsData.columns.str.contains('lag4')) | \n",
    "                                                        (goodsData.columns.str.contains('indQtr_')) | #  |\n",
    "                                                        (goodsData.columns.str.contains('gvkey_')) | #  | \n",
    "                                                        (goodsData.columns.str.contains('ageTercile_')) |\n",
    "                                                        (goodsData.columns.str.contains('sizeTercile_')) |\n",
    "                                                        (goodsData.columns.str.contains('profitTercile_'))]\n",
    "\n",
    "                        X = sm.add_constant(X)\n",
    "\n",
    "                        firms = goodsData['gvkey']\n",
    "\n",
    "\n",
    "                        y = goodsData[outcomeVar]\n",
    "\n",
    "\n",
    "                        model = sm.OLS(y, X).fit(cov_type='cluster',cov_kwds={'groups': firms},use_t=True)\n",
    "                        pvals = model.pvalues[1: 1 + len(goodsData.columns[goodsData.columns.str.contains(indVar) & ~goodsData.columns.str.contains('empWt_')])]\n",
    "                        coeff = model.params[1: 1 + len(goodsData.columns[goodsData.columns.str.contains(indVar)  & ~goodsData.columns.str.contains('empWt_')])]\n",
    "                        errs  = model.bse[1: 1 + len(goodsData.columns[goodsData.columns.str.contains(indVar)     & ~goodsData.columns.str.contains('empWt_')])]\n",
    "                \n",
    "                        '''print(coeff)\n",
    "                        print(pvals)'''\n",
    "\n",
    "\n",
    "                        results.loc[i,'industry'] = ind\n",
    "\n",
    "                        results.loc[i,'outcomeVar'] = outcomeVar\n",
    "                        results.loc[i,'weatherVar'] = weatherVar\n",
    "\n",
    "                        # str(\"%.4f\" % allCoefs[i]) + ' (' + str(\"%.2f\" % allPVals[i]) + ')'\n",
    "                        \n",
    "                        results.loc[i,'lag0']       = str(\"%.4f\" % coeff[0]) + ' (' + str(\"%.2f\" % pvals[0]) + ')'\n",
    "                        results.loc[i,'lag1']       = str(\"%.4f\" % coeff[1]) + ' (' + str(\"%.2f\" % pvals[1]) + ')'\n",
    "                        results.loc[i,'lag2']       = str(\"%.4f\" % coeff[2]) + ' (' + str(\"%.2f\" % pvals[2]) + ')'\n",
    "                        results.loc[i,'lag3']       = str(\"%.4f\" % coeff[3]) + ' (' + str(\"%.2f\" % pvals[3]) + ')'\n",
    "                        \n",
    "                        results.loc[i,'n'] = X.shape[0]\n",
    "                        # results.loc[i,'lag4']       = coeff[4]\n",
    "\n",
    "                        '''results.loc[i,'pval0']      = pvals[0]\n",
    "                        results.loc[i,'pval1']      = pvals[1]\n",
    "                        results.loc[i,'pval2']      = pvals[2]\n",
    "                        results.loc[i,'pval3']      = pvals[3]\n",
    "                        # results.loc[i,'pval4']      = pvals[4]\n",
    "                        \n",
    "                        results.loc[i,'bse0']       = errs[0]\n",
    "                        results.loc[i,'bse1']       = errs[1]\n",
    "                        results.loc[i,'bse2']       = errs[2]\n",
    "                        results.loc[i,'bse3']       = errs[3]'''\n",
    "                        # results.loc[i,'bse4']       = errs[4]\n",
    "\n",
    "\n",
    "                        results.to_csv(\"../../allIndustryResults.csv\")\n",
    "\n",
    "                        print( time.time() - start)\n",
    "                        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(\"allIndustryResults.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results)\n",
    "\n",
    "'''# merge in the industry names\n",
    "conversionTable = pd.read_csv(\"../../data/indMapping.csv\")\n",
    "conversionTable.dropna(inplace=True)\n",
    "conversionTable.reset_index(drop = True, inplace = True)\n",
    "\n",
    "conversionTable.head()\n",
    "\n",
    "results = results.merge(conversionTable)\n",
    "\n",
    "results.to_csv(\"../../allIndustryResults.csv\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try this with the streak data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weatherVars  = ['hotStreak', 'wetStreak'] \n",
    "outcomeVars  = ['lnRevNormd', 'lnCostNormd']\n",
    "\n",
    "\n",
    "industries = range(1,44)\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "results = pd.DataFrame()\n",
    "\n",
    "i = 0\n",
    "\n",
    "for ind in industries:\n",
    "    print('##########################################################')\n",
    "    print(ind)\n",
    "    filename = '../../data/companyData/igData_ind' + str(ind) + '.csv'           \n",
    "    goodsData = pd.read_csv(filename).drop(columns = {'Unnamed: 0'})\n",
    "    \n",
    "    if goodsData.shape[0] > 0:\n",
    "    \n",
    "        for outcomeVar in outcomeVars:\n",
    "            for weatherVar in weatherVars:\n",
    "                i = i + 1\n",
    "\n",
    "\n",
    "                indVar = weatherVar\n",
    "\n",
    "\n",
    "                print(outcomeVar, \"~\", indVar)\n",
    "\n",
    "\n",
    "                # find: concurrent ; or lagged supplier data\n",
    "                X = goodsData.loc[:,((goodsData.columns.str.contains(indVar) & ~goodsData.columns.str.contains('empWt_')) | \n",
    "                                                (goodsData.columns.str.contains('indQtr_')) |\n",
    "                                                (goodsData.columns.str.contains('gvkey_'))  | \n",
    "                                                (goodsData.columns.str.contains('ageTercile_')) |\n",
    "                                                (goodsData.columns.str.contains('sizeTercile_')) |\n",
    "                                                (goodsData.columns.str.contains('profitTercile_')))]\n",
    "                \n",
    "                X = sm.add_constant(X)\n",
    "\n",
    "\n",
    "\n",
    "                firms = goodsData['gvkey']\n",
    "\n",
    "\n",
    "                y = goodsData[outcomeVar]\n",
    "\n",
    "\n",
    "                model = sm.OLS(y, X).fit(cov_type='cluster',cov_kwds={'groups': firms},use_t=True)\n",
    "                pvals = model.pvalues[1: 1 + len(goodsData.columns[goodsData.columns.str.contains(indVar) & ~goodsData.columns.str.contains('empWt_')] )]\n",
    "                coeff = model.params[1: 1 + len(goodsData.columns[goodsData.columns.str.contains(indVar)  & ~goodsData.columns.str.contains('empWt_')])]\n",
    "                errs  = model.bse[1: 1 + len(goodsData.columns[goodsData.columns.str.contains(indVar)     & ~goodsData.columns.str.contains('empWt_')])]\n",
    "                \n",
    "                '''print(coeff)\n",
    "                print(pvals)'''\n",
    "\n",
    "\n",
    "                results.loc[i,'industry'] = ind\n",
    "\n",
    "                results.loc[i,'outcomeVar'] = outcomeVar\n",
    "                results.loc[i,'weatherVar'] = weatherVar\n",
    "\n",
    "                results.loc[i,'lag0']       = coeff[0]\n",
    "                results.loc[i,'lag1']       = coeff[1]\n",
    "                results.loc[i,'lag2']       = coeff[2]\n",
    "                results.loc[i,'lag3']       = coeff[3]\n",
    "                results.loc[i,'lag4']       = coeff[4]\n",
    "                \n",
    "                results.loc[i,'bse0']       = errs[0]\n",
    "                results.loc[i,'bse1']       = errs[1]\n",
    "                results.loc[i,'bse2']       = errs[2]\n",
    "                results.loc[i,'bse3']       = errs[3]\n",
    "                results.loc[i,'bse4']       = errs[4]\n",
    "\n",
    "                results.loc[i,'pval0']      = pvals[0]\n",
    "                results.loc[i,'pval1']      = pvals[1]\n",
    "                results.loc[i,'pval2']      = pvals[2]\n",
    "                results.loc[i,'pval3']      = pvals[3]\n",
    "                results.loc[i,'pval4']      = pvals[4]\n",
    "\n",
    "\n",
    "                results.to_csv(\"../../allIndustryResults_streaks.csv\")\n",
    "\n",
    "                print( time.time() - start)\n",
    "                \n",
    "\n",
    "# merge in the industry names\n",
    "conversionTable = pd.read_csv(\"../../data/indMapping.csv\")\n",
    "conversionTable.dropna(inplace=True)\n",
    "conversionTable.reset_index(drop = True, inplace = True)\n",
    "\n",
    "conversionTable.head()\n",
    "\n",
    "results = results.merge(conversionTable)\n",
    "\n",
    "\n",
    "results.to_csv(\"../../allIndustryResults_streaks.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_csv(\"../../allIndustryResults_streaks.csv\").drop(columns = {'Unnamed: 0'})\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Employment Weights\n",
    "\n",
    "Now do this for the employment-weighted average of the days of extreme weather."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoffVarsYr = ['0.95'] # , '1x5Qtrs', '1x5Yrs'] # '1x5Qtrs',\n",
    "weatherVars  = ['precip_', 'temp_']        #, 'temp5Days_', 'precip5Days_'] # , 'precip_']#, , ] #[,]\n",
    "statVarsYr   = ['zipQuarterquant_']\n",
    "outcomeVars  = ['lnRevNormd', 'lnCostNormd']\n",
    "\n",
    "industries = range(1,44)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "results = pd.DataFrame()\n",
    "\n",
    "i = 0\n",
    "\n",
    "\n",
    "\n",
    "for ind in industries:\n",
    "    print('##########################################################')\n",
    "    print(ind)\n",
    "    filename = '../../data/companyData/igData_ind' + str(ind) + '.csv'           \n",
    "    goodsData = pd.read_csv(filename).drop(columns = {'Unnamed: 0'})\n",
    "    if goodsData.shape[0] > 0:\n",
    "\n",
    "\n",
    "        for outcomeVar in outcomeVars:\n",
    "            for weatherVar in weatherVars:\n",
    "                for statVar in statVarsYr:                     \n",
    "                    for cutoffVar in cutoffVarsYr:\n",
    "\n",
    "                        i = i + 1\n",
    "\n",
    "\n",
    "\n",
    "                        '''goodsData = goodsData[~goodsData.lnRev.isna() & \n",
    "                                             ~goodsData.lnCost.isna() & \n",
    "                                             ~goodsData.revenueChange.isna() & \n",
    "                                             ~goodsData.costChange.isna()]'''\n",
    "\n",
    "\n",
    "                        indVar = weatherVar + statVar + cutoffVar\n",
    "\n",
    "\n",
    "                        print(outcomeVar, \"~\", indVar)\n",
    "\n",
    "\n",
    "                        # find: concurrent ; or lagged supplier data\n",
    "                        X = goodsData.loc[:,((goodsData.columns.str.contains(indVar) & goodsData.columns.str.contains('empWt_')) | \n",
    "                                                        (goodsData.columns.str.contains('indQtr_')) |\n",
    "                                                        (goodsData.columns.str.contains('gvkey_'))  | \n",
    "                                                        (goodsData.columns.str.contains('ageTercile_')) |\n",
    "                                                        (goodsData.columns.str.contains('sizeTercile_')) |\n",
    "                                                        (goodsData.columns.str.contains('profitTercile_')))]\n",
    "\n",
    "                        X = sm.add_constant(X)\n",
    "\n",
    "                        firms = goodsData['gvkey']\n",
    "\n",
    "\n",
    "                        y = goodsData[outcomeVar]\n",
    "\n",
    "\n",
    "                        model = sm.OLS(y, X).fit(cov_type='cluster',cov_kwds={'groups': firms},use_t=True)\n",
    "                        pvals = model.pvalues[1: 1 + len(goodsData.columns[goodsData.columns.str.contains(indVar) & goodsData.columns.str.contains('empWt_')])]\n",
    "                        coeff = model.params[1: 1 + len(goodsData.columns[goodsData.columns.str.contains(indVar) & goodsData.columns.str.contains('empWt_')])]\n",
    "                        errs  = model.bse[1: 1 + len(goodsData.columns[goodsData.columns.str.contains(indVar)  & goodsData.columns.str.contains('empWt_')])]\n",
    "                \n",
    "                        '''print(coeff)\n",
    "                        print(pvals)'''\n",
    "\n",
    "\n",
    "                        results.loc[i,'industry'] = ind\n",
    "\n",
    "                        results.loc[i,'outcomeVar'] = outcomeVar\n",
    "                        results.loc[i,'weatherVar'] = weatherVar\n",
    "\n",
    "                        results.loc[i,'lag0']       = coeff[0]\n",
    "                        results.loc[i,'lag1']       = coeff[1]\n",
    "                        results.loc[i,'lag2']       = coeff[2]\n",
    "                        results.loc[i,'lag3']       = coeff[3]\n",
    "                        results.loc[i,'lag4']       = coeff[4]\n",
    "\n",
    "                        results.loc[i,'bse0']       = errs[0]\n",
    "                        results.loc[i,'bse1']       = errs[1]\n",
    "                        results.loc[i,'bse2']       = errs[2]\n",
    "                        results.loc[i,'bse3']       = errs[3]\n",
    "                        results.loc[i,'bse4']       = errs[4]\n",
    "\n",
    "                        results.loc[i,'pval0']      = pvals[0]\n",
    "                        results.loc[i,'pval1']      = pvals[1]\n",
    "                        results.loc[i,'pval2']      = pvals[2]\n",
    "                        results.loc[i,'pval3']      = pvals[3]\n",
    "                        results.loc[i,'pval4']      = pvals[4]\n",
    "\n",
    "\n",
    "                        results.to_csv(\"../../results_byInds_withControls_empWts.csv\")\n",
    "\n",
    "                        print( time.time() - start)\n",
    "                        \n",
    "\n",
    "# merge in the industry names\n",
    "conversionTable = pd.read_csv(\"../../data/indMapping.csv\")\n",
    "conversionTable.dropna(inplace=True)\n",
    "conversionTable.reset_index(drop = True, inplace = True)\n",
    "\n",
    "conversionTable.head()\n",
    "\n",
    "results = results.merge(conversionTable)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over outcome variables and weather definitions\n",
    "weather = results.weatherVar.unique()\n",
    "outcome = results.outcomeVar.unique()\n",
    "\n",
    "\n",
    "for weather in weatherVars:\n",
    "    for outcome in outcomeVars:\n",
    "        # choose the elective parts of this - number of columns and the range of the axes\n",
    "        numCols = 4\n",
    "        yLims   = 0.1\n",
    "\n",
    "        industries = results.industryName.unique()\n",
    "        rowNum = len(industries) // numCols + 1\n",
    "        colNum = numCols\n",
    "\n",
    "        fig, ax = plt.subplots(rowNum, colNum, sharex='all', sharey='all',\n",
    "                              figsize=(20,40),\n",
    "                              constrained_layout=True)\n",
    "\n",
    "        fig.suptitle('Direct Effects: ' + outcome + ' ~ ' + weather + ' Employment Weights', fontsize=36)\n",
    "\n",
    "\n",
    "\n",
    "        i = 0\n",
    "        for ind in industries:\n",
    "            rowIndex = i // numCols\n",
    "            colIndex = i % numCols\n",
    "\n",
    "\n",
    "            i   = i + 1\n",
    "\n",
    "\n",
    "            rev = results[(results.outcomeVar == outcome) & (results.weatherVar == weather) & \n",
    "                         (results.industryName == ind)].reset_index()\n",
    "            x   = [0,1,2,3,4]\n",
    "            y   = [rev.lag0,rev.lag1,rev.lag2,rev.lag3,rev.lag4]\n",
    "\n",
    "\n",
    "            errors = [rev.bse0,rev.bse1,rev.bse2,rev.bse3,rev.bse4]\n",
    "\n",
    "            # plt.errorbar(x,y,yerr = errors, fmt = '.k')\n",
    "            # plt.show()\n",
    "\n",
    "            '''ax[rowIndex, colIndex].text(0.5, 0.5, str((i, j)),\n",
    "                                  fontsize=18, ha='center')'''\n",
    "            ax[rowIndex, colIndex].errorbar(x,y,yerr = errors, fmt = '.k')\n",
    "            ax[rowIndex, colIndex].xaxis.grid(False)\n",
    "            ax[rowIndex, colIndex].yaxis.grid(False)\n",
    "            ax[rowIndex, colIndex].axhline(y=0)\n",
    "            ax[rowIndex, colIndex].set_ylim([-yLims, yLims])\n",
    "\n",
    "            ax[rowIndex, colIndex].yaxis.set_ticks(np.arange(-yLims, yLims + 0.1, 0.1))\n",
    "            ax[rowIndex, colIndex].xaxis.set_ticks(np.arange(0.0, 5.0, 1.0))\n",
    "\n",
    "            ax[rowIndex, colIndex].tick_params(axis='both', labelsize = 16)\n",
    "            ax[rowIndex, colIndex].set_title(ind, fontsize = 24)\n",
    "\n",
    "\n",
    "            # ax[rowIndex, colIndex].\n",
    "            \n",
    "        fig.savefig('dirEffects_' + outcome + '_' + weather + '_empWts' + '.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indirect Effects\n",
    "This is almost exactly the same but with supplier information in place of the direct company information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can alter this so that we're doing it with the employment weights as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoffVarsYr = ['0.95'] \n",
    "weatherVars  = ['precip_', 'temp_'] \n",
    "statVarsYr   = ['zipQuarterquant_']\n",
    "outcomeVars  = ['lnRevNormd', 'lnCostNormd']\n",
    "\n",
    "\n",
    "industries = range(1,44)\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "results = pd.DataFrame()\n",
    "\n",
    "i = 0\n",
    "\n",
    "\n",
    "\n",
    "for ind in industries:\n",
    "    print('##########################################################')\n",
    "    print(ind)\n",
    "    \n",
    "    filename = \"../../data/companyData/supplier_igData_ind\" + str(ind) + \".csv\"\n",
    "    goodsData = pd.read_csv(filename).drop(columns = {'Unnamed: 0'})\n",
    "\n",
    "    if goodsData.shape[0] > 50:\n",
    "        for outcomeVar in outcomeVars:\n",
    "            for weatherVar in weatherVars:\n",
    "                for statVar in statVarsYr:                     \n",
    "                    for cutoffVar in cutoffVarsYr:\n",
    "\n",
    "                        i = i + 1\n",
    "\n",
    "                        indVar = weatherVar + statVar + cutoffVar\n",
    "\n",
    "\n",
    "                        print(outcomeVar, \"~\", indVar)\n",
    "\n",
    "\n",
    "                        # find: concurrent ; or lagged supplier data\n",
    "                        X = goodsData.loc[:,(((goodsData.columns.str.contains(indVar)) & ~goodsData.columns.str.contains('empWt_')) | \n",
    "                                (goodsData.columns.str.contains('indQtr_')) |\n",
    "                                (goodsData.columns.str.contains('gvkey_')) | #  | \n",
    "                                (goodsData.columns.str.contains('ageTercile_')) |\n",
    "                                (goodsData.columns.str.contains('sizeTercile_')) |\n",
    "                                (goodsData.columns.str.contains('profitTercile_')) | \n",
    "                                (goodsData.columns == 'supplierTercile'))] \n",
    "                        \n",
    "                        X = sm.add_constant(X)\n",
    "\n",
    "                        print(X.columns)\n",
    "                        firms = goodsData['gvkey']\n",
    "\n",
    "\n",
    "                        y = goodsData[outcomeVar]\n",
    "\n",
    "\n",
    "                        model = sm.OLS(y, X).fit(cov_type='cluster',cov_kwds={'groups': firms},use_t=True)\n",
    "                        pvals = model.pvalues[1: 1 + len(goodsData.columns[goodsData.columns.str.contains(indVar) & ~goodsData.columns.str.contains('empWt_')] )]\n",
    "                        coeff = model.params[1: 1 + len(goodsData.columns[goodsData.columns.str.contains(indVar)  & ~goodsData.columns.str.contains('empWt_')])]\n",
    "                        errs  = model.bse[1: 1 + len(goodsData.columns[goodsData.columns.str.contains(indVar)     & ~goodsData.columns.str.contains('empWt_')])]\n",
    "                \n",
    "                        '''print(coeff)\n",
    "                        print(pvals)'''\n",
    "\n",
    "\n",
    "                        results.loc[i,'industry'] = ind\n",
    "\n",
    "                        results.loc[i,'outcomeVar'] = outcomeVar\n",
    "                        results.loc[i,'weatherVar'] = weatherVar\n",
    "\n",
    "                        results.loc[i,'lag0']       = coeff[0]\n",
    "                        results.loc[i,'lag1']       = coeff[1]\n",
    "                        results.loc[i,'lag2']       = coeff[2]\n",
    "                        results.loc[i,'lag3']       = coeff[3]\n",
    "                        results.loc[i,'lag4']       = coeff[4]\n",
    "\n",
    "                        results.loc[i,'bse0']       = errs[0]\n",
    "                        results.loc[i,'bse1']       = errs[1]\n",
    "                        results.loc[i,'bse2']       = errs[2]\n",
    "                        results.loc[i,'bse3']       = errs[3]\n",
    "                        results.loc[i,'bse4']       = errs[4]\n",
    "\n",
    "                        results.loc[i,'pval0']      = pvals[0]\n",
    "                        results.loc[i,'pval1']      = pvals[1]\n",
    "                        results.loc[i,'pval2']      = pvals[2]\n",
    "                        results.loc[i,'pval3']      = pvals[3]\n",
    "                        results.loc[i,'pval4']      = pvals[4]\n",
    "\n",
    "\n",
    "                        results.to_csv(\"../../indirResults_hqs.csv\")\n",
    "\n",
    "                        print( time.time() - start)\n",
    "\n",
    "\n",
    "# merge in the industry names\n",
    "conversionTable = pd.read_csv(\"../../data/indMapping.csv\")\n",
    "conversionTable.dropna(inplace=True)\n",
    "conversionTable.reset_index(drop = True, inplace = True)\n",
    "\n",
    "conversionTable.head()\n",
    "\n",
    "results = results.merge(conversionTable)\n",
    "\n",
    "results.to_csv(\"../../indirResults_hqs.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_csv(\"../../indirResults_hqs.csv\").drop(columns = {'Unnamed: 0'})\n",
    "print(results.industry.unique())\n",
    "results.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(outcome, weather, ind)\n",
    "\n",
    "rev = results[(results.outcomeVar == outcome) & (results.weatherVar == weather) & \n",
    "                         (results.industry == ind)].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over outcome variables and weather definitions\n",
    "weatherVars = results.weatherVar.unique()\n",
    "outcomeVars = results.outcomeVar.unique()\n",
    "\n",
    "industries = [2,17,18,28,31,40,41,42] # results.industryName.unique()\n",
    "\n",
    "for outcome in outcomeVars:\n",
    "    for weather in weatherVars:\n",
    "        # choose the elective parts of this - number of columns and the range of the axes\n",
    "        numCols = 3\n",
    "        yLims   = 0.03\n",
    "\n",
    "        # industries = results.industryName.unique()\n",
    "        rowNum = len(industries) // numCols + 1\n",
    "        colNum = numCols\n",
    "\n",
    "        fig, ax = plt.subplots(rowNum, colNum, sharex='all', sharey='all',\n",
    "                              figsize=(20,20),\n",
    "                              constrained_layout=True)\n",
    "\n",
    "        fig.suptitle('Indirect Effects: ' + outcome + ' ~ ' + weather, fontsize=36)\n",
    "\n",
    "\n",
    "\n",
    "        i = 0\n",
    "        for ind in industries:\n",
    "            rowIndex = i // numCols\n",
    "            colIndex = i % numCols\n",
    "\n",
    "\n",
    "            i   = i + 1\n",
    "\n",
    "\n",
    "            rev = results[(results.outcomeVar == outcome) & (results.weatherVar == weather) & \n",
    "                         (results.industry == ind)].reset_index()\n",
    "            indName = rev.industryName.unique()[0]\n",
    "            x   = [0,1,2,3,4]\n",
    "            y   = [rev.lag0,rev.lag1,rev.lag2,rev.lag3,rev.lag4]\n",
    "\n",
    "\n",
    "            errors = [rev.bse0,rev.bse1,rev.bse2,rev.bse3,rev.bse4]\n",
    "\n",
    "            # plt.errorbar(x,y,yerr = errors, fmt = '.k')\n",
    "            # plt.show()\n",
    "\n",
    "            '''ax[rowIndex, colIndex].text(0.5, 0.5, str((i, j)),\n",
    "                                  fontsize=18, ha='center')'''\n",
    "            ax[rowIndex, colIndex].errorbar(x,y,yerr = errors, fmt = '.k')\n",
    "            ax[rowIndex, colIndex].xaxis.grid(False)\n",
    "            ax[rowIndex, colIndex].yaxis.grid(False)\n",
    "            ax[rowIndex, colIndex].axhline(y=0)\n",
    "            ax[rowIndex, colIndex].set_ylim([-yLims, yLims])\n",
    "\n",
    "            ax[rowIndex, colIndex].yaxis.set_ticks(np.arange(-yLims, yLims + 0.1, 0.1))\n",
    "            ax[rowIndex, colIndex].xaxis.set_ticks(np.arange(0.0, 5.0, 1.0))\n",
    "\n",
    "            ax[rowIndex, colIndex].tick_params(axis='both', labelsize = 16)\n",
    "            ax[rowIndex, colIndex].set_title(indName, fontsize = 24)\n",
    "\n",
    "\n",
    "            # ax[rowIndex, colIndex].\n",
    "    \n",
    "        fig.savefig('indirEffects_' + outcome + '_' + weather + '.png')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now do this by streaks - consecutive days with at least 95th percentile temp or rain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "weatherVars  = ['hotStreak',  'wetStreak']   #[,]\n",
    "outcomeVars  = ['lnRevNormd', 'lnCostNormd'] # ['revenueChange'] #[, 'costChange']#,'lnCost','lnInc','lnRev']\n",
    "\n",
    "# if we wanted to do the regressions below for all industries, we would use the following\n",
    "'''filename = \"../../data/companyData/goodsData_supplierData.csv\"\n",
    "goodsData = pd.read_csv(filename).drop(columns = {'Unnamed: 0'})\n",
    "'''\n",
    "\n",
    "# goodsData = goodsData[~goodsData.lnRev.isna() & ~goodsData.lnCost.isna() & ~goodsData.lnCostNormd.isna()]\n",
    "goodsData['scTercile']  = pd.qcut(goodsData['suppliers'], 3, labels=False, duplicates = 'drop')\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "results = pd.DataFrame()\n",
    "i = 0\n",
    "\n",
    "industries = range(1,44)\n",
    "\n",
    "for ind in industries:\n",
    "    filename = \"../../data/companyData/supplier_igData_ind\" + str(ind) + \".csv\"\n",
    "    goodsData = pd.read_csv(filename).drop(columns = {'Unnamed: 0'})\n",
    "\n",
    "    if goodsData.shape[0] > 50:\n",
    "\n",
    "        for outcomeVar in outcomeVars:\n",
    "            for weatherVar in weatherVars:\n",
    "                \n",
    "                i = i + 1\n",
    "                \n",
    "                indVar = weatherVar\n",
    "\n",
    "\n",
    "                print(outcomeVar, \"~\", indVar)\n",
    "\n",
    "\n",
    "                # find: concurrent ; or lagged supplier datawet\n",
    "                X = goodsData.loc[:,(((goodsData.columns.str.contains(indVar))) | \n",
    "                                (goodsData.columns.str.contains('indQtr_')) |\n",
    "                                (goodsData.columns.str.contains('gvkey_')) | #  | \n",
    "                                (goodsData.columns.str.contains('ageTercile_')) |\n",
    "                                (goodsData.columns.str.contains('sizeTercile_')) |\n",
    "                                (goodsData.columns.str.contains('profitTercile_')) | \n",
    "                                (goodsData.columns == 'supplierTercile'))]     \n",
    "\n",
    "                X = sm.add_constant(X)\n",
    "\n",
    "                \n",
    "                firms = goodsData['gvkey']\n",
    "\n",
    "\n",
    "                y = goodsData[outcomeVar]\n",
    "\n",
    "\n",
    "                modelResults = sm.OLS(y, X).fit(cov_type='cluster',cov_kwds={'groups': firms},use_t=True)\n",
    "                pvals = modelResults.pvalues[1: 1 + len(goodsData.columns[goodsData.columns.str.contains(indVar) & goodsData.columns.str.contains('supplier_')])]\n",
    "                coeff = modelResults.params[1: 1 + len(goodsData.columns[goodsData.columns.str.contains(indVar)  & goodsData.columns.str.contains('supplier_')])]\n",
    "                errs  = modelResults.bse[1: 1 + len(goodsData.columns[goodsData.columns.str.contains(indVar)  & goodsData.columns.str.contains('supplier_')])]\n",
    "                \n",
    "                '''print(coeff)\n",
    "                print(pvals)'''\n",
    "\n",
    "\n",
    "                results.loc[i,'industry'] = ind\n",
    "\n",
    "                results.loc[i,'outcomeVar'] = outcomeVar\n",
    "                results.loc[i,'weatherVar'] = weatherVar\n",
    "\n",
    "                results.loc[i,'lag0']       = coeff[0]\n",
    "                results.loc[i,'lag1']       = coeff[1]\n",
    "                results.loc[i,'lag2']       = coeff[2]\n",
    "                results.loc[i,'lag3']       = coeff[3]\n",
    "                results.loc[i,'lag4']       = coeff[4]\n",
    "                \n",
    "                results.loc[i,'bse0']       = errs[0]\n",
    "                results.loc[i,'bse1']       = errs[1]\n",
    "                results.loc[i,'bse2']       = errs[2]\n",
    "                results.loc[i,'bse3']       = errs[3]\n",
    "                results.loc[i,'bse4']       = errs[4]\n",
    "\n",
    "                results.loc[i,'pval0']      = pvals[0]\n",
    "                results.loc[i,'pval1']      = pvals[1]\n",
    "                results.loc[i,'pval2']      = pvals[2]\n",
    "                results.loc[i,'pval3']      = pvals[3]\n",
    "                results.loc[i,'pval4']      = pvals[4]\n",
    "                \n",
    "                \n",
    "                \n",
    "                print( time.time() - start)\n",
    "\n",
    "                results.to_csv(\"../../data/indirResults_hqs_streaks.csv\")\n",
    "\n",
    "# merge in the industry names\n",
    "conversionTable = pd.read_csv(\"../../data/indMapping.csv\")\n",
    "conversionTable.dropna(inplace=True)\n",
    "conversionTable.reset_index(drop = True, inplace = True)\n",
    "\n",
    "conversionTable.head()\n",
    "\n",
    "results = results.merge(conversionTable)\n",
    "\n",
    "\n",
    "results.to_csv(\"../../data/indirResults_hqs_streaks.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_csv(\"../../data/indirResults_hqs_streaks.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weatherVars = results.weatherVar.unique()\n",
    "outcomeVars = results.outcomeVar.unique()\n",
    "\n",
    "industries = [2,17,18,28,31,40,41,42] # results.industryName.unique()\n",
    "\n",
    "for outcome in outcomeVars:\n",
    "    for weather in weatherVars:\n",
    "        # choose the elective parts of this - number of columns and the range of the axes\n",
    "        numCols = 3\n",
    "        yLims   = 0.2\n",
    "\n",
    "        # industries = results.industryName.unique()\n",
    "        rowNum = len(industries) // numCols + 1\n",
    "        colNum = numCols\n",
    "\n",
    "        fig, ax = plt.subplots(rowNum, colNum, sharex='all', sharey='all',\n",
    "                              figsize=(20,20),\n",
    "                              constrained_layout=True)\n",
    "\n",
    "        fig.suptitle('Indirect Effects: ' + outcome + ' ~ ' + weather, fontsize=36)\n",
    "\n",
    "\n",
    "\n",
    "        i = 0\n",
    "        for ind in industries:\n",
    "            rowIndex = i // numCols\n",
    "            colIndex = i % numCols\n",
    "\n",
    "\n",
    "            i   = i + 1\n",
    "\n",
    "\n",
    "            rev = results[(results.outcomeVar == outcome) & (results.weatherVar == weather) & \n",
    "                         (results.industry == ind)].reset_index()\n",
    "            indName = rev.industryName.unique()[0]\n",
    "            x   = [0,1,2,3,4]\n",
    "            y   = [rev.lag0,rev.lag1,rev.lag2,rev.lag3,rev.lag4]\n",
    "\n",
    "\n",
    "            errors = [rev.bse0,rev.bse1,rev.bse2,rev.bse3,rev.bse4]\n",
    "\n",
    "            # plt.errorbar(x,y,yerr = errors, fmt = '.k')\n",
    "            # plt.show()\n",
    "\n",
    "            '''ax[rowIndex, colIndex].text(0.5, 0.5, str((i, j)),\n",
    "                                  fontsize=18, ha='center')'''\n",
    "            ax[rowIndex, colIndex].errorbar(x,y,yerr = errors, fmt = '.k')\n",
    "            ax[rowIndex, colIndex].xaxis.grid(False)\n",
    "            ax[rowIndex, colIndex].yaxis.grid(False)\n",
    "            ax[rowIndex, colIndex].axhline(y=0)\n",
    "            ax[rowIndex, colIndex].set_ylim([-yLims, yLims])\n",
    "\n",
    "            ax[rowIndex, colIndex].yaxis.set_ticks(np.arange(-yLims, yLims + 0.1, 0.1))\n",
    "            ax[rowIndex, colIndex].xaxis.set_ticks(np.arange(0.0, 5.0, 1.0))\n",
    "\n",
    "            ax[rowIndex, colIndex].tick_params(axis='both', labelsize = 16)\n",
    "            ax[rowIndex, colIndex].set_title(indName, fontsize = 24)\n",
    "\n",
    "            # ax[rowIndex, colIndex].\n",
    "    \n",
    "        fig.savefig('indirEffects_' + outcome + '_' + weather + '.png')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "----------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Faster and More Heuristic\n",
    "The below gives us unclustered standard errors, output to a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findSE(X,reg,y):\n",
    "    N = len(X)\n",
    "    p = len(X.columns) + 1  # plus one because LinearRegression adds an intercept term\n",
    "\n",
    "    X_with_intercept = np.empty(shape=(N, p), dtype=np.float)\n",
    "    X_with_intercept[:, 0] = 1\n",
    "    X_with_intercept[:, 1:p] = X.values\n",
    "\n",
    "    y_hat = reg.predict(X)\n",
    "    residuals = y.values - y_hat\n",
    "    residual_sum_of_squares = residuals.T @ residuals\n",
    "    sigma_squared_hat = residual_sum_of_squares / (N - p)\n",
    "    var_beta_hat = np.linalg.inv(X_with_intercept.T @ X_with_intercept) * sigma_squared_hat\n",
    "\n",
    "    se0 = var_beta_hat[1, 1] ** 0.5\n",
    "    se1 = var_beta_hat[2, 2] ** 0.5\n",
    "    se2 = var_beta_hat[3, 3] ** 0.5\n",
    "    se3 = var_beta_hat[4, 4] ** 0.5\n",
    "    se4 = var_beta_hat[5, 5] ** 0.5\n",
    "    se5 = var_beta_hat[6, 6] ** 0.5\n",
    "    '''se6 = var_beta_hat[7, 7] ** 0.5\n",
    "    se7 = var_beta_hat[8, 8] ** 0.5\n",
    "    se8 = var_beta_hat[9, 9] ** 0.5'''\n",
    "    return([abs(reg.coef_[0]/se0),abs(reg.coef_[1]/se1),abs(reg.coef_[2]/se2),\n",
    "            abs(reg.coef_[3]/se3),abs(reg.coef_[4]/se4),abs(reg.coef_[5]/se5)]\n",
    "          )\n",
    "\n",
    "'''        \n",
    "abs(reg.coef_[0]/se0),\n",
    "          abs(reg.coef_[1]/se1),\n",
    "          abs(reg.coef_[2]/se2),\n",
    "          abs(reg.coef_[3]/se3),\n",
    "          abs(reg.coef_[4]/se4),\n",
    "          abs(reg.coef_[5]/se5),\n",
    "          \"SE0: \", se0,\n",
    "          \"SE1: \", se1,\n",
    "          \"SE2: \", se2,\n",
    "          \"SE3: \", se3,\n",
    "          \"SE4: \", se4,\n",
    "          \"SE5: \", se5,\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "'''cutoffVarsYr = ['0.95'] # ,'1xYr']                                    #,'1x5Yrs'] #, ] # ,'1xQtr', '1x5Qtrs'\n",
    "weatherVars  = ['precip_', 'temp_', 'precip5Days_', 'temp5Days_'] #[,]\n",
    "statVarsYr   = ['zipquant_','zipQuarterquant_']\n",
    "outcomeVars  = ['lnRev', 'revenueChange'] # ,'lnCost',  'costChange'] # [,'lnRevNormd','lnCostNormd'] # 'revenueChange' 'costChange',\n",
    "firmVars     = ['firmQtr_'] # 'gvkey'\n",
    "'''\n",
    "\n",
    "# try this by industry\n",
    "cutoffVarsYr = ['0.95'] # ,'1xYr']                                    #,'1x5Yrs'] #, ] # ,'1xQtr', '1x5Qtrs'\n",
    "weatherVars  = ['precip_', 'temp_', 'precip5Days_', 'temp5Days_'] #[,]\n",
    "statVarsYr   = ['ffquant_','indQuarterquant_']\n",
    "outcomeVars  = ['lnRev', 'revenueChange',  'lnCost',  'costChange'] # [,'lnRevNormd','lnCostNormd'] # 'revenueChange' 'costChange',\n",
    "firmVars     = ['firmQtr_']\n",
    "\n",
    "\n",
    "inds = [1, 2, 6, 7, 18, 31, 41, 42]\n",
    "\n",
    "goodsData = goodsData[~goodsData.lnRev.isna() & ~goodsData.lnCost.isna() &\n",
    "                      ~goodsData.lnCostNormd.isna() & ~goodsData.lnRevNormd.isna()]\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "results = pd.DataFrame()\n",
    "i = 0\n",
    "for ind in inds:\n",
    "    print('#######################################################################################',ind)\n",
    "    for outcomeVar in outcomeVars:\n",
    "        for weatherVar in weatherVars:\n",
    "            for statVar in statVarsYr:                     \n",
    "                for cutoffVar in cutoffVarsYr:\n",
    "                    for firmVar in firmVars:\n",
    "                        tempData = goodsData[goodsData.famafrench == ind]\n",
    "                        \n",
    "                        i = i + 1\n",
    "                        indVar = weatherVar + statVar + cutoffVar\n",
    "\n",
    "\n",
    "                        print(outcomeVar, \"~\", indVar, \"|\", firmVar)\n",
    "\n",
    "\n",
    "                        # find: concurrent ; or lagged supplier data\n",
    "                        X = tempData.loc[:,((tempData.columns.str.contains(indVar)) |\n",
    "                                          (tempData.columns.str.contains('indQtr_')) |\n",
    "                                          # (goodsData.columns.str.contains('gvkey_'))) |   # &   \n",
    "                                          # (goodsData.columns.str.contains('firmQtr_'))) |\n",
    "                                          (tempData.columns.str.contains(firmVar)))] # |\n",
    "                        '''(tempData.columns.str.contains('ageQtr_')) |\n",
    "                          (tempData.columns.str.contains('sizeQtr_')) |\n",
    "                          (tempData.columns.str.contains('profitQtr_'))]   #  & '''\n",
    "\n",
    "                                          # (goodsData.columns.str.contains('firmQtr_')))       & \n",
    "                                        # ~(goodsData.columns.str.contains('lag4')) &\n",
    "                                                                        # ~(goodsData.columns.str.contains('lag2')) & \n",
    "\n",
    "\n",
    "                        X = X[X.columns[(X.sum(axis = 0) >= 4)]]\n",
    "                        # print(X.columns)\n",
    "                        firms = tempData['gvkey']\n",
    "\n",
    "\n",
    "                        y = tempData[outcomeVar]\n",
    "\n",
    "\n",
    "                        ######################################\n",
    "                        # fit the model on this subset\n",
    "                        reg = linear_model.LinearRegression()\n",
    "                        reg.fit(X,y)\n",
    "\n",
    "\n",
    "                        # print('Coeff: ' , reg.coef_[0:5], 'SE type (looking >2): ', findSE(X,reg,y))\n",
    "                        results.loc[i,'ind'] = ind\n",
    "\n",
    "\n",
    "                        results.loc[i,'outcomeVar'] = outcomeVar\n",
    "                        results.loc[i,'weatherVar'] = weatherVar\n",
    "                        results.loc[i,'statVar']    = statVar\n",
    "                        results.loc[i,'cutoffVar']  = cutoffVar\n",
    "                        results.loc[i,'firmVar']    = firmVar\n",
    "\n",
    "\n",
    "                        results.loc[i,'lag0']       = reg.coef_[0]\n",
    "                        results.loc[i,'lag1']       = reg.coef_[1]\n",
    "                        results.loc[i,'lag2']       = reg.coef_[2]\n",
    "                        results.loc[i,'lag3']       = reg.coef_[3]\n",
    "                        results.loc[i,'lag4']       = reg.coef_[4]\n",
    "\n",
    "\n",
    "\n",
    "                        seratios = findSE(X,reg,y)\n",
    "\n",
    "                        results.loc[i,'ratio0']       = seratios[0]\n",
    "                        results.loc[i,'ratio1']       = seratios[1]\n",
    "                        results.loc[i,'ratio2']       = seratios[2]\n",
    "                        results.loc[i,'ratio3']       = seratios[3]\n",
    "                        results.loc[i,'ratio4']       = seratios[4]\n",
    "\n",
    "                        # print(results)\n",
    "\n",
    "                        print(time.time() - start)\n",
    "\n",
    "                        print('*******************************************************************')\n",
    "                    \n",
    "results.to_csv(\"../../data/results_notNormd.csv\")\n",
    "\n",
    "\n",
    "# merge in the industry names\n",
    "conversionTable = pd.read_csv(\"../../data/indMapping.csv\")\n",
    "conversionTable.dropna(inplace=True)\n",
    "conversionTable.reset_index(drop = True, inplace = True)\n",
    "\n",
    "conversionTable.head()\n",
    "\n",
    "results = results.merge(conversionTable)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
