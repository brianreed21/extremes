{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brianreed/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:30: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  method='lar', copy_X=True, eps=np.finfo(np.float).eps,\n",
      "/Users/brianreed/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:167: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  method='lar', copy_X=True, eps=np.finfo(np.float).eps,\n",
      "/Users/brianreed/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:284: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_Gram=True, verbose=0,\n",
      "/Users/brianreed/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:862: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "/Users/brianreed/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1101: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "/Users/brianreed/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1127: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, positive=False):\n",
      "/Users/brianreed/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1362: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "/Users/brianreed/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1602: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "/Users/brianreed/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1738: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, positive=False):\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import os\n",
    "import re\n",
    "\n",
    "import scipy\n",
    "\n",
    "import collections\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "import geopandas as gpd\n",
    "\n",
    "import numpy as np\n",
    " \n",
    "from difflib import get_close_matches\n",
    "\n",
    "from fuzzywuzzy import process\n",
    "from fuzzywuzzy import fuzz\n",
    "from sklearn import linear_model\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from linearmodels import PanelOLS, FamaMacBeth\n",
    "from scipy import stats\n",
    "\n",
    "import itertools\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from numpy.linalg import matrix_rank\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grab Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/brianreed/Documents/supplyChain/extremes/extremesAnalysisCode'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(105706, 487) Index(['X', 'gvkey', 'datadate', 'year', 'qtr', 'companyName', 'curcdq',\n",
      "       'assets', 'cash', 'costGoodsSold',\n",
      "       ...\n",
      "       'excessRainNational', 'excessHeat90PlusEmp', 'excessRainNationalEmp',\n",
      "       'indSeason', 'tempTercile_byQtr', 'precipTercile_byQtr',\n",
      "       'tempQuintile_byQtr', 'precipQuintile_byQtr', 'tempDecile_byQtr',\n",
      "       'precipDecile_byQtr'],\n",
      "      dtype='object', length=487)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brianreed/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "goodsData = pd.read_csv(\"../../data/companyData/goodsData.csv\").drop(columns = {'Unnamed: 0'})\n",
    "goodsData['year'] = goodsData.year.astype('str').str.slice(0,4).astype('int64')\n",
    "goodsData.columns = goodsData.columns.str.replace(\"0.95\", \"Extreme\")\n",
    "goodsData = goodsData[~goodsData.lnOpIncNormd.isna() & ~goodsData.lnRevNormd.isna() & \\\n",
    "         ~goodsData.lnCostNormd.isna() & ~goodsData.lnStockClose.isna()]\n",
    "print(goodsData.shape, goodsData.columns)\n",
    "\n",
    "firms = goodsData['gvkey']\n",
    "\n",
    "goodsData['excessHeat'] = goodsData.extremeHeatDaily - 9\n",
    "goodsData['excessRain'] = goodsData.extremePrecipDaily - 9\n",
    "\n",
    "goodsData['excessHeatEmp'] = goodsData.extremeHeatDays_wtd - 9\n",
    "goodsData['excessRainEmp'] = goodsData.extremePrecipDays_wtd - 9\n",
    "\n",
    "goodsData['excessHeatMax'] = goodsData.extremeHeatDays_max - 9\n",
    "goodsData['excessRainMax'] = goodsData.extremePrecipDays_max - 9\n",
    "\n",
    "goodsData['excessHeat90Plus'] = goodsData.heatDays90Plus - 9\n",
    "goodsData['excessRainNational'] = goodsData.precip95National - 9\n",
    "\n",
    "goodsData['excessHeat90PlusEmp']   = goodsData.heatDays90Plus_wtd - 9\n",
    "goodsData['excessRainNationalEmp'] = goodsData.precip95National_wtd - 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "goodsData = goodsData[goodsData.gvkey.isin(list(goodsData.gvkey.value_counts()[(goodsData.gvkey.value_counts() > 8)].index))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['agForFish',\n",
       " 'construction',\n",
       " 'manu',\n",
       " 'mining',\n",
       " 'retail',\n",
       " 'transportUtilities',\n",
       " 'wholesale']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(goodsData.indGroup.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------\n",
    "\n",
    "### play around with the industry regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gvkey</th>\n",
       "      <th>year</th>\n",
       "      <th>ggroup</th>\n",
       "      <th>gind</th>\n",
       "      <th>gsector</th>\n",
       "      <th>gsubind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1004</td>\n",
       "      <td>1997</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>201010.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20101010.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1004</td>\n",
       "      <td>1998</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>201010.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20101010.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1004</td>\n",
       "      <td>1999</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>201010.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20101010.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1004</td>\n",
       "      <td>2000</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>201010.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20101010.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1004</td>\n",
       "      <td>2001</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>201010.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20101010.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    gvkey  year  ggroup      gind gsector     gsubind\n",
       "0    1004  1997  2010.0  201010.0    20.0  20101010.0\n",
       "2    1004  1998  2010.0  201010.0    20.0  20101010.0\n",
       "6    1004  1999  2010.0  201010.0    20.0  20101010.0\n",
       "10   1004  2000  2010.0  201010.0    20.0  20101010.0\n",
       "14   1004  2001  2010.0  201010.0    20.0  20101010.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gics = pd.read_csv(\"../../data/companyData/gicsCodes.csv\").\\\n",
    "    astype({'ggroup': 'str',\n",
    "           'gind': 'str',\n",
    "           'gsector': 'str',\n",
    "           'gsubind': 'str'}).\\\n",
    "    rename(columns = {'fyearq': 'year'})[['gvkey','year','ggroup','gind','gsector','gsubind']].drop_duplicates()\n",
    "gics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getResults(outcome, weatherVar, controls, goodsData):\n",
    "    equation = outcome + ' ~ ' + weatherVar + ' + ' + controls\n",
    "\n",
    "    mod = smf.ols(formula = equation, data = goodsData[~(goodsData.empMx_temp_zipQuarter_95.isna())]).fit() \n",
    "    # cov_type='cluster',cov_kwds={'groups': firms})             \n",
    "\n",
    "    # convert this into a much more condensed version\n",
    "    coeffs  = pd.DataFrame(mod.params,   columns = ['coeffs'])\n",
    "    pvalues = pd.DataFrame(mod.pvalues, columns = ['pvals'])\n",
    "\n",
    "\n",
    "    pvalues = pvalues[pvalues.index.str.contains(weatherVar[0:4])]\n",
    "    coeffs  = coeffs[coeffs.index.str.contains(weatherVar[0:4])]\n",
    "\n",
    "\n",
    "    resultsTemp = pd.concat([coeffs,pvalues],axis = 1)\n",
    "    resultsTemp['variable'] = outcome\n",
    "    # resultsTemp.loc['upperVariable'] = ['^' + , '*********'] \n",
    "    \n",
    "    return(resultsTemp)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gsector</th>\n",
       "      <th>gsectorDesc</th>\n",
       "      <th>ggroup</th>\n",
       "      <th>ggroupDesc</th>\n",
       "      <th>gind</th>\n",
       "      <th>gindDesc</th>\n",
       "      <th>gsubind</th>\n",
       "      <th>gsubindDesc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.0</td>\n",
       "      <td>Energy</td>\n",
       "      <td>1010.0</td>\n",
       "      <td>Energy</td>\n",
       "      <td>101010.0</td>\n",
       "      <td>Energy Equipment &amp; Services</td>\n",
       "      <td>10101010.0</td>\n",
       "      <td>Oil &amp; Gas Drilling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.0</td>\n",
       "      <td>Energy</td>\n",
       "      <td>1010.0</td>\n",
       "      <td>Energy</td>\n",
       "      <td>101010.0</td>\n",
       "      <td>Energy Equipment &amp; Services</td>\n",
       "      <td>10101020.0</td>\n",
       "      <td>Oil &amp; Gas Equipment &amp; Services</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.0</td>\n",
       "      <td>Energy</td>\n",
       "      <td>1010.0</td>\n",
       "      <td>Energy</td>\n",
       "      <td>101020.0</td>\n",
       "      <td>Oil, Gas &amp; Consumable Fuels</td>\n",
       "      <td>10102010.0</td>\n",
       "      <td>Integrated Oil &amp; Gas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10.0</td>\n",
       "      <td>Energy</td>\n",
       "      <td>1010.0</td>\n",
       "      <td>Energy</td>\n",
       "      <td>101020.0</td>\n",
       "      <td>Oil, Gas &amp; Consumable Fuels</td>\n",
       "      <td>10102020.0</td>\n",
       "      <td>Oil &amp; Gas Exploration &amp; Production</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10.0</td>\n",
       "      <td>Energy</td>\n",
       "      <td>1010.0</td>\n",
       "      <td>Energy</td>\n",
       "      <td>101020.0</td>\n",
       "      <td>Oil, Gas &amp; Consumable Fuels</td>\n",
       "      <td>10102030.0</td>\n",
       "      <td>Oil &amp; Gas Refining &amp; Marketing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  gsector gsectorDesc  ggroup ggroupDesc      gind  \\\n",
       "0    10.0      Energy  1010.0     Energy  101010.0   \n",
       "2    10.0      Energy  1010.0     Energy  101010.0   \n",
       "4    10.0      Energy  1010.0     Energy  101020.0   \n",
       "6    10.0      Energy  1010.0     Energy  101020.0   \n",
       "8    10.0      Energy  1010.0     Energy  101020.0   \n",
       "\n",
       "                      gindDesc     gsubind                         gsubindDesc  \n",
       "0  Energy Equipment & Services  10101010.0                  Oil & Gas Drilling  \n",
       "2  Energy Equipment & Services  10101020.0      Oil & Gas Equipment & Services  \n",
       "4  Oil, Gas & Consumable Fuels  10102010.0                Integrated Oil & Gas  \n",
       "6  Oil, Gas & Consumable Fuels  10102020.0  Oil & Gas Exploration & Production  \n",
       "8  Oil, Gas & Consumable Fuels  10102030.0      Oil & Gas Refining & Marketing  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gicsMap = pd.read_csv(\"../../data/companyData/gicsMap.csv\").drop(columns = {'Unnamed: 8'})\n",
    "\n",
    "# every complete descriptor shows up with 2 lines of descriptive text\n",
    "# show here the first of those and then fill in all the other values vertically\n",
    "gicsMap = gicsMap[~gicsMap.gsubind.isna()].fillna(method='ffill').\\\n",
    "    astype({'ggroup': 'str',\n",
    "           'gind': 'str',\n",
    "           'gsector': 'str',\n",
    "           'gsubind': 'str'}).drop_duplicates()\n",
    "allGICS = gics.merge(gicsMap)\n",
    "\n",
    "gicsMap.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sic2</th>\n",
       "      <th>sic2Desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Agricultural Production - Crops</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Agricultural Production - Livestock and Animal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>Agricultural Services</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>Forestry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>Fishing, Hunting and Trapping</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sic2                                           sic2Desc\n",
       "0     1                    Agricultural Production - Crops\n",
       "1     2  Agricultural Production - Livestock and Animal...\n",
       "2     7                              Agricultural Services\n",
       "3     8                                           Forestry\n",
       "4     9                      Fishing, Hunting and Trapping"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sicsMap = pd.read_csv(\"../../data/companyData/sic_2_digit_codes.csv\").\\\n",
    "    rename(columns = {'Code Value': 'sic2', 'Description' : 'sic2Desc'})\n",
    "sicsMap.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         45\n",
       "1         13\n",
       "2         13\n",
       "3         45\n",
       "4         13\n",
       "          ..\n",
       "107345    59\n",
       "107388    28\n",
       "107389    28\n",
       "107390    28\n",
       "107391    28\n",
       "Name: sic2, Length: 103624, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goodsData.sic2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "goodsData = goodsData.merge(allGICS).merge(sicsMap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Capital Goods                                                 14210\n",
       "Technology Hardware & Equipment                               12569\n",
       "Pharmaceuticals, Biotechnology & Life Sciences                11043\n",
       "Energy                                                        10670\n",
       "Health Care Equipment & Services                               8530\n",
       "Materials                                                      7402\n",
       "Consumer Durables & Apparel                                    5845\n",
       "Utilities                                                      5651\n",
       "Semiconductors & Semiconductor Equipment                       5424\n",
       "Food, Beverage & Tobacco                                       3436\n",
       "Transportation                                                 3219\n",
       "Household & Personal Products                                  2320\n",
       "Commercial  & Professional Services                            2295\n",
       "Automobiles & Components                                       2025\n",
       "Retailing                                                      1876\n",
       "Telecommunication Services                                     1837\n",
       "Media & Entertainment                                          1250\n",
       "Consumer Services                                              1041\n",
       "Software & Services                                             915\n",
       "Media (discontinued effective close of September 28, 2018)      848\n",
       "Food & Staples Retailing                                        271\n",
       "Real Estate                                                     210\n",
       "Diversified Financials                                          154\n",
       "Name: ggroupDesc, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goodsData.ggroupDesc.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Energy', 'Industrials', 'Health Care', 'Consumer Staples',\n",
       "       'Utilities', 'Communication Services', 'Consumer Discretionary',\n",
       "       'Information Technology', 'Materials', 'Real Estate', 'Financials'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "industries = goodsData.gsectorDesc.unique()\n",
    "industries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "goodsData['hottest'] = 1*(goodsData.tempTercile == 3)\n",
    "goodsData['coldest'] = 1*(goodsData.tempTercile == 1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "goodsData.to_csv(\"../../data/companyData/goodsData_withIndDefs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         2003_1\n",
       "1         2003_2\n",
       "2         2003_3\n",
       "3         2003_4\n",
       "4         2004_1\n",
       "           ...  \n",
       "103036    2013_3\n",
       "103037    2013_4\n",
       "103038    2014_1\n",
       "103039    2014_2\n",
       "103040    2014_3\n",
       "Name: yearQtr, Length: 103041, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goodsData.yearQtr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################\n",
      "                       coeffs     pvals    variable quarter\n",
      "excessHeat90PlusEmp -0.000098  0.000002  opIncNormd     all\n",
      "##################\n",
      "                 coeffs     pvals    variable quarter\n",
      "excessRainEmp -0.000145  0.051639  opIncNormd     all\n",
      "##################\n",
      "                     coeffs  pvals     variable quarter\n",
      "excessHeat90PlusEmp     NaN    NaN  opIncChange     all\n",
      "##################\n",
      "               coeffs  pvals     variable quarter\n",
      "excessRainEmp     NaN    NaN  opIncChange     all\n",
      "##################\n",
      "                       coeffs     pvals      variable quarter\n",
      "excessHeat90PlusEmp -0.000195  0.011001  lnOpIncNormd     all\n",
      "##################\n",
      "                 coeffs     pvals      variable quarter\n",
      "excessRainEmp -0.001296  0.000003  lnOpIncNormd     all\n",
      "##################\n",
      "                       coeffs     pvals  variable quarter\n",
      "excessHeat90PlusEmp  0.000035  0.249102  revNormd     all\n",
      "##################\n",
      "                 coeffs     pvals  variable quarter\n",
      "excessRainEmp -0.000076  0.490132  revNormd     all\n",
      "##################\n",
      "                     coeffs  pvals   variable quarter\n",
      "excessHeat90PlusEmp     NaN    NaN  revChange     all\n",
      "##################\n",
      "##################\n",
      "##################\n",
      "                 coeffs     pvals    variable quarter\n",
      "excessRainEmp -0.000072  0.330069  lnRevNormd     all\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"allResults = pd.concat(resultList)\\n\\nallResults.to_csv('../results/resultsByInd.csv')\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultList = []\n",
    "results    = pd.DataFrame()   \n",
    "quarters   = goodsData.qtr.unique()\n",
    "\n",
    "\n",
    "outcomes = ['opIncNormd', 'opIncChange', 'lnOpIncNormd',\n",
    "           'revNormd',    'revChange',   'lnRevNormd'] \n",
    "\n",
    "\n",
    "weatherVars = ['excessHeat90PlusEmp', 'excessRainEmp']\n",
    "\n",
    "\n",
    "controls = 'C(indSeason) + C(yearQtr) + C(gvkey) + C(ageTercile) + C(profitTercile) + C(sizeTercile)'\n",
    "\n",
    "\n",
    "for outcome in outcomes:\n",
    "    for weatherVar in weatherVars:\n",
    "        \n",
    "        print('##################')\n",
    "        \n",
    "        try: \n",
    "            resultsTemp = getResults(outcome, weatherVar, controls, goodsData)\n",
    "\n",
    "            resultsTemp['quarter']  = 'all'\n",
    "            # resultsTemp['n']        = tempData.shape[0]\n",
    "            print(resultsTemp) #outcome, weatherVar, controls, goodsData\n",
    "\n",
    "            results = pd.concat([results,resultsTemp], axis = 0)\n",
    "        except:\n",
    "            pass\n",
    "                    \n",
    "\n",
    "\n",
    "resultList.append(results)\n",
    "'''allResults = pd.concat(resultList)\n",
    "\n",
    "allResults.to_csv('../results/resultsByInd.csv')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "industryDefs = ['sic2Desc', 'indGroup', 'ggroupDesc','gindDesc','gsectorDesc','gsubindDesc']\n",
    "resultList = []\n",
    "results    = pd.DataFrame()   \n",
    "quarters   = goodsData.qtr.unique()\n",
    "\n",
    "for indDef in industryDefs:\n",
    "    print('****************************************************')\n",
    "    print(indDef)\n",
    "\n",
    "\n",
    "    industries = goodsData[indDef].unique()\n",
    "\n",
    "    outcomes = ['lnOpIncNormd', 'lnRevNormd']#, 'lnCostNormd']#, 'lnStockClose']\n",
    "\n",
    "    weatherVars = ['excessHeat', 'excessHeatEmp','excessHeatMax', 'excessHeat90Plus',\n",
    "                   'excessHeat:C(coldest)', 'excessHeatEmp:C(coldest)',\n",
    "                   'excessHeatMax:C(coldest)','excessHeat90Plus:C(hottest)',\n",
    "                   'excessRain', 'excessRainEmp','excessRainMax', 'excessRainNational',\n",
    "                   'extremeHeatQuarterly', 'extremePrecipQuarterly',\n",
    "                   'excessRain:C(coldest)', 'excessRainEmp:C(coldest)','excessRainMax:C(coldest)', 'excessRainNational:C(coldest)',\n",
    "                   'extremeHeatQuarterly:C(coldest)', 'extremePrecipQuarterly:C(coldest)']\n",
    "    # ['extremeHeatDaily', 'extremePrecipDaily', 'heatDays90Plus', 'precip95National']\n",
    "\n",
    "\n",
    "    controls = 'C(indSeason) + C(yearQtr) + C(gvkey) + C(ageTercile) + C(profitTercile) + C(sizeTercile)'\n",
    "\n",
    "\n",
    "\n",
    "    for outcome in outcomes:\n",
    "        for weatherVar in weatherVars:\n",
    "            print('##################')\n",
    "            for ind in industries:\n",
    "                # for qtr in quarters:\n",
    "                try: \n",
    "                    print(ind)\n",
    "\n",
    "                    tempData = goodsData[(goodsData[indDef] == ind)] # & (goodsData.qtr == qtr)]\n",
    "\n",
    "                    resultsTemp = getResults(outcome, weatherVar, controls, tempData)\n",
    "\n",
    "                    resultsTemp['indDef']   = indDef\n",
    "                    resultsTemp['industry'] = ind\n",
    "                    resultsTemp['quarter']  = 'all'\n",
    "                    resultsTemp['n']        = tempData.shape[0]\n",
    "                    print(resultsTemp) #outcome, weatherVar, controls, goodsData\n",
    "\n",
    "                    results = pd.concat([results,resultsTemp], axis = 0)\n",
    "                except:\n",
    "                    pass\n",
    "                    \n",
    "\n",
    "\n",
    "resultList.append(results)\n",
    "allResults = pd.concat(resultList)\n",
    "\n",
    "allResults.to_csv('../results/resultsByInd.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    '''\n",
    "    ['extremeHeatDaily', 'extremePrecipDaily','heatDays90Plus',\n",
    "                   'extremeHeatDays_wtd', 'extremePrecipDays_wtd','precip95National']\n",
    "                   'extremeHeatQuarterly', 'extremePrecipQuarterly', # extreme on average\n",
    "                  # 'heatAnomalyQuarterly', 'precipAnomalyQuarterly', # quarter above average\n",
    "                  # 'heatAnomalyDaily', 'precipAnomalyDaily', # days above average\n",
    "                   'streak90Plus', # days above 90\n",
    "                  'heat95National','precip95National', # national weights\n",
    "                  # 'heat99National','precip99National', # national weights\n",
    "                  'extremeHeatDays_wtd', 'extremePrecipDays_wtd', # establishments, wtd avg\n",
    "                  'extremeHeatDays_max', 'extremePrecipDays_max']\n",
    "    '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allResults.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of five airlines to plot\n",
    "weatherVars = list(allResults.index.unique())\n",
    "plt.figure(figsize = (10, 5))\n",
    "\n",
    "# Iterate through the five airlines\n",
    "for weather in ['excessHeat', 'excessHeatEmp', 'excessHeat90Plus']:\n",
    "    # Subset to the airline\n",
    "    subset = allResults[(allResults.index == weather) & (allResults.pvals < 0.1)]\n",
    "    \n",
    "    # Draw the density plot\n",
    "    sns.distplot(subset.coeffs, hist = False, kde = True,\n",
    "                 kde_kws = {'linewidth': 1},\n",
    "                 label = weather)\n",
    "    \n",
    "# Plot formatting\n",
    "\n",
    "plt.title('Density Plot with Multiple Airlines')\n",
    "plt.xlabel('Delay (min)')\n",
    "plt.xlim([-0.05, 0.05])\n",
    "plt.ylabel('Density')\n",
    "plt.legend(prop={'size': 16}, title = 'Airline')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getResults_byInd(outcome, weatherVar, controls):\n",
    "    equation = outcome + ' ~ ' + weatherVar + '*C(indGroup) + ' + controls\n",
    "\n",
    "    mod = smf.ols(formula = equation, data = goodsData[~(goodsData.empMx_temp_zipQuarter_95.isna())]).fit() \n",
    "    # cov_type='cluster',cov_kwds={'groups': firms})             \n",
    "\n",
    "    # convert this into a much more condensed version\n",
    "    coeffs  = pd.DataFrame(mod.params,   columns = ['coeffs'])\n",
    "    pvalues = pd.DataFrame(mod.pvalues, columns = ['pvals'])\n",
    "\n",
    "\n",
    "    pvalues = pvalues[pvalues.index.str.contains(weatherVar[0:4])]\n",
    "    coeffs  = coeffs[coeffs.index.str.contains(weatherVar[0:4])]\n",
    "\n",
    "\n",
    "    resultsTemp = pd.concat([coeffs,pvalues],axis = 1)\n",
    "\n",
    "    resultsTemp.loc['upperVariable'] = ['^' + outcome, '*********'] \n",
    "    \n",
    "    return(resultsTemp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getResults_bySeason(outcome, weatherVar, controls):\n",
    "    equation = outcome + ' ~ ' + weatherVar + '*C(qtr) + ' + controls\n",
    "\n",
    "    mod = smf.ols(formula = equation, data = goodsData[~(goodsData.empMx_temp_zipQuarter_95.isna())]).fit() \n",
    "    # cov_type='cluster',cov_kwds={'groups': firms})             \n",
    "\n",
    "    # convert this into a much more condensed version\n",
    "    coeffs  = pd.DataFrame(mod.params,   columns = ['coeffs'])\n",
    "    pvalues = pd.DataFrame(mod.pvalues, columns = ['pvals'])\n",
    "\n",
    "\n",
    "    pvalues = pvalues[pvalues.index.str.contains(weatherVar[0:4])]\n",
    "    coeffs  = coeffs[coeffs.index.str.contains(weatherVar[0:4])]\n",
    "\n",
    "\n",
    "    resultsTemp = pd.concat([coeffs,pvalues],axis = 1)\n",
    "\n",
    "    resultsTemp.loc['upperVariable'] = ['^' + outcome, '*********'] \n",
    "    \n",
    "    return(resultsTemp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simpler Results\n",
    "One response across industries and across seasons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "\n",
    "outcomes = ['lnOpIncNormd', 'lnRevNormd']# , 'lnCostNormd', 'lnStockClose']\n",
    "weatherVars = ['excessHeat', 'excessHeatEmp','excessHeatMax', 'excessHeat90Plus',\n",
    "               'excessRain', 'excessRainEmp','excessRainMax', 'excessRainNational',\n",
    "               'extremeHeatQuarterly', 'extremePrecipQuarterly']\n",
    "\n",
    "\n",
    "controls = 'C(indSeason) + C(yearQtr) + C(gvkey)' # + C(ageTercile) + C(profitTercile) + C(sizeTercile)'\n",
    "#  + C(ageTercile) + C(profitTercile) + C(sizeTercile)'\n",
    "\n",
    "resultList = []\n",
    "results    = pd.DataFrame()\n",
    "\n",
    "for weatherVar in weatherVars:\n",
    "    for outcome in outcomes:\n",
    "        try:\n",
    "            print(outcome)\n",
    "\n",
    "            resultsTemp = getResults(outcome, weatherVar, controls, goodsData)\n",
    "            print(resultsTemp)\n",
    "\n",
    "            results = pd.concat([results,resultsTemp], axis = 1)\n",
    "            print(time.time() - start)\n",
    "            \n",
    "            \n",
    "        except:\n",
    "            print('No Dice! ' + outcome + \"~\" + weatherVar)\n",
    "            pass\n",
    "    \n",
    "    \n",
    "    \n",
    "resultList.append(results)\n",
    "\n",
    "\n",
    "allResults_byInd = pd.concat(resultList, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## By Seasons\n",
    "Do all of the above on subsamples. Stagger this: do precipitation results first, then for each season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "\n",
    "outcomes    = ['lnOpIncNormd'] #, 'lnRevNormd'] # , 'lnStockClose']\n",
    "weatherVars = ['excessHeat', 'excessRain', 'excessHeat90Plus','extremeHeatQuarterly', 'extremePrecipQuarterly']\n",
    "''''excessHeatEmp','excessHeatMax', \n",
    "                'excessRainEmp','excessRainMax', 'excessRainNational','''\n",
    "\n",
    "\n",
    "''''excessHeat:C(coldest)', 'excessHeatEmp:C(coldest)',\n",
    "               'excessHeatMax:C(coldest)','excessHeat90Plus:C(hottest)','''\n",
    "\n",
    "'''toKeep      = goodsData.gvkey.value_counts().index[(goodsData.gvkey.value_counts()  <= 4*19) & \\\n",
    "                                                   (goodsData.gvkey.value_counts()  >  4)]\n",
    "                                              \n",
    "'''\n",
    "quarters    = list(goodsData.qtr.unique())\n",
    "\n",
    "controls = 'C(indGroup) + C(year) + C(gvkey)' # + C(ageTercile) + C(profitTercile) + C(sizeTercile)'\n",
    "\n",
    "resultList = []\n",
    "results    = pd.DataFrame()\n",
    "\n",
    "for outcome in outcomes:\n",
    "    for weatherVar in weatherVars:\n",
    "        for quarter in quarters:\n",
    "            print(quarter)\n",
    "            print(goodsData[(goodsData.qtr == quarter)].shape[0])\n",
    "            \n",
    "            try:\n",
    "                print(outcome)\n",
    "                \n",
    "                tempData = goodsData[(goodsData.qtr == quarter)]\n",
    "                \n",
    "                resultsTemp = getResults(outcome,weatherVar,controls,tempData)\n",
    "                resultsTemp['quarter'] = quarter\n",
    "                resultsTemp['indDef']   = 'indGroup'\n",
    "                resultsTemp['industry'] = 'all'\n",
    "                resultsTemp['n']        = tempData.shape[0]\n",
    "                \n",
    "                \n",
    "                print(resultsTemp)\n",
    "\n",
    "                results = pd.concat([results,resultsTemp], axis = 1)\n",
    "                print(time.time() - start)\n",
    "\n",
    "\n",
    "            except:\n",
    "                print('No Dice! ' + outcome + \"~\" + weatherVar)\n",
    "                pass\n",
    "    \n",
    "    \n",
    "    \n",
    "resultList.append(results)\n",
    "\n",
    "allResults_bySeason = pd.concat(resultList, axis=0)\n",
    "\n",
    "\n",
    "allResults_bySeason.to_csv('../results/resultsByQtr.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## By Industries\n",
    "first do the responses on an ind-by-ind level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "\n",
    "outcomes    = ['lnOpIncNormd', 'lnRevNormd', 'lnCostNormd'] # , 'lnStockClose']\n",
    "weatherVars = ['extremeHeatDaily','heatDays90Plus','extremeHeatDays_wtd',\n",
    "              'extremePrecipDaily','precip95National','extremePrecipDays_wtd']\n",
    "\n",
    "\n",
    "'''['extremeHeatDaily','heatAnomalyDaily','extremeHeatQuarterly','heatAnomalyQuarterly',\n",
    "               'heatDays90Plus','heat95National','heat99National','extremeHeatDays_wtd','extremeHeatDays_max',\n",
    "               'extremePrecipDaily','precipAnomalyDaily','extremePrecipQuarterly','precipAnomalyQuarterly',\n",
    "               'precip95National', 'precip99National','extremePrecipDays_wtd','extremePrecipDays_max']'''\n",
    "\n",
    "toKeep      = goodsData.gvkey.value_counts().index[(goodsData.gvkey.value_counts()  <= 4*19) & \\\n",
    "                                                   (goodsData.gvkey.value_counts()  >  4)]\n",
    "                                              \n",
    "\n",
    "quarters    = list(goodsData.qtr.unique())\n",
    "industries  = list(goodsData.indGroup.unique())\n",
    "\n",
    "\n",
    "controls = 'C(indGroup) + C(year) + C(gvkey)  + C(ageTercile) + C(profitTercile) + C(sizeTercile)'\n",
    "\n",
    "resultList = []\n",
    "results    = pd.DataFrame()\n",
    "\n",
    "for weatherVar in weatherVars:\n",
    "    print(weatherVar, '*****************')\n",
    "    for outcome in outcomes:\n",
    "        print('************************')\n",
    "        for industry in industries:\n",
    "            print(industry, '**********')\n",
    "\n",
    "            try:\n",
    "                print(outcome)\n",
    "\n",
    "                resultsTemp = getResults(outcome,weatherVar,controls,goodsData[(goodsData.indGroup == industry) & \\\n",
    "                                                (goodsData.gvkey.isin(toKeep))])\n",
    "                resultsTemp['ind'] = industry\n",
    "                print(resultsTemp)\n",
    "\n",
    "                results = pd.concat([results,resultsTemp], axis = 1)\n",
    "                print(time.time() - start)\n",
    "\n",
    "\n",
    "            except:\n",
    "                print('No Dice! ' + outcome + \"~\" + weatherVar)\n",
    "                pass\n",
    "    \n",
    "    \n",
    "    \n",
    "resultList.append(results)\n",
    "\n",
    "\n",
    "allResults_byIndustry = pd.concat(resultList, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allResults_byIndustry.to_csv(\"../../data/companyData/allResults_byIndustry.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "try by quarter; it seems a little tough to identify effects by industry by season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "\n",
    "outcomes    = ['lnOpIncNormd', 'lnRevNormd', 'lnCostNormd'] # , 'lnStockClose']\n",
    "weatherVars = ['extremeHeatDaily','heatDays90Plus','extremeHeatDays_wtd',\n",
    "              'extremePrecipDaily','precip95National','extremePrecipDays_wtd']\n",
    "\n",
    "\n",
    "'''['extremeHeatDaily','heatAnomalyDaily','extremeHeatQuarterly','heatAnomalyQuarterly',\n",
    "               'heatDays90Plus','heat95National','heat99National','extremeHeatDays_wtd','extremeHeatDays_max',\n",
    "               'extremePrecipDaily','precipAnomalyDaily','extremePrecipQuarterly','precipAnomalyQuarterly',\n",
    "               'precip95National', 'precip99National','extremePrecipDays_wtd','extremePrecipDays_max']'''\n",
    "\n",
    "toKeep      = goodsData.gvkey.value_counts().index[(goodsData.gvkey.value_counts()  <= 4*19) & \\\n",
    "                                                   (goodsData.gvkey.value_counts()  >  4)]\n",
    "                                              \n",
    "\n",
    "quarters    = list(goodsData.qtr.unique())\n",
    "industries  = list(goodsData.indGroup.unique())\n",
    "\n",
    "\n",
    "controls = 'C(indGroup) + C(year) + C(gvkey)' #  + C(ageTercile) + C(profitTercile) + C(sizeTercile)'\n",
    "\n",
    "resultList = []\n",
    "results    = pd.DataFrame()\n",
    "\n",
    "for weatherVar in weatherVars:\n",
    "    print(weatherVar, '*****************')\n",
    "    for outcome in outcomes:\n",
    "        print('************************')\n",
    "        for industry in industries:\n",
    "            print(industry, '**********')\n",
    "            for quarter in quarters:\n",
    "                print(quarter)\n",
    "\n",
    "\n",
    "                try:\n",
    "                    print(outcome)\n",
    "\n",
    "                    resultsTemp = getResults(outcome,weatherVar,controls,goodsData[(goodsData.indGroup == industry) & \\\n",
    "                                                                                   (goodsData.qtr == quarter) & \\\n",
    "                                                    (goodsData.gvkey.isin(toKeep))])\n",
    "                    resultsTemp['qtr'] = quarter\n",
    "                    print(resultsTemp)\n",
    "\n",
    "                    results = pd.concat([results,resultsTemp], axis = 1)\n",
    "                    print(time.time() - start)\n",
    "\n",
    "\n",
    "                except:\n",
    "                    print('No Dice! ' + outcome + \"~\" + weatherVar)\n",
    "                    pass\n",
    "    \n",
    "    \n",
    "    \n",
    "resultList.append(results)\n",
    "\n",
    "\n",
    "allResults_bySeason = pd.concat(resultList, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allResults_bySeason.to_csv(\"../../data/companyData/allResults_bySeason.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "below we have more on the interactions front. i don't think these are super promising but are worth keeping in line and in mind.\n",
    "\n",
    "-------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## By Background Climate\n",
    "first, terciles of this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "\n",
    "outcomes = ['lnOpIncNormd', 'lnRevNormd'] #, 'lnCostNormd'] #, 'lnStockClose']\n",
    "weatherVars = ['extremeHeatDaily*C(tempTercile)', 'heatDays90Plus*C(tempTercile)', # 'streak90Plus*C(tempTercile)',  # days of extremes\n",
    "              #'extremeHeatQuarterly*C(tempTercile)', 'extremePrecipQuarterly*C(precipTercile)', # extreme on average\n",
    "              #'heatAnomalyQuarterly*C(tempTercile)', 'precipAnomalyQuarterly*C(precipTercile)', # quarter above average\n",
    "              # 'heatAnomalyDaily*C(tempTercile)', 'precipAnomalyDaily*C(precipTercile)', # days above average\n",
    "              # 'heat95National*C(tempTercile)', # days above 90\n",
    "              'extremePrecipDaily*C(precipTercile)',\n",
    "              'extremeHeatDays_wtd*C(tempTercile)', 'extremePrecipDays_wtd*C(precipTercile)']\n",
    "              #'heat99National*C(tempTercile)','precip99National*C(precipTercile)']\n",
    "\n",
    "\n",
    "controls = 'C(indGroup):C(qtr) + C(yearQtr) + C(gvkey)' #  + C(ageTercile) + C(profitTercile) + C(sizeTercile)'\n",
    "\n",
    "resultList = []\n",
    "results    = pd.DataFrame()\n",
    "mglResults = pd.DataFrame()\n",
    "\n",
    "\n",
    "for weatherVar in weatherVars:\n",
    "    for outcome in outcomes:\n",
    "        try:\n",
    "            print(outcome)\n",
    "\n",
    "            resultsTemp = getResults(outcome, weatherVar, controls, goodsData)\n",
    "            print(resultsTemp)\n",
    "\n",
    "            results = pd.concat([results,resultsTemp], axis = 1)\n",
    "            print(time.time() - start)\n",
    "            \n",
    "            # put this into a dataframe\n",
    "            mglEffects = pd.DataFrame()\n",
    "            effects    = []\n",
    "            effects.append(resultsTemp[resultsTemp.index == resultsTemp.index[0]].coeffs[0])\n",
    "            for coeff in resultsTemp.index[1:-1]:\n",
    "                effects.append(resultsTemp[resultsTemp.index == resultsTemp.index[0]].coeffs[0] + resultsTemp[resultsTemp.index == coeff].coeffs[0])\n",
    "\n",
    "            # put these together \n",
    "            mglEffects['coeff']   = resultsTemp.index[0:-1]\n",
    "            mglEffects['effects'] = effects\n",
    "            print(mglEffects)\n",
    "            # and stash it for later\n",
    "            mglResults = pd.concat([mglResults, mglEffects], axis = 1)\n",
    "            \n",
    "            \n",
    "        except:\n",
    "            print('No Dice! ' + outcome + \"~\" + weatherVar)\n",
    "            pass\n",
    "    \n",
    "    \n",
    "    \n",
    "resultList.append(results)\n",
    "\n",
    "\n",
    "allResults_byTercile = pd.concat(resultList, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# next, do it by just hot/cold, wet/dry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "\n",
    "outcomes = ['lnOpIncNormd', 'lnRevNormd', 'lnCostNormd', 'lnStockClose']\n",
    "weatherVars = ['extremeHeatDaily*C(tempHalf)', 'extremePrecipDaily*C(precipHalf)', # days of extremes\n",
    "              'extremeHeatQuarterly*C(tempHalf)', 'extremePrecipQuarterly*C(precipHalf)', # extreme on average\n",
    "              'heatDays90Plus*C(tempHalf)', 'streak90Plus*C(tempHalf)']\n",
    "\n",
    "\n",
    "controls = 'C(indGroup):C(qtr) + C(yearQtr) + C(gvkey)' #  + C(ageTercile) + C(profitTercile) + C(sizeTercile)'\n",
    "\n",
    "resultList = []\n",
    "results    = pd.DataFrame()\n",
    "mglResults = pd.DataFrame()\n",
    "\n",
    "\n",
    "for weatherVar in weatherVars:\n",
    "    for outcome in outcomes:\n",
    "        try:\n",
    "            print(outcome)\n",
    "\n",
    "            resultsTemp = getResults(outcome, weatherVar, controls, goodsData)\n",
    "            print(resultsTemp)\n",
    "\n",
    "            results = pd.concat([results,resultsTemp], axis = 1)\n",
    "            print(time.time() - start)\n",
    "            \n",
    "            # put this into a dataframe\n",
    "            mglEffects = pd.DataFrame()\n",
    "            effects    = []\n",
    "            effects.append(resultsTemp[resultsTemp.index == resultsTemp.index[0]].coeffs[0])\n",
    "            for coeff in resultsTemp.index[1:-1]:\n",
    "                effects.append(resultsTemp[resultsTemp.index == resultsTemp.index[0]].coeffs[0] + resultsTemp[resultsTemp.index == coeff].coeffs[0])\n",
    "\n",
    "            # put these together \n",
    "            mglEffects['coeff']   = resultsTemp.index[0:-1]\n",
    "            mglEffects['effects'] = effects\n",
    "            print(mglEffects)\n",
    "            # and stash it for later\n",
    "            mglResults = pd.concat([mglResults, mglEffects], axis = 1)\n",
    "            \n",
    "        except:\n",
    "            print('No Dice! ' + outcome + \"~\" + weatherVar)\n",
    "            pass\n",
    "    \n",
    "    \n",
    "    \n",
    "resultList.append(results)\n",
    "\n",
    "\n",
    "allResults_byTercile = pd.concat(resultList, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at either terciles or halves when defining extremes by industry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "\n",
    "outcomes = ['lnOpIncNormd', 'lnRevNormd', 'lnCostNormd', 'lnStockClose']\n",
    "\n",
    "weatherVars = ['extremeHeatDaily*C(tempHalf_byInd)', 'extremePrecipDaily*C(precipHalf_byInd)', # days of extremes\n",
    "              'extremeHeatQuarterly*C(tempHalf_byInd)', 'extremePrecipQuarterly*C(precipHalf_byInd)', # extreme on average\n",
    "              'heatDays90Plus*C(tempHalf_byInd)', 'streak90Plus*C(tempHalf_byInd)',\n",
    "              'extremeHeatDaily*C(tempTercile_byInd)', 'extremePrecipDaily*C(precipTercile_byInd)', # days of extremes\n",
    "              'extremeHeatQuarterly*C(tempTercile_byInd)', 'extremePrecipQuarterly*C(precipTercile_byInd)', # extreme on average\n",
    "              'heatDays90Plus*C(tempTercile_byInd)', 'streak90Plus*C(tempTercile_byInd)']\n",
    "\n",
    "\n",
    "controls = 'C(indGroup):C(qtr) + C(yearQtr) + C(gvkey)' #  + C(ageTercile) + C(profitTercile) + C(sizeTercile)'\n",
    "\n",
    "resultList = []\n",
    "results    = pd.DataFrame()\n",
    "mglResults = pd.DataFrame()\n",
    "\n",
    "\n",
    "for weatherVar in weatherVars:\n",
    "    for outcome in outcomes:\n",
    "        try:\n",
    "            print(outcome)\n",
    "\n",
    "            resultsTemp = getResults(outcome, weatherVar, controls, goodsData)\n",
    "            print(resultsTemp)\n",
    "\n",
    "            results = pd.concat([results,resultsTemp], axis = 1)\n",
    "            print(time.time() - start)\n",
    "            \n",
    "            # put this into a dataframe\n",
    "            mglEffects = pd.DataFrame()\n",
    "            effects    = []\n",
    "            effects.append(resultsTemp[resultsTemp.index == resultsTemp.index[0]].coeffs[0])\n",
    "            for coeff in resultsTemp.index[1:-1]:\n",
    "                effects.append(resultsTemp[resultsTemp.index == resultsTemp.index[0]].coeffs[0] + resultsTemp[resultsTemp.index == coeff].coeffs[0])\n",
    "\n",
    "            # put these together \n",
    "            mglEffects['coeff']   = resultsTemp.index[0:-1]\n",
    "            mglEffects['effects'] = effects\n",
    "            print(mglEffects)\n",
    "            # and stash it for later\n",
    "            mglResults = pd.concat([mglResults, mglEffects], axis = 1)\n",
    "            \n",
    "            \n",
    "        except:\n",
    "            print('No Dice! ' + outcome + \"~\" + weatherVar)\n",
    "            pass\n",
    "    \n",
    "    \n",
    "    \n",
    "resultList.append(results)\n",
    "\n",
    "\n",
    "allResults_byTercile = pd.concat(resultList, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Industries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "\n",
    "# try the marginal effects here\n",
    "outcome    = 'lnOpIncNormd'\n",
    "weatherVar = 'extremeHeatDaily'\n",
    "controls   = 'C(indGroup):C(qtr) + C(yearQtr) + C(gvkey)' #  + C(ageTercile) + C(profitTercile) + C(sizeTercile)'\n",
    "\n",
    "\n",
    "equation = outcome + ' ~ ' + weatherVar + '*C(indGroup) + ' + controls\n",
    "\n",
    "\n",
    "mod = smf.ols(formula = equation, data = goodsData[~(goodsData.empMx_temp_zipQuarter_95.isna())]).fit() \n",
    "\n",
    "print(time.time() - start)\n",
    "\n",
    "\n",
    "# convert this into a much more condensed version\n",
    "coeffs  = pd.DataFrame(mod.params,   columns = ['coeffs'])\n",
    "pvalues = pd.DataFrame(mod.pvalues, columns = ['pvals'])\n",
    "\n",
    "\n",
    "pvalues = pvalues[pvalues.index.str.contains(weatherVar[0:4])]\n",
    "coeffs  = coeffs[coeffs.index.str.contains(weatherVar[0:4])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "\n",
    "outcomes = ['lnOpIncNormd', 'lnRevNormd', 'lnCostNormd', 'lnStockClose']\n",
    "\n",
    "weatherVars = ['extremeHeatDaily', 'extremePrecipDaily',\n",
    "               'heatDays90Plus', 'streak90Plus', \n",
    "               'heat95National','precip95National',\n",
    "               'heat99National','precip99National']\n",
    "\n",
    "controls = 'C(indGroup):C(qtr) + C(yearQtr) + C(gvkey)' #  + C(ageTercile) + C(profitTercile) + C(sizeTercile)'\n",
    "\n",
    "resultList = []\n",
    "results    = pd.DataFrame()\n",
    "mglResults = pd.DataFrame()\n",
    "\n",
    "for weatherVar in weatherVars:\n",
    "    for outcome in outcomes:\n",
    "        try:\n",
    "            print(outcome)\n",
    "\n",
    "            resultsTemp = getResults_byInd(outcome, weatherVar, controls)\n",
    "            print(resultsTemp)\n",
    "\n",
    "            results = pd.concat([results,resultsTemp], axis = 1)\n",
    "            print(time.time() - start)\n",
    "            \n",
    "            #####\n",
    "            # put this into a dataframe\n",
    "            mglEffects = pd.DataFrame()\n",
    "            effects    = []\n",
    "            effects.append(resultsTemp[resultsTemp.index == resultsTemp.index[0]].coeffs[0])\n",
    "            for coeff in resultsTemp.index[1:-1]:\n",
    "                effects.append(resultsTemp[resultsTemp.index == resultsTemp.index[0]].coeffs[0] + resultsTemp[resultsTemp.index == coeff].coeffs[0])\n",
    "\n",
    "            # put these together \n",
    "            mglEffects['coeff']   = resultsTemp.index[0:-1]\n",
    "            mglEffects['effects'] = effects\n",
    "            print(mglEffects)\n",
    "            # and stash it for later\n",
    "            mglResults = pd.concat([mglResults, mglEffects], axis = 1)\n",
    "            \n",
    "            \n",
    "        except:\n",
    "            print('No Dice! ' + outcome + \"~\" + weatherVar)\n",
    "            pass\n",
    "    \n",
    "    \n",
    "    \n",
    "resultList.append(results)\n",
    "\n",
    "\n",
    "allResults_byInd = pd.concat(resultList, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for coeff in resultsTemp.index[1:-1]:\n",
    "    print(coeff) \n",
    "\n",
    "    print(resultsTemp[resultsTemp.index == resultsTemp.index[0]].coeffs[0] + resultsTemp[resultsTemp.index == coeff].coeffs[0])\n",
    "\n",
    "    # effects.append(resultsTemp[resultsTemp.index == resultsTemp.index[0]].coeffs[0] + resultsTemp[resultsTemp.index == coeff].coeffs[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seasons\n",
    "First do this by season, then just check that it's not snow\n",
    "\n",
    "~(goodsData.qtr == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "\n",
    "outcomes    = ['lnOpIncNormd', 'lnRevNormd', 'lnCostNormd', 'lnStockClose']\n",
    "weatherVars = ['extremeHeatDaily', 'extremePrecipDaily',\n",
    "               'heatDays90Plus', 'streak90Plus', \n",
    "              'heat95National','precip95National',\n",
    "              'heat99National','precip99National']\n",
    "\n",
    "\n",
    "controls = 'C(indGroup):C(qtr) + C(yearQtr) + C(gvkey)' #  + C(ageTercile) + C(profitTercile) + C(sizeTercile)'\n",
    "\n",
    "resultList = []\n",
    "results    = pd.DataFrame()\n",
    "\n",
    "for weatherVar in weatherVars:\n",
    "    for outcome in outcomes:\n",
    "        try:\n",
    "            print(outcome)\n",
    "\n",
    "            resultsTemp = getResults_bySeason(outcome, weatherVar, controls)\n",
    "            print(resultsTemp)\n",
    "\n",
    "            results = pd.concat([results,resultsTemp], axis = 1)\n",
    "            print(time.time() - start)\n",
    "            \n",
    "            \n",
    "            # put this into a dataframe\n",
    "            mglEffects = pd.DataFrame()\n",
    "            effects    = []\n",
    "            effects.append(resultsTemp[resultsTemp.index == resultsTemp.index[0]].coeffs[0])\n",
    "            for coeff in resultsTemp.index[1:-1]:\n",
    "                effects.append(resultsTemp[resultsTemp.index == resultsTemp.index[0]].coeffs[0] + resultsTemp[resultsTemp.index == coeff].coeffs[0])\n",
    "\n",
    "            # put these together \n",
    "            mglEffects['coeff']   = resultsTemp.index[0:-1]\n",
    "            mglEffects['effects'] = effects\n",
    "            print(mglEffects)\n",
    "            # and stash it for later\n",
    "            mglResults = pd.concat([mglResults, mglEffects], axis = 1)\n",
    "            \n",
    "        except:\n",
    "            print('No Dice! ' + outcome + \"~\" + weatherVar)\n",
    "            pass\n",
    "    \n",
    "    \n",
    "    \n",
    "resultList.append(results)\n",
    "\n",
    "\n",
    "allResults_bySeason = pd.concat(resultList, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Allow for other season-specific responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "\n",
    "outcomes = ['lnOpIncNormd', 'lnRevNormd', 'lnCostNormd', 'lnStockClose']\n",
    "\n",
    "\n",
    "weatherVars = ['extremeHeat*C(qtr)', 'extremePrecip*C(qtr)']\n",
    "\n",
    "\n",
    "'''['extremeHeat','extremeHeat_wtd','extremePrecip_max','extremeHeat*C(tempTercile)','extremePrecip*C(precipTercile)',\n",
    "               'extremeHeat_wtd*C(tempTercile)','extremePrecip_wtd*C(precipTercile)','extremeHeat_max*C(tempTercile)',\n",
    "               'extremePrecip_max*C(precipTercile)']'''\n",
    "\n",
    "\n",
    "controls = 'C(indGroup):C(qtr) + C(yearQtr) + C(gvkey)' #  + C(ageTercile) + C(profitTercile) + C(sizeTercile)'\n",
    "\n",
    "resultList = []\n",
    "results    = pd.DataFrame()\n",
    "\n",
    "for weatherVar in weatherVars:\n",
    "    for outcome in outcomes:\n",
    "        try:\n",
    "            print(outcome)\n",
    "\n",
    "            equation = outcome + ' ~ ' + weatherVar + ' + ' + controls\n",
    "\n",
    "            mod = smf.ols(formula = equation, data = goodsData[~(goodsData.empMx_temp_zipQuarter_95.isna())]).fit() # cov_type='cluster',cov_kwds={'groups': firms})             \n",
    "\n",
    "            print(time.time() - start) \n",
    "\n",
    "\n",
    "\n",
    "            # convert this into a much more condensed version\n",
    "            coeffs  = pd.DataFrame(mod.params,   columns = ['coeffs'])\n",
    "            pvalues = pd.DataFrame(mod.pvalues, columns = ['pvals'])\n",
    "\n",
    "\n",
    "\n",
    "            pvalues = pvalues[pvalues.index.str.contains(weatherVar[0:4])]\n",
    "            coeffs  = coeffs[coeffs.index.str.contains(weatherVar[0:4])]\n",
    "\n",
    "\n",
    "            resultsTemp = pd.concat([coeffs,pvalues],axis = 1)\n",
    "\n",
    "            resultsTemp.loc['upperVariable'] = ['^' + outcome, '*********'] \n",
    "\n",
    "            results = pd.concat([results,resultsTemp], axis = 1)\n",
    "\n",
    "            print(resultsTemp)\n",
    "\n",
    "\n",
    "            '''print(coeffs)\n",
    "            print(pvalues)'''\n",
    "            \n",
    "        except:\n",
    "            print('No Dice! ' + outcome + \"~\" + weatherVar)\n",
    "            pass\n",
    "    \n",
    "    \n",
    "    \n",
    "resultList.append(results)\n",
    "\n",
    "\n",
    "allResults = pd.concat(resultList, axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smf.ols(formula = 'lnOpIncNormd ~ extremeHeat + C(indGroup):C(qtr) + C(yearQtr) + C(gvkey)', data = goodsData).fit().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allResults.to_csv(\"../../data/companyData/allResults_precip.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following are the initial results. This is when we have 3 lags and tercile is defined It roughly seems like:\n",
    "- higher temperature is beneficial in places at lower levels of temperature\n",
    "- higher precipitation is still harmful in places at lower levels of precipitation\n",
    "- high levels of both might be harmful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "resultList = []\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "outcomes = ['lnOpIncNormd', 'lnRevNormd', 'lnCostNormd', 'lnStockClose']\n",
    "\n",
    "weatherVars = ['extremeHeat',\n",
    "               'extremePrecip',\n",
    "               'heat90Plus',\n",
    "               'extremeHeat*C(tempTercile)',\n",
    "               'extremePrecip*C(precipTercile)',\n",
    "               'C(streak90Plus)',\n",
    "               'heat90Plus*C(tempTercile)',\n",
    "               'C(streak90Plus)*C(tempTercile)'\n",
    "              ]\n",
    "\n",
    "\n",
    "# 'temp_zipWeek95_99 + lag1_temp_zipWeek95_99 + lag2_temp_zipWeek95_99 ', \n",
    "# 'temp_zipMonth95_99 + lag1_temp_zipMonth95_99 + lag2_temp_zipMonth95_99 ',\n",
    "# 'temp_zipQuarter95_99 + lag1_temp_zipQuarter95_99 + lag2_temp_zipQuarter95_99 ']\n",
    "\n",
    "controls = 'C(indGroup)*C(qtr) + C(yearQtr) + C(gvkey)' #  + C(ageTercile) + C(profitTercile) + C(sizeTercile)'\n",
    "\n",
    "for weatherVar in weatherVars:\n",
    "    print(\"***************\")\n",
    "    print(weatherVar)\n",
    "    results = pd.DataFrame()\n",
    "\n",
    "    for outcome in outcomes:            \n",
    "        equation = outcome + ' ~ ' + weatherVar + ' + ' + controls\n",
    "        print(equation)\n",
    "        \n",
    "        try:\n",
    "            firms = goodsData['gvkey']\n",
    "\n",
    "            mod = smf.ols(formula = equation, data = goodsData).fit() # cov_type='cluster',cov_kwds={'groups': firms})             \n",
    "\n",
    "            print(time.time() - start) \n",
    "\n",
    "            # convert this into a much more condensed version\n",
    "            coeffs = pd.DataFrame(mod.params,   columns = ['coeffs'])\n",
    "            pvalues = pd.DataFrame(mod.pvalues, columns = ['pvals'])\n",
    "\n",
    "            coeffs = coeffs[coeffs.index.str.contains(weatherVar[0:4])]\n",
    "            pvalues = pvalues[pvalues.index.str.contains(weatherVar[0:4])]\n",
    "\n",
    "            resultsTemp = pd.concat([coeffs,pvalues],axis = 1)\n",
    "\n",
    "            resultsTemp.loc['upperVariable'] = ['^' + outcome, '*********'] \n",
    "\n",
    "            results = pd.concat([results,resultsTemp], axis = 1)\n",
    "\n",
    "            print(resultsTemp)\n",
    "        except:\n",
    "            print('No Dice! ' + outcome + \"~\" + weatherVar)\n",
    "            pass\n",
    "\n",
    "    resultList.append(results)\n",
    "\n",
    "\n",
    "allResults = pd.concat(resultList, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultList = []\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "outcomes = ['lnOpIncNormd', 'lnRevNormd', 'lnCostNormd', 'lnStockClose']\n",
    "\n",
    "weatherVars = ['extremeHeat',\n",
    "               'extremePrecip',\n",
    "               'heat90Plus',\n",
    "               'extremeHeat*C(tempTercile)',\n",
    "               'extremePrecip*C(precipTercile)',\n",
    "               'C(streak90Plus)',\n",
    "               'heat90Plus*C(tempTercile)',\n",
    "               'C(streak90Plus)*C(tempTercile)'\n",
    "              ]\n",
    "\n",
    "\n",
    "# 'temp_zipWeek95_99 + lag1_temp_zipWeek95_99 + lag2_temp_zipWeek95_99 ', \n",
    "# 'temp_zipMonth95_99 + lag1_temp_zipMonth95_99 + lag2_temp_zipMonth95_99 ',\n",
    "# 'temp_zipQuarter95_99 + lag1_temp_zipQuarter95_99 + lag2_temp_zipQuarter95_99 ']\n",
    "\n",
    "controls = 'C(indGroup)*C(qtr) + C(yearQtr) + C(gvkey)  + C(ageTercile) + C(profitTercile) + C(sizeTercile)'\n",
    "\n",
    "for weatherVar in weatherVars:\n",
    "    print(\"***************\")\n",
    "    print(weatherVar)\n",
    "    results = pd.DataFrame()\n",
    "\n",
    "    for outcome in outcomes:            \n",
    "        equation = outcome + ' ~ ' + weatherVar + ' + ' + controls\n",
    "        print(equation)\n",
    "        \n",
    "        try:\n",
    "            firms = goodsData['gvkey']\n",
    "\n",
    "            mod = smf.ols(formula = equation, data = goodsData).fit() # cov_type='cluster',cov_kwds={'groups': firms})             \n",
    "\n",
    "            print(time.time() - start) \n",
    "\n",
    "            # convert this into a much more condensed version\n",
    "            coeffs = pd.DataFrame(mod.params,   columns = ['coeffs'])\n",
    "            pvalues = pd.DataFrame(mod.pvalues, columns = ['pvals'])\n",
    "\n",
    "            coeffs = coeffs[coeffs.index.str.contains(weatherVar[0:4])]\n",
    "            pvalues = pvalues[pvalues.index.str.contains(weatherVar[0:4])]\n",
    "\n",
    "            resultsTemp = pd.concat([coeffs,pvalues],axis = 1)\n",
    "\n",
    "            resultsTemp.loc['upperVariable'] = ['^' + outcome, '*********'] \n",
    "\n",
    "            results = pd.concat([results,resultsTemp], axis = 1)\n",
    "\n",
    "            print(resultsTemp)\n",
    "        except:\n",
    "            print('No Dice! ' + outcome + \"~\" + weatherVar)\n",
    "            pass\n",
    "\n",
    "    resultList.append(results)\n",
    "\n",
    "\n",
    "allResults = pd.concat(resultList, axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions\n",
    "Take revenue all the way through."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome  = 'lnRevNormd'\n",
    "weather  = 'extremePrecip'\n",
    "controls = 'C(indGroup):C(qtr) + C(yearQtr) + C(gvkey) + C(ageTercile) + C(profitTercile) + C(sizeTercile)'\n",
    "\n",
    "equation = outcome + ' ~ ' + weather + ' + ' + controls\n",
    " \n",
    "print(equation)\n",
    "\n",
    "precipMod = smf.ols(formula = equation, data = goodsData).fit()\n",
    "\n",
    "print(precipMod.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge the additional precip data into here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precipAvg = pd.read_csv(\"../../data/companyData/precipExtraDays.csv\").drop(columns = {'Unnamed: 0'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precipPreds = goodsData.merge(precipAvg)\n",
    "\n",
    "precipPreds.loc[precipPreds['qtr'] == 1, 'extremePrecip'] = precipPreds.Q1 + precipPreds.Q4\n",
    "precipPreds.loc[precipPreds['qtr'] == 2, 'extremePrecip'] = precipPreds.Q2 + precipPreds.Q1\n",
    "precipPreds.loc[precipPreds['qtr'] == 3, 'extremePrecip'] = precipPreds.Q3 + precipPreds.Q2\n",
    "precipPreds.loc[precipPreds['qtr'] == 4, 'extremePrecip'] = precipPreds.Q4 + precipPreds.Q3\n",
    "# precipPreds['extremePrecip'] = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precipPreds.extremePrecip.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precipPreds['changes'] = precipMod.params.extremePrecip*precipPreds.extremePrecip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirEffects = precipPreds['changes'].groupby(precipPreds.state).mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirEffects.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirEffects.changes.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goodsData_moreExtremes = goodsData.copy()\n",
    "goodsData_moreExtremes['extremeHeat']   += 10\n",
    "goodsData_moreExtremes['extremePrecip'] += 10\n",
    "\n",
    "ypred_moreExtremes = tempMod.predict(goodsData_moreExtremes)\n",
    "\n",
    "plt.hist(ypred_moreExtremes - ypred, bins = 100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indirect Effects\n",
    "Let's look at the effects on a customer of extremes at its suppliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goodsData = pd.read_csv(\"../../data/companyData/goodsData_largestSupplierData_indirEffects.csv\").drop(columns = {'Unnamed: 0'})\n",
    "goodsData.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allWeather_withLags = pd.read_csv(\"../../data/companyData/allWeather_withLags_allZips.csv\").drop(columns = {'Unnamed: 0'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goodsData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(goodsData.dist > 250)/goodsData.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# goodsData = pd.read_csv(\"../../data/companyData/goodsData_supplierData.csv\").drop(columns = {'Unnamed: 0'})\n",
    "goodsData['year']      = goodsData.year.astype('str').str.slice(0,4).astype('int64')\n",
    "goodsData['firstYear'] = goodsData.firstYear.astype('str').str.slice(0,4).astype('int64')\n",
    "goodsData['lastYear']  = goodsData.lastYear.astype('str').str.slice(0,4).astype('int64')\n",
    "\n",
    "\n",
    "goodsData.columns = goodsData.columns.str.replace(\"0.95\", \"Extreme\")\n",
    "\n",
    "print(goodsData.shape, goodsData.columns)\n",
    "\n",
    "firms = goodsData['gvkey']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in goodsData.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goodsData['supplierConc'] = goodsData['dist'] > 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "\n",
    "outcome  = 'lnRevNormd'\n",
    "weather  = 'supplier_extremePrecip'#*C(supplierConc)'\n",
    "controls = 'C(indGroup):C(qtr) + C(yearQtr) + C(gvkey) + C(ageTercile) + C(profitTercile) + C(sizeTercile)'\n",
    "\n",
    "equation = outcome + ' ~ ' + weather + ' + ' + controls\n",
    " \n",
    "print(equation)\n",
    "\n",
    "precipModIndir = smf.ols(formula = equation, data = goodsData[goodsData.dist < 250]).fit()\n",
    "\n",
    "print(time.time() - start) \n",
    "\n",
    "\n",
    "print(precipModIndir.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "# outcomes = ['lnOpIncNormd', 'lnRevNormd', 'lnCostNormd', 'lnStockClose']\n",
    "\n",
    "outcome  = 'lnOpIncNormd'\n",
    "weather  = 'supplier_extremePrecip '\n",
    "controls = 'C(indGroup):C(qtr) + C(yearQtr) + C(gvkey) + C(ageTercile) + C(profitTercile) + C(sizeTercile)'\n",
    "\n",
    "equation = outcome + ' ~ ' + weather + ' + ' + controls\n",
    " \n",
    "print(equation)\n",
    "\n",
    "precipModIndir = smf.ols(formula = equation, data = goodsData).fit()\n",
    "\n",
    "print(time.time() - start) \n",
    "\n",
    "\n",
    "print(precipModIndir.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precipAvg = pd.read_csv(\"../../data/companyData/precipExtraDays.csv\").\\\n",
    "    drop(columns = {'Unnamed: 0'}).rename(columns = {'zipcode': 'supplier_zipcode'})\n",
    "\n",
    "\n",
    "precipAvg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precipPreds = goodsData.merge(precipAvg)\n",
    "\n",
    "precipPreds.loc[precipPreds['qtr'] == 1, 'extremePrecip'] = precipPreds.Q1 + precipPreds.Q4\n",
    "precipPreds.loc[precipPreds['qtr'] == 2, 'extremePrecip'] = precipPreds.Q2 + precipPreds.Q1\n",
    "precipPreds.loc[precipPreds['qtr'] == 3, 'extremePrecip'] = precipPreds.Q3 + precipPreds.Q2\n",
    "precipPreds.loc[precipPreds['qtr'] == 4, 'extremePrecip'] = precipPreds.Q4 + precipPreds.Q3\n",
    "# precipPreds['extremePrecip'] = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precipPreds.extremePrecip.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " precipModIndir.params.supplier_extremePrecip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precipPreds['changes'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precipPreds['changes'] = precipModIndir.params.supplier_extremePrecip*precipPreds.extremePrecip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stateChangesIndir = pd.DataFrame(precipPreds['changes'].groupby(precipPreds.state).mean().reset_index())\n",
    "stateChangesIndir.rename(columns = {'changes': 'indirChanges'}, inplace = True)\n",
    "\n",
    "stateChangesIndir.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stateChangesIndir.indirChanges.stadescribe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allEffects = dirEffects.merge(stateChangesIndir)\n",
    "\n",
    "allEffects.sort_values(by = ['changes'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allEffects.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (24, 16))\n",
    "\n",
    "\n",
    "plt.bar(allEffects.state,allEffects.changes,      \n",
    "        label = 'Direct Effect',   color = 'palegoldenrod')\n",
    "'''plt.bar(allEffects.state,allEffects.indirChanges, \n",
    "        label = 'Indirect Effect', color = 'firebrick')'''\n",
    "\n",
    "plt.title('State Average Effect of Projected Change in Extreme Precipitation, 2020-2040',\n",
    "          fontsize = 36, pad = 24)\n",
    "\n",
    "plt.xlabel('State', fontsize = 24, labelpad = 36)\n",
    "plt.xticks(fontsize=16)\n",
    "\n",
    "plt.ylabel('Effect on log Revenue/Assets', fontsize = 24, labelpad = 24)\n",
    "plt.yticks(fontsize=20)\n",
    "\n",
    "plt.legend(fontsize = 24, loc = 'upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see the same thing here with temperature: positive correlation overall, with a negative effect on the warmer terciles and a positive effect on the coolest one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "# outcomes = ['lnOpIncNormd', 'lnRevNormd', 'lnCostNormd', 'lnStockClose']\n",
    "\n",
    "\n",
    "outcome  = 'lnOpIncNormd'\n",
    "weather  = 'supplier_heat90Plus'\n",
    "controls = 'C(indGroup):C(qtr) + C(yearQtr) + C(gvkey) + C(ageTercile) + C(profitTercile) + C(sizeTercile)'\n",
    "\n",
    "equation = outcome + ' ~ ' + weather + ' + ' + controls\n",
    " \n",
    "print(equation)\n",
    "\n",
    "tempMod = smf.ols(formula = equation, data = goodsData).fit()\n",
    "\n",
    "print(time.time() - start) \n",
    "\n",
    "\n",
    "print(tempMod.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "outcome  = 'lnOpIncNormd'\n",
    "weather  = 'C(supplierTempTercile)*(supplier_heat90Plus)'\n",
    "controls = 'C(indGroup):C(qtr) + C(yearQtr) + C(gvkey) + C(ageTercile) + C(profitTercile) + C(sizeTercile)'\n",
    "\n",
    "equation = outcome + ' ~ ' + weather + ' + ' + controls\n",
    " \n",
    "print(equation)\n",
    "\n",
    "tempMod = smf.ols(formula = equation, data = goodsData).fit()\n",
    "\n",
    "print(time.time() - start) \n",
    "\n",
    "\n",
    "print(tempMod.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do the same as we did below, making a dataframe that summarizes a lot of the results. For now just do: \n",
    "- extreme heat\n",
    "- extreme precip\n",
    "- both of above, with breakdown by tercile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultList = []\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "outcomes = ['lnOpIncNormd', 'lnRevNormd', 'lnCostNormd', 'lnStockClose']\n",
    "\n",
    "weatherVars = ['supplier_extremePrecip',\n",
    "               'supplier_extremeHeat',\n",
    "               'supplier_heat90Plus'\n",
    "              ]\n",
    "\n",
    "\n",
    "# 'temp_zipWeek95_99 + lag1_temp_zipWeek95_99 + lag2_temp_zipWeek95_99 ', \n",
    "# 'temp_zipMonth95_99 + lag1_temp_zipMonth95_99 + lag2_temp_zipMonth95_99 ',\n",
    "# 'temp_zipQuarter95_99 + lag1_temp_zipQuarter95_99 + lag2_temp_zipQuarter95_99 ']\n",
    "\n",
    "controls = 'C(indGroup)*C(qtr) + C(yearQtr) + C(gvkey)'\n",
    "\n",
    "for weatherVar in weatherVars:\n",
    "    print(\"***************\")\n",
    "    print(weatherVar)\n",
    "    results = pd.DataFrame()\n",
    "\n",
    "    for outcome in outcomes:            \n",
    "        equation = outcome + ' ~ ' + weatherVar + ' + ' + controls\n",
    "        print(equation)\n",
    "        \n",
    "        try:\n",
    "            mod = smf.ols(formula = equation, data = goodsData).fit()             \n",
    "\n",
    "            print(time.time() - start) \n",
    "\n",
    "            # convert this into a much more condensed version\n",
    "            coeffs = pd.DataFrame(mod.params,   columns = ['coeffs'])\n",
    "            pvalues = pd.DataFrame(mod.pvalues, columns = ['pvals'])\n",
    "\n",
    "            coeffs = coeffs[coeffs.index.str.contains(weatherVar[0:4])]\n",
    "            pvalues = pvalues[pvalues.index.str.contains(weatherVar[0:4])]\n",
    "\n",
    "            resultsTemp = pd.concat([coeffs,pvalues],axis = 1)\n",
    "\n",
    "            resultsTemp.loc['upperVariable'] = ['^' + outcome, '*********'] \n",
    "\n",
    "            results = pd.concat([results,resultsTemp], axis = 1)\n",
    "\n",
    "            print(resultsTemp)\n",
    "        except:\n",
    "            print('No Dice! ' + outcome + \"~\" + weatherVar)\n",
    "            pass\n",
    "\n",
    "    resultList.append(results)\n",
    "\n",
    "\n",
    "allResults = pd.concat(resultList, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultList = []\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "outcomes = ['lnOpIncNormd', 'lnRevNormd', 'lnCostNormd', 'lnStockClose']\n",
    "\n",
    "weatherVars = ['supplier_extremePrecip',\n",
    "               'supplier_extremeHeat',\n",
    "               'supplier_heat90Plus',\n",
    "               'supplier_streak90Plus',\n",
    "               'supplier_extremePrecip*C(supplierPrecipTercile)',\n",
    "               'supplier_extremeHeat*C(supplierTempTercile)',\n",
    "               'supplier_heat90Plus*C(supplierTempTercile)',\n",
    "               'supplier_streak90Plus*C(supplierTempTercile)'\n",
    "              ]\n",
    "\n",
    "\n",
    "# 'temp_zipWeek95_99 + lag1_temp_zipWeek95_99 + lag2_temp_zipWeek95_99 ', \n",
    "# 'temp_zipMonth95_99 + lag1_temp_zipMonth95_99 + lag2_temp_zipMonth95_99 ',\n",
    "# 'temp_zipQuarter95_99 + lag1_temp_zipQuarter95_99 + lag2_temp_zipQuarter95_99 ']\n",
    "\n",
    "controls = 'C(indGroup)*C(qtr) + C(yearQtr) + C(gvkey) + C(ageTercile) + C(profitTercile) + C(sizeTercile)'\n",
    "\n",
    "for weatherVar in weatherVars:\n",
    "    print(\"***************\")\n",
    "    print(weatherVar)\n",
    "    results = pd.DataFrame()\n",
    "\n",
    "    for outcome in outcomes:            \n",
    "        equation = outcome + ' ~ ' + weatherVar + ' + ' + controls\n",
    "        print(equation)\n",
    "        \n",
    "        try:\n",
    "            mod = smf.ols(formula = equation, data = goodsData).fit()             \n",
    "\n",
    "            print(time.time() - start) \n",
    "\n",
    "            # convert this into a much more condensed version\n",
    "            coeffs = pd.DataFrame(mod.params,   columns = ['coeffs'])\n",
    "            pvalues = pd.DataFrame(mod.pvalues, columns = ['pvals'])\n",
    "\n",
    "            coeffs = coeffs[coeffs.index.str.contains(weatherVar[0:4])]\n",
    "            pvalues = pvalues[pvalues.index.str.contains(weatherVar[0:4])]\n",
    "\n",
    "            resultsTemp = pd.concat([coeffs,pvalues],axis = 1)\n",
    "\n",
    "            resultsTemp.loc['upperVariable'] = ['^' + outcome, '*********'] \n",
    "\n",
    "            results = pd.concat([results,resultsTemp], axis = 1)\n",
    "\n",
    "            print(resultsTemp)\n",
    "        except:\n",
    "            print('No Dice! ' + outcome + \"~\" + weatherVar)\n",
    "            pass\n",
    "\n",
    "    resultList.append(results)\n",
    "\n",
    "\n",
    "allResults = pd.concat(resultList, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Direct Effects\n",
    "Look at the effects on the suppliers when they're affected directly.\n",
    "\n",
    "## Complete Dataset\n",
    "### At HQs\n",
    "\n",
    "The below gives us the full, clustered standard errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultList[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, do the basics: days of extreme precipitation and (separately) extreme temperature, with 3 lags. We include a balance of time and industry-specific controls, fewer than are in the other regressions but generally allowing for a time trend, firm-specific trends, industry-seasonal trends, and profit, size, and age characteristics. We don't have time-specific trends across firms or industries but it's not clear that these would really change over the 10 years of the sample.\n",
    "\n",
    "\n",
    "\n",
    "There are a couple of background facts that I'm relying on here: \n",
    "- the 1x year, 1x5 years, etc variables might be too rare to really pick up an effect.\n",
    "- it's possible that lower tiers, or less extreme extremes, might matter too. may want to try to pick up a lower threshold as well. \n",
    "- the normalized variables (divided by lagged assets) seem to be more sensitive / response than just growth and just log-levels. this is likely because of something like the fact that this helps equalize for differences in the size of the firms in a way that neither log nor growth does. \n",
    "\n",
    "\n",
    "\n",
    "there are a couple of things to remember with these results:\n",
    "- the company size/age/profitability terciles don't make a lick of difference\n",
    "- precipitation seems to matter, period, for cumulative number of days\n",
    "- temperature might need a longer streak for the effect to happen\n",
    "\n",
    "\n",
    "\n",
    "a few things come out more in the heterogeneity analyses:\n",
    "- it seems like the local-relative extremes matter especially at the upper ends of the distributions. this is a little counterintuitive but i think the story is something like the following: we expect that places with higher average temperatures would have higher ''95th percentile events'', and places with lower average temperatures might have lower ''95th percentile events'', that might actually not be that extreme. \n",
    "- we would expect the heatBin:extremeTemp(Precip) measure to show an opposite result if the extreme definition is an absolute one and not a relative one (larger effect in places with lower normal temps (precip) // lower effect in places with higher normal temps (precip)) because it's closer to their baseline & closer to what they might expect.\n",
    "- there's not much with the industry-specific results? it could be that the data are currently too diffuse or too small to really \n",
    "\n",
    "\n",
    "\n",
    "questions:\n",
    "- are there other moments of distributions or other ways to measure shifts in extremes?\n",
    "- how should i best approach the industry-specific regressions? - separate regressions or interaction terms?\n",
    "- what mechanisms should i consider? bs consider the role of \"input specificity\", as judged by patents or r&d. ps consider a few different ones: materiality, defined by value of physical assets/value of total assets; industry specificity; and expectation. \n",
    "    - are there any \"climate mechanisms\" i can examine here, other than just expectations?\n",
    "    - how can we adapt or incorporate the scc here?\n",
    "\n",
    "\n",
    "\n",
    "things to push forward on:\n",
    "- targeting specific industries: either with different lag tiers, or with \n",
    "- indirect regressions!\n",
    "- stock regressions\n",
    "- extreme convective storms\n",
    "- counts in disclosures\n",
    "\n",
    "\n",
    "\n",
    "things that are probably very relevant that i should keep experimenting with:\n",
    "- measures of concentration: establishment weights, percent of firm w/in 10% (or honestly 70%+) of hq\n",
    "- extreme temp as 90+, maybe some flood-relative measure of extreme rain?\n",
    "\n",
    "\n",
    "First, total days of heat and rain.\n",
    "\n",
    "\n",
    "\n",
    "*AT SOME POINT, WE CAN ADD ADDTL COLUMNS FOR OTHER VARIABLES OF INTEREST TO THIS AS WELL: cost & profit, maybe also stocks [if we do a quarter before, quarter after] thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultList = []\n",
    "\n",
    "keys = ['_more25%', '_more50%', '_more75%', '']\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "for key in keys:\n",
    "    '##################################################################'\n",
    "    filename = '../../data/companyData/goodsData_igData' + key + '.csv'\n",
    "    \n",
    "    print(filename)\n",
    "\n",
    "    goodsData = pd.read_csv(filename).drop(columns = {'Unnamed: 0'})\n",
    "\n",
    "    goodsData.columns = goodsData.columns.str.replace(\"0.95\", \"Extreme\")\n",
    "\n",
    "    print(goodsData.shape)\n",
    "\n",
    "    firms = goodsData['gvkey']\n",
    "\n",
    "\n",
    "\n",
    "    outcomes = ['lnOpIncNormd', 'lnRevNormd', 'lnCostNormd', 'lnStockClose']\n",
    "\n",
    "    weatherVars = ['precip_zipQuarterquant_Extreme + lag1_precip_zipQuarterquant_Extreme + lag2_precip_zipQuarterquant_Extreme + lag3_precip_zipQuarterquant_Extreme',\n",
    "                  'temp5Days_zipQuarterquant_Extreme + lag1_temp5Days_zipQuarterquant_Extreme + lag2_temp5Days_zipQuarterquant_Extreme + lag3_temp5Days_zipQuarterquant_Extreme',\n",
    "                  'days90Plus + lag1_days90Plus + lag2_days90Plus + lag3_days90Plus',\n",
    "                  'streak90Plus + lag1_streak90Plus + lag2_streak90Plus + lag3_streak90Plus', \n",
    "                  'propAboveTenThou + lag1_propAboveTenThou + lag2_propAboveTenThou + lag3_propAboveTenThou',\n",
    "                  'propAboveHundredThou + lag1_propAboveHundredThou + lag2_propAboveHundredThou + lag3_propAboveHundredThou',\n",
    "                  'propAboveMilli + lag1_propAboveMilli + lag2_propAboveMilli + lag3_propAboveMilli']\n",
    "\n",
    "                  # 'temp_zipWeek95_99 + lag1_temp_zipWeek95_99 + lag2_temp_zipWeek95_99 ', \n",
    "                  # 'temp_zipMonth95_99 + lag1_temp_zipMonth95_99 + lag2_temp_zipMonth95_99 ',\n",
    "                  # 'temp_zipQuarter95_99 + lag1_temp_zipQuarter95_99 + lag2_temp_zipQuarter95_99 ']\n",
    "\n",
    "    controls = ' + C(indGroup):C(qtr) + C(yearQtr) + C(gvkey) + C(ageTercile) + C(profitTercile) + C(sizeTercile)'\n",
    "\n",
    "    for weatherVar in weatherVars:\n",
    "        print(\"***************\")\n",
    "        results = pd.DataFrame()\n",
    "\n",
    "        for outcome in outcomes:    \n",
    "            print(outcome + \"~\" + weatherVar)\n",
    "            try:\n",
    "                mod = smf.ols(formula = outcome + ' ~ ' + weatherVar + controls, data = goodsData).fit()             \n",
    "\n",
    "                print(time.time() - start) \n",
    "\n",
    "                # convert this into a much more condensed version\n",
    "                coeffs = pd.DataFrame(mod.params,   columns = ['coeffs'])\n",
    "                pvalues = pd.DataFrame(mod.pvalues, columns = ['pvals'])\n",
    "\n",
    "                coeffs = coeffs[coeffs.index.str.contains(weatherVar[0:4])]\n",
    "                pvalues = pvalues[pvalues.index.str.contains(weatherVar[0:4])]\n",
    "\n",
    "                resultsTemp = pd.concat([coeffs,pvalues],axis = 1)\n",
    "\n",
    "                resultsTemp.loc['upperVariable'] = ['^' + outcome, '*********'] \n",
    "\n",
    "                results = pd.concat([results,resultsTemp], axis = 1)\n",
    "                results['conc'] = key\n",
    "\n",
    "                print(resultsTemp)\n",
    "                \n",
    "            except:\n",
    "                print('No Dice! ' + outcome + \"~\" + weatherVar)\n",
    "                pass\n",
    "\n",
    "        resultList.append(results)\n",
    "        \n",
    "        \n",
    "allResults = pd.concat(resultList, axis=0)\n",
    "\n",
    "allResults.to_csv('../../data/companyData/results.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allResults = pd.DataFrame()\n",
    "\n",
    "for result in resultList:\n",
    "    if result.shape[1] == 9:\n",
    "        allResults = pd.concat([allResults,result])\n",
    "    print(allResults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allResults.to_csv('../../data/companyData/allResults_byConc.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to get the variance-covariance matrix, from https://www.statsmodels.org/dev/generated/statsmodels.regression.linear_model.RegressionResults.cov_params.html . We can use this in the calculation of MEs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precipMod.cov_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "# + C(ageTercile) + C(profitTercile) + C(sizeTercile)\n",
    "tempMod = smf.ols(formula = 'lnRevNormd ~ temp_zipQuarterquant_Extreme + lag1_temp_zipQuarterquant_Extreme + lag2_temp_zipQuarterquant_Extreme + lag3_temp_zipQuarterquant_Extreme + C(indGroup):C(qtr) + C(yearQtr) + C(gvkey) ', data = goodsData).fit()\n",
    "\n",
    "print(time.time() - start) \n",
    "\n",
    "# convert this into a much more condensed version\n",
    "coeffs = pd.DataFrame(tempMod.params,   columns = ['coeffs'])\n",
    "pvalues = pd.DataFrame(tempMod.pvalues, columns = ['pvals'])\n",
    "\n",
    "coeffs = coeffs[coeffs.index.str.contains('temp')]\n",
    "pvalues = pvalues[pvalues.index.str.contains('temp')]\n",
    "\n",
    "results = pd.concat([coeffs,pvalues],axis = 1)\n",
    "\n",
    "\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results are influenced by the particular transformation. if we do 1 + the ratio, we have a particular problem with the second period here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at \"sustained\" heat and rain. We can look at incidence of a heatwave or sustained temperatures above a given amount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "\n",
    "precip5DaysMod = smf.ols(formula = 'lnRevNormd ~ precip5Days_zipQuarterquant_Extreme + lag1_precip5Days_zipQuarterquant_Extreme + lag2_precip5Days_zipQuarterquant_Extreme + lag3_precip5Days_zipQuarterquant_Extreme + C(indGroup):C(qtr) + C(yearQtr) + C(gvkey) + C(ageTercile) + C(profitTercile) + C(sizeTercile)', data = goodsData).fit()\n",
    "\n",
    "print(time.time() - start) \n",
    "\n",
    "# convert this into a much more condensed version\n",
    "coeffs = pd.DataFrame(precip5DaysMod.params,   columns = ['coeffs'])\n",
    "pvalues = pd.DataFrame(precip5DaysMod.pvalues, columns = ['pvals'])\n",
    "\n",
    "coeffs = coeffs[coeffs.index.str.contains('precip')]\n",
    "pvalues = pvalues[pvalues.index.str.contains('precip')]\n",
    "\n",
    "results = pd.concat([coeffs,pvalues],axis = 1)\n",
    "\n",
    "\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "\n",
    "temp5DaysMod = smf.ols(formula = 'lnRevNormd ~ temp5Days_zipQuarterquant_Extreme + lag1_temp5Days_zipQuarterquant_Extreme + lag2_temp5Days_zipQuarterquant_Extreme + lag3_temp5Days_zipQuarterquant_Extreme + C(indGroup):C(qtr) + C(yearQtr) + C(gvkey) + C(ageTercile) + C(profitTercile) + C(sizeTercile)', data = goodsData).fit()\n",
    "\n",
    "print(time.time() - start) \n",
    "\n",
    "# convert this into a much more condensed version\n",
    "coeffs  = pd.DataFrame(temp5DaysMod.params,  columns = ['coeffs'])\n",
    "pvalues = pd.DataFrame(temp5DaysMod.pvalues, columns = ['pvals'])\n",
    "\n",
    "coeffs  = coeffs[coeffs.index.str.contains('temp')]\n",
    "pvalues = pvalues[pvalues.index.str.contains('temp')]\n",
    "\n",
    "results = pd.concat([coeffs,pvalues],axis = 1)\n",
    "\n",
    "\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breakouts by tercile\n",
    "\n",
    "See how the effect varies in places that are background hot // background wet.\n",
    "\n",
    "Sort of inspired by the BS2016 tercile approach, we divide each place into terciles. I THINK (double check this) that this is based on annual average temperature and precipitation. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "\n",
    "precipModTercile = smf.ols(formula = 'lnRevNormd ~ C(precipTercile)*(precip_zipQuarterquant_Extreme + lag1_precip_zipQuarterquant_Extreme + lag2_precip_zipQuarterquant_Extreme + lag3_precip_zipQuarterquant_Extreme) + C(indGroup):C(qtr) + C(yearQtr) + C(gvkey) + C(ageTercile) + C(profitTercile) + C(sizeTercile)', data = goodsData).fit()\n",
    "\n",
    "print(time.time() - start) \n",
    "\n",
    "# convert this into a much more condensed version\n",
    "coeffs  = pd.DataFrame(precipModTercile.params,  columns = ['coeffs'])\n",
    "pvalues = pd.DataFrame(precipModTercile.pvalues, columns = ['pvals'])\n",
    "\n",
    "coeffs  = coeffs[coeffs.index.str.contains('precip')]\n",
    "pvalues = pvalues[pvalues.index.str.contains('precip')]\n",
    "\n",
    "results = pd.concat([coeffs,pvalues],axis = 1)\n",
    "\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "\n",
    "tempModTercile = smf.ols(formula = 'lnRevNormd ~ C(tempTercile)*(temp_zipQuarterquant_Extreme + lag1_temp_zipQuarterquant_Extreme + lag2_temp_zipQuarterquant_Extreme + lag3_temp_zipQuarterquant_Extreme) + C(indGroup):C(qtr) + C(yearQtr) + C(gvkey) + C(ageTercile) + C(profitTercile) + C(sizeTercile)', data = goodsData).fit()\n",
    "\n",
    "print(time.time() - start) \n",
    "\n",
    "# convert this into a much more condensed version\n",
    "coeffs  = pd.DataFrame(tempModTercile.params,  columns = ['coeffs'])\n",
    "pvalues = pd.DataFrame(tempModTercile.pvalues, columns = ['pvals'])\n",
    "\n",
    "coeffs  = coeffs[coeffs.index.str.contains('temp')]\n",
    "pvalues = pvalues[pvalues.index.str.contains('temp')]\n",
    "\n",
    "results = pd.concat([coeffs,pvalues],axis = 1)\n",
    "\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try the sustained effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "\n",
    "precip5DaysModTercile = smf.ols(formula = 'lnRevNormd ~ C(precipTercile)*(precip5Days_zipQuarterquant_Extreme + lag1_precip5Days_zipQuarterquant_Extreme + lag2_precip5Days_zipQuarterquant_Extreme + lag3_precip5Days_zipQuarterquant_Extreme) + C(indGroup):C(qtr) + C(yearQtr) + C(gvkey) + C(ageTercile) + C(profitTercile) + C(sizeTercile)', data = goodsData).fit()\n",
    "\n",
    "print(time.time() - start) \n",
    "\n",
    "# convert this into a much more condensed version\n",
    "coeffs  = pd.DataFrame(precip5DaysModTercile.params,  columns = ['coeffs'])\n",
    "pvalues = pd.DataFrame(precip5DaysModTercile.pvalues, columns = ['pvals'])\n",
    "\n",
    "coeffs  = coeffs[coeffs.index.str.contains('precip')]\n",
    "pvalues = pvalues[pvalues.index.str.contains('precip')]\n",
    "\n",
    "results = pd.concat([coeffs,pvalues],axis = 1)\n",
    "\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "\n",
    "temp5DaysModTercile = smf.ols(formula = 'lnRevNormd ~ C(tempTercile)*(temp5Days_zipQuarterquant_Extreme + lag1_temp5Days_zipQuarterquant_Extreme + lag2_temp5Days_zipQuarterquant_Extreme + lag3_temp5Days_zipQuarterquant_Extreme) + C(indGroup):C(qtr) + C(yearQtr) + C(gvkey) + C(ageTercile) + C(profitTercile) + C(sizeTercile)', data = goodsData).fit()\n",
    "\n",
    "print(time.time() - start) \n",
    "\n",
    "# convert this into a much more condensed version\n",
    "coeffs  = pd.DataFrame(temp5DaysModTercile.params,  columns = ['coeffs'])\n",
    "pvalues = pd.DataFrame(temp5DaysModTercile.pvalues, columns = ['pvals'])\n",
    "\n",
    "coeffs  = coeffs[coeffs.index.str.contains('temp')]\n",
    "pvalues = pvalues[pvalues.index.str.contains('temp')]\n",
    "\n",
    "results = pd.concat([coeffs,pvalues],axis = 1)\n",
    "\n",
    "\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temperature\n",
    "It seems like we're getting a pretty strong signal on precipitation: more precipitation is bad, and it's bad even (especially?) in places where background level of precipitation is high, maybe because the most extreme tail of it is that much more extreme in these places. We have a little bit more work to do with temperature. \n",
    "\n",
    "From the above, we find the following:\n",
    "    - Temperature does NOT seem to matter on a 1-day fluctuation basis. \n",
    "    - Temperature DOES seem to matter on a 5-day moving average case.\n",
    "    \n",
    "We can seem to look at the following:\n",
    "    - Total days above 90F (another extreme; maybe interact with quartiles of avg temperature too)\n",
    "    - Y/N for whether there was a 7-day streak above 90F, matching PS.\n",
    "    - Weeks, months, qtr at different t'hold\n",
    "        - Maybe try different bins as well.\n",
    "\n",
    "\n",
    "First, try the total number of days that are at least 90F. Weird result is that more days above 90 is associated with better results here. REVISIT THIS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "\n",
    "tempDaysAbove90Mod = smf.ols(formula = 'lnRevNormd ~ days90Plus + lag1_days90Plus + lag2_days90Plus + lag3_days90Plus + C(indGroup):C(qtr) + C(yearQtr) + C(gvkey) + C(ageTercile) + C(profitTercile) + C(sizeTercile)', data = goodsData).fit()\n",
    "\n",
    "print(time.time() - start) \n",
    "\n",
    "# convert this into a much more condensed version\n",
    "coeffs  = pd.DataFrame(tempDaysAbove90Mod.params,  columns = ['coeffs'])\n",
    "pvalues = pd.DataFrame(tempDaysAbove90Mod.pvalues, columns = ['pvals'])\n",
    "\n",
    "coeffs  = coeffs[coeffs.index.str.contains('days90')]\n",
    "pvalues = pvalues[pvalues.index.str.contains('days90')]\n",
    "\n",
    "results = pd.concat([coeffs,pvalues],axis = 1)\n",
    "\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look at the breakdown by days that are normally below, at, or above average, we see the strongest result is in places that are normally below average. This is a drop of almost 4\\%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "\n",
    "tempDaysAbove90Mod = smf.ols(formula = 'lnRevNormd ~ C(tempTercile)*(days90Plus + lag1_days90Plus + lag2_days90Plus + lag3_days90Plus) + C(indGroup):C(qtr) + C(yearQtr) + C(gvkey) + C(ageTercile) + C(profitTercile) + C(sizeTercile)', data = goodsData).fit()\n",
    "\n",
    "print(time.time() - start) \n",
    "\n",
    "coeffs  = pd.DataFrame(tempDaysAbove90Mod.params,  columns = ['coeffs'])\n",
    "pvalues = pd.DataFrame(tempDaysAbove90Mod.pvalues, columns = ['pvals'])\n",
    "\n",
    "coeffs  = coeffs[coeffs.index.str.contains('days90')]\n",
    "pvalues = pvalues[pvalues.index.str.contains('days90')]\n",
    "\n",
    "results = pd.concat([coeffs,pvalues],axis = 1)\n",
    "\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try the same things by streaks. The effect sizes are large, but not statistically significantly estimated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "\n",
    "tempStreakAbove90Mod = smf.ols(formula = 'lnRevNormd ~ streak90Plus + lag1_streak90Plus + lag2_streak90Plus + lag3_streak90Plus + C(indGroup):C(qtr) + C(yearQtr) + C(gvkey) + C(ageTercile) + C(profitTercile) + C(sizeTercile)', data = goodsData).fit()\n",
    "\n",
    "print(time.time() - start) \n",
    "\n",
    "coeffs  = pd.DataFrame(tempStreakAbove90Mod.params,  columns = ['coeffs'])\n",
    "pvalues = pd.DataFrame(tempStreakAbove90Mod.pvalues, columns = ['pvals'])\n",
    "\n",
    "coeffs  = coeffs[coeffs.index.str.contains('streak90')]\n",
    "pvalues = pvalues[pvalues.index.str.contains('streak90')]\n",
    "\n",
    "results = pd.concat([coeffs,pvalues],axis = 1)\n",
    "\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "\n",
    "tempStreakAbove90Mod_intxn = smf.ols(formula = 'lnRevNormd ~  C(tempTercile)*(streak90Plus + lag1_streak90Plus + lag2_streak90Plus + lag3_streak90Plus) + C(indGroup):C(qtr) + C(yearQtr) + C(gvkey) + C(ageTercile) + C(profitTercile) + C(sizeTercile)', data = goodsData).fit()\n",
    "\n",
    "print(time.time() - start) \n",
    "\n",
    "coeffs  = pd.DataFrame(tempStreakAbove90Mod_intxn.params,  columns = ['coeffs'])\n",
    "pvalues = pd.DataFrame(tempStreakAbove90Mod_intxn.pvalues, columns = ['pvals'])\n",
    "\n",
    "coeffs  = coeffs[coeffs.index.str.contains('streak90')]\n",
    "pvalues = pvalues[pvalues.index.str.contains('streak90')]\n",
    "\n",
    "results = pd.concat([coeffs,pvalues],axis = 1)\n",
    "\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try the things by weeks, month, quarter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "#  + lag1_temp_zipWeek95_99 + lag2_temp_zipWeek95_99 + lag3_temp_zipWeek95_99\n",
    "# \n",
    "\n",
    "tempWeekMod = smf.ols(formula = 'lnRevNormd ~  (temp_zipWeek95_99 + lag1_temp_zipWeek95_99 + lag2_temp_zipWeek95_99 ) + C(indGroup):C(qtr) + C(yearQtr) + C(gvkey) + C(ageTercile) + C(profitTercile) + C(sizeTercile)', data = goodsData).fit()\n",
    "\n",
    "print(time.time() - start) \n",
    "\n",
    "coeffs  = pd.DataFrame(tempWeekMod.params,  columns = ['coeffs'])\n",
    "pvalues = pd.DataFrame(tempWeekMod.pvalues, columns = ['pvals'])\n",
    "\n",
    "coeffs  = coeffs[coeffs.index.str.contains('temp')]\n",
    "pvalues = pvalues[pvalues.index.str.contains('temp')]\n",
    "\n",
    "results = pd.concat([coeffs,pvalues],axis = 1)\n",
    "\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we break this down by the background temperature of the place, though, it seems like we find a similar effect in the coldest places: a warm week in the coldest places is the most negative, in the quarter concurrent with when it's warmest.\n",
    "\n",
    "\n",
    "[is this the same effect? other places, did we not see a positive effect of slightly warmer weather in cooler places?]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "#  + lag1_temp_zipWeek95_99 + lag2_temp_zipWeek95_99 + lag3_temp_zipWeek95_99\n",
    "# + C(ageTercile) + C(profitTercile) + C(sizeTercile)\n",
    "\n",
    "tempWeekMod_intxn = smf.ols(formula = 'lnRevNormd ~  C(tempTercile)*(temp_zipWeek95_99 + lag1_temp_zipWeek95_99 + lag2_temp_zipWeek95_99 ) + C(indGroup):C(qtr) + C(yearQtr) + C(gvkey) + C(ageTercile) + C(profitTercile) + C(sizeTercile) ', data = goodsData).fit()\n",
    "\n",
    "print(time.time() - start) \n",
    "\n",
    "coeffs  = pd.DataFrame(tempWeekMod_intxn.params,  columns = ['coeffs'])\n",
    "pvalues = pd.DataFrame(tempWeekMod_intxn.pvalues, columns = ['pvals'])\n",
    "\n",
    "coeffs  = coeffs[coeffs.index.str.contains('temp')]\n",
    "pvalues = pvalues[pvalues.index.str.contains('temp')]\n",
    "\n",
    "results = pd.concat([coeffs,pvalues],axis = 1)\n",
    "\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try months now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "#  + lag1_temp_zipMonth95_99 + lag2_temp_zipMonth95_99 + lag3_temp_zipMonth95_99\n",
    "# \n",
    "\n",
    "tempMonthMod = smf.ols(formula = 'lnRevNormd ~  (temp_zipMonth95_99 + lag1_temp_zipMonth95_99 + lag2_temp_zipMonth95_99 ) + C(indGroup):C(qtr) + C(yearQtr) + C(gvkey) + C(ageTercile) + C(profitTercile) + C(sizeTercile)', data = goodsData).fit()\n",
    "\n",
    "print(time.time() - start) \n",
    "\n",
    "coeffs  = pd.DataFrame(tempMonthMod.params,  columns = ['coeffs'])\n",
    "pvalues = pd.DataFrame(tempMonthMod.pvalues, columns = ['pvals'])\n",
    "\n",
    "coeffs  = coeffs[coeffs.index.str.contains('temp')]\n",
    "pvalues = pvalues[pvalues.index.str.contains('temp')]\n",
    "\n",
    "results = pd.concat([coeffs,pvalues],axis = 1)\n",
    "\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "#  + lag1_temp_zipMonth95_99 + lag2_temp_zipMonth95_99 + lag3_temp_zipMonth95_99\n",
    "# + C(ageTercile) + C(profitTercile) + C(sizeTercile)\n",
    "\n",
    "tempMonthMod_intxn = smf.ols(formula = 'lnRevNormd ~  C(tempTercile)*(temp_zipMonth95_99 + lag1_temp_zipMonth95_99 + lag2_temp_zipMonth95_99 ) + C(indGroup):C(qtr) + C(yearQtr) + C(gvkey) + C(ageTercile) + C(profitTercile) + C(sizeTercile) ', data = goodsData).fit()\n",
    "\n",
    "print(time.time() - start) \n",
    "\n",
    "coeffs  = pd.DataFrame(tempMonthMod_intxn.params,  columns = ['coeffs'])\n",
    "pvalues = pd.DataFrame(tempMonthMod_intxn.pvalues, columns = ['pvals'])\n",
    "\n",
    "coeffs  = coeffs[coeffs.index.str.contains('temp')]\n",
    "pvalues = pvalues[pvalues.index.str.contains('temp')]\n",
    "\n",
    "results = pd.concat([coeffs,pvalues],axis = 1)\n",
    "\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And quarters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "#  + lag1_temp_zipWeek95_99 + lag2_temp_zipWeek95_99 + lag3_temp_zipWeek95_99\n",
    "# + C(ageTercile) + C(profitTercile) + C(sizeTercile)\n",
    "\n",
    "tempQuarterMod = smf.ols(formula = 'lnRevNormd ~  (temp_zipQuarter95_99 + lag1_temp_zipQuarter95_99 + lag2_temp_zipQuarter95_99 ) + C(indGroup):C(qtr) + C(yearQtr) + C(gvkey) + C(ageTercile) + C(profitTercile) + C(sizeTercile) ', data = goodsData).fit()\n",
    "\n",
    "print(time.time() - start) \n",
    "\n",
    "coeffs  = pd.DataFrame(tempQuarterMod.params,  columns = ['coeffs'])\n",
    "pvalues = pd.DataFrame(tempQuarterMod.pvalues, columns = ['pvals'])\n",
    "\n",
    "coeffs  = coeffs[coeffs.index.str.contains('temp')]\n",
    "pvalues = pvalues[pvalues.index.str.contains('temp')]\n",
    "\n",
    "results = pd.concat([coeffs,pvalues],axis = 1)\n",
    "\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "\n",
    "tempQuarterMod_intxn = smf.ols(formula = 'lnRevNormd ~  C(tempTercile)*(temp_zipQuarter90_95 + lag1_temp_zipQuarter90_95 + lag2_temp_zipQuarter90_95 ) + C(indGroup):C(qtr) + C(yearQtr) + C(gvkey) + C(ageTercile) + C(profitTercile) + C(sizeTercile) ', data = goodsData).fit()\n",
    "\n",
    "print(time.time() - start) \n",
    "\n",
    "coeffs  = pd.DataFrame(tempQuarterMod_intxn.params,  columns = ['coeffs'])\n",
    "pvalues = pd.DataFrame(tempQuarterMod_intxn.pvalues, columns = ['pvals'])\n",
    "\n",
    "coeffs  = coeffs[coeffs.index.str.contains('temp')]\n",
    "pvalues = pvalues[pvalues.index.str.contains('temp')]\n",
    "\n",
    "results = pd.concat([coeffs,pvalues],axis = 1)\n",
    "\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Tests\n",
    "Now try a few other ones here. \n",
    "- Streak of days above 95th percentile, temperature and rain.\n",
    "- By categories of days: 0-5, 5-10, 10-15, 15+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "\n",
    "precipStreakMod = smf.ols(formula   = 'lnRevNormd ~ C(wetStreak) + C(lag1_wetStreak) + C(lag2_wetStreak) + C(lag3_wetStreak) + C(indGroup):C(qtr) + C(yearQtr) + C(gvkey) + C(ageTercile) + C(profitTercile) + C(sizeTercile)', data = goodsData).fit()\n",
    "\n",
    "\n",
    "print(time.time() - start) \n",
    "\n",
    "coeffs  = pd.DataFrame(precipStreakMod.params,  columns = ['coeffs'])\n",
    "pvalues = pd.DataFrame(precipStreakMod.pvalues, columns = ['pvals'])\n",
    "\n",
    "coeffs  = coeffs[coeffs.index.str.contains('wet')]\n",
    "pvalues = pvalues[pvalues.index.str.contains('wet')]\n",
    "\n",
    "results = pd.concat([coeffs,pvalues],axis = 1)\n",
    "\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "\n",
    "tempStreakMod = smf.ols(formula   = 'lnRevNormd ~ C(hotStreak) + C(lag1_hotStreak) + C(lag2_hotStreak) + C(lag3_hotStreak) + C(indGroup):C(qtr) + C(yearQtr) + C(gvkey) + C(ageTercile) + C(profitTercile) + C(sizeTercile)', data = goodsData).fit()\n",
    "\n",
    "print(time.time() - start) \n",
    "\n",
    "coeffs  = pd.DataFrame(tempStreakMod.params,  columns = ['coeffs'])\n",
    "pvalues = pd.DataFrame(tempStreakMod.pvalues, columns = ['pvals'])\n",
    "\n",
    "coeffs  = coeffs[coeffs.index.str.contains('hot')]\n",
    "pvalues = pvalues[pvalues.index.str.contains('hot')]\n",
    "\n",
    "results = pd.concat([coeffs,pvalues],axis = 1)\n",
    "\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try with the different breakout categories of what's coming together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "\n",
    "precipCatMod = smf.ols(formula   = 'lnRevNormd ~ C(wetDaysCat) + C(lag1_wetDaysCat) + C(lag2_wetDaysCat) + C(lag3_wetDaysCat) + C(indGroup):C(qtr) + C(yearQtr) + C(gvkey) + C(ageTercile) + C(profitTercile) + C(sizeTercile)', data = goodsData).fit() # cov_type  = 'cluster',cov_kwds={'groups': firms},use_t=True)\n",
    "\n",
    "\n",
    "print(time.time() - start) \n",
    "\n",
    "coeffs  = pd.DataFrame(precipCatMod.params,  columns = ['coeffs'])\n",
    "pvalues = pd.DataFrame(precipCatMod.pvalues, columns = ['pvals'])\n",
    "\n",
    "coeffs  = coeffs[coeffs.index.str.contains('wet')]\n",
    "pvalues = pvalues[pvalues.index.str.contains('wet')]\n",
    "\n",
    "results = pd.concat([coeffs,pvalues],axis = 1)\n",
    "\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "\n",
    "tempCatMod = smf.ols(formula   = 'lnRevNormd ~ C(hotDaysCat) + C(lag1_hotDaysCat) + C(lag2_hotDaysCat) + C(lag3_hotDaysCat) + C(indGroup):C(qtr) + C(yearQtr) + C(gvkey) + C(ageTercile) + C(profitTercile) + C(sizeTercile)', data = goodsData).fit()\n",
    "\n",
    "\n",
    "print(time.time() - start) \n",
    "\n",
    "\n",
    "coeffs  = pd.DataFrame(tempCatMod.params,  columns = ['coeffs'])\n",
    "pvalues = pd.DataFrame(tempCatMod.pvalues, columns = ['pvals'])\n",
    "\n",
    "coeffs  = coeffs[coeffs.index.str.contains('hot')]\n",
    "pvalues = pvalues[pvalues.index.str.contains('hot')]\n",
    "\n",
    "results = pd.concat([coeffs,pvalues],axis = 1)\n",
    "\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "\n",
    "tempCatMod_intxn = smf.ols(formula   = 'lnRevNormd ~ C(tempTercile)*(C(hotDaysCat) + C(lag1_hotDaysCat) + C(lag2_hotDaysCat) + C(lag3_hotDaysCat)) + C(indGroup):C(qtr) + C(yearQtr) + C(gvkey) + C(ageTercile) + C(profitTercile) + C(sizeTercile)', data = goodsData).fit()\n",
    "\n",
    "\n",
    "print(time.time() - start) \n",
    "\n",
    "\n",
    "coeffs  = pd.DataFrame(tempCatMod_intxn.params,  columns = ['coeffs'])\n",
    "pvalues = pd.DataFrame(tempCatMod_intxn.pvalues, columns = ['pvals'])\n",
    "\n",
    "coeffs  = coeffs[coeffs.index.str.contains('hot')]\n",
    "pvalues = pvalues[pvalues.index.str.contains('hot')]\n",
    "\n",
    "results = pd.concat([coeffs,pvalues],axis = 1)\n",
    "\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Robustness Checks\n",
    "Try playing with temperature a little bit more. Look at:\n",
    "    - interaction with concentration\n",
    "    - establishment-weighted vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "\n",
    "tempStreakConcMod = smf.ols(formula   = 'lnRevNormd ~ C(firmConcTercile)*(C(hotDaysCat) + C(lag1_hotDaysCat) + C(lag2_hotDaysCat) + C(lag3_hotDaysCat)) + C(indGroup):C(qtr) + C(yearQtr) + C(gvkey) + C(ageTercile) + C(profitTercile) + C(sizeTercile)', \n",
    "                           data = goodsData)\n",
    "tempStreakConcRes = tempStreakConcMod.fit() # cov_type  = 'cluster',cov_kwds={'groups': firms},use_t=True)\n",
    "\n",
    "\n",
    "print(time.time() - start) \n",
    "\n",
    "tempStreakConcRes.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try the temperature as defined by super super hot days, anywhere in the country - 95th percentile anywhere. This will only happen in a few places in , or at least, there will be some geographic skew. But we can control for that by looking at the effect of hot temps given different baselines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "\n",
    "tempModAnnual_noControls = smf.ols(formula   = 'lnRevNormd ~ temp_annualquant_Extreme + lag1_temp_annualquant_Extreme + lag2_temp_annualquant_Extreme + lag3_temp_annualquant_Extreme + C(indGroup):C(qtr) + C(yearQtr) + C(gvkey)', data = goodsData)\n",
    "tempResAnnual_noControls = tempModAnnual_noControls.fit(cov_type  = 'cluster',cov_kwds={'groups': firms},use_t=True)\n",
    "\n",
    "\n",
    "print(time.time() - start) \n",
    "\n",
    "tempResAnnual_noControls.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try the standard interactions, controlling for the background climate in given places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look at the below, we see that the places that are normally coolest are negatively impacted by extreme extremes. Specifically, using an across-the-country cutoff for temperature, we have that the biggest negative effect happens in the places that are normally the lowest-temperature.\n",
    "\n",
    "This gives some promise that we might find an effect of temperature in some places, depending on expectation or baseline climate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "\n",
    "tempEstMod_annual = smf.ols(formula   = 'lnRevNormd ~ C(tempTercile)*(temp_annualquant_Extreme + lag1_temp_annualquant_Extreme + lag2_temp_annualquant_Extreme + lag3_temp_annualquant_Extreme) + C(indGroup):C(qtr) + C(yearQtr) + C(gvkey) + C(ageTercile) + C(profitTercile) + C(sizeTercile)', \n",
    "                           data = goodsData)\n",
    "\n",
    "\n",
    "tempResMod_annual = tempEstMod_annual.fit() # cov_type  = 'cluster',cov_kwds={'groups': firms},use_t=True)\n",
    "\n",
    "\n",
    "print(time.time() - start) \n",
    "\n",
    "tempResMod_annual.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try it by precipitation quartile for comparison's sake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "\n",
    "precipEstMod_annual = smf.ols(formula   = 'lnRevNormd ~ C(precipTercile)*(precip_annualquant_Extreme + lag1_precip_annualquant_Extreme + lag2_precip_annualquant_Extreme + lag3_precip_annualquant_Extreme) + C(indGroup):C(qtr) + C(yearQtr) + C(gvkey) + C(ageTercile) + C(profitTercile) + C(sizeTercile)', \n",
    "                           data = goodsData)\n",
    "\n",
    "\n",
    "precipResMod_annual = precipEstMod_annual.fit() # cov_type  = 'cluster',cov_kwds={'groups': firms},use_t=True)\n",
    "\n",
    "\n",
    "print(time.time() - start) \n",
    "\n",
    "precipResMod_annual.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's make sure we have the originals, the OGs, for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "\n",
    "tempEstMod_zipQuarter = smf.ols(formula   = 'lnRevNormd ~ C(tempTercile)*(temp_zipQuarterquant_Extreme + lag1_temp_zipQuarterquant_Extreme + lag2_temp_zipQuarterquant_Extreme + lag3_temp_zipQuarterquant_Extreme) + C(indGroup):C(qtr) + C(yearQtr) + C(gvkey) + C(ageTercile) + C(profitTercile) + C(sizeTercile)', \n",
    "                           data = goodsData)\n",
    "\n",
    "\n",
    "tempResMod_zipQuarter = tempEstMod_zipQuarter.fit() # cov_type  = 'cluster',cov_kwds={'groups': firms},use_t=True)\n",
    "\n",
    "\n",
    "print(time.time() - start) \n",
    "\n",
    "tempResMod_zipQuarter.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "\n",
    "precipEstMod_zipQuarter = smf.ols(formula   = 'lnRevNormd ~ C(precipTercile)*(precip_zipQuarterquant_Extreme + lag1_precip_zipQuarterquant_Extreme + lag2_precip_zipQuarterquant_Extreme + lag3_precip_zipQuarterquant_Extreme) + C(indGroup):C(qtr) + C(yearQtr) + C(gvkey) + C(ageTercile) + C(profitTercile) + C(sizeTercile)', \n",
    "                           data = goodsData)\n",
    "\n",
    "\n",
    "precipResMod_zipQuarter = precipEstMod_zipQuarter.fit() # cov_type  = 'cluster',cov_kwds={'groups': firms},use_t=True)\n",
    "\n",
    "\n",
    "print(time.time() - start) \n",
    "\n",
    "precipResMod_zipQuarter.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Industry-Specific"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start to do some of the heterogeneity analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precipMod_byInd       = smf.ols(formula = 'lnRevNormd ~ C(indGroup)*(precip_zipQuarterquant_Extreme + lag1_precip_zipQuarterquant_Extreme + lag2_precip_zipQuarterquant_Extreme + lag3_precip_zipQuarterquant_Extreme) + C(indGroup)*C(qtr) + C(yearQtr) + C(gvkey) + C(ageTercile) + C(profitTercile) + C(sizeTercile)', data = goodsData).fit()\n",
    "coeff = precipMod_byInd.params\n",
    "pvals = precipMod_byInd.pvalues\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precipMod_byInd.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase    = 'precip_zipQuarterquant_Extreme'\n",
    "\n",
    "condition = [s for s in coeff.index if phrase in s]\n",
    "coeffs_ofInt = coeff[condition]\n",
    "pvals_ofInt  = pvals[condition] \n",
    "\n",
    "results = pd.DataFrame()\n",
    "\n",
    "# get coeffs, lags, for each of these\n",
    "lag0   = [s for s in coeffs_ofInt.index if ('lag' not in s)]\n",
    "# lag0   = ['t']*len(lag0)\n",
    "coeff0 = coeffs_ofInt[lag0]\n",
    "pval0  = pvals_ofInt[lag0]\n",
    "lags0  = ['t']*len(lag0)\n",
    "\n",
    "lag1   = [s for s in coeffs_ofInt.index if ('lag1' in s)]\n",
    "coeff1 = coeffs_ofInt[lag1]\n",
    "pval1  = pvals_ofInt[lag1]\n",
    "lags1  = ['t-1']*len(lag0)\n",
    "\n",
    "lag2   = [s for s in coeffs_ofInt.index if ('lag2' in s)]\n",
    "coeff2 = coeffs_ofInt[lag2]\n",
    "pval2  = pvals_ofInt[lag2]\n",
    "lags2  = ['t-2']*len(lag0)\n",
    "\n",
    "lag3   = [s for s in coeffs_ofInt.index if ('lag3' in s)]\n",
    "coeff3 = coeffs_ofInt[lag3]\n",
    "pval3  = pvals_ofInt[lag3]\n",
    "lags3  = ['t-3']*len(lag3)\n",
    "\n",
    "allNames = list(itertools.chain(lag0,lag1,lag2,lag3))\n",
    "intxns   = [char.split(':')[0] for char in allNames]\n",
    "allCoefs = list(itertools.chain(coeff0,coeff1,coeff2,coeff3))  \n",
    "allPVals = list(itertools.chain(pval0,pval1,pval2,pval3))  \n",
    "allLagLabels = list(itertools.chain(lags0,lags1,lags2,lags3))  \n",
    "coefsWithPVals = []\n",
    "\n",
    "for i in range(0,len(allCoefs)):\n",
    "    next = str(\"%.4f\" % allCoefs[i]) + ' (' + str(\"%.2f\" % allPVals[i]) + ')'\n",
    "    coefsWithPVals.append(next)\n",
    "    \n",
    "take2 = pd.DataFrame([intxns,allLagLabels,coefsWithPVals]).T\n",
    "take2.columns = ['indInteraction','allLagLabels','coefsWithPVals']\n",
    "take2.pivot(index='indInteraction', columns='allLagLabels', values='coefsWithPVals').reset_index().to_csv('take2.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try with the total number of industries as described in the other doc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precipTotal_byInd  = smf.ols(formula = 'lnRevNormd ~ C(indGroup)*(extremePrecip) + C(indGroup)*C(qtr) + C(yearQtr) + C(gvkey) + C(ageTercile) + C(profitTercile) + C(sizeTercile)', data = goodsData).fit()\n",
    "coeff              = precipTotal_byInd.params\n",
    "pvals              = precipTotal_byInd.pvalues\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precipTotal_byInd.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase    = 'extremePrecip'\n",
    "\n",
    "condition = [s for s in coeff.index if phrase in s]\n",
    "coeffs_ofInt = coeff[condition]\n",
    "pvals_ofInt  = pvals[condition] \n",
    "\n",
    "\n",
    "results = pd.DataFrame()\n",
    "\n",
    "\n",
    "allNames = coeffs_ofInt.index\n",
    "intxns   = [char.split(':')[0] for char in allNames]\n",
    "allCoefs = list(coeffs_ofInt)  \n",
    "allPVals = list(pvals_ofInt)  \n",
    "coefsWithPVals = []\n",
    "\n",
    "for i in range(0,len(allCoefs)):\n",
    "    next = str(\"%.4f\" % allCoefs[i]) + ' (' + str(\"%.2f\" % allPVals[i]) + ')'\n",
    "    coefsWithPVals.append(next)\n",
    "\n",
    "print(coefsWithPVals)\n",
    "    \n",
    "\n",
    "take3 = pd.DataFrame([intxns,coefsWithPVals]).T\n",
    "take3.columns = ['indInteraction','coefsWithPVals']\n",
    "\n",
    "print(take3)\n",
    "\n",
    "take3.to_csv('take3.csv')\n",
    "\n",
    "'''take2.pivot(index='indInteraction', columns='allLagLabels', values='coefsWithPVals').reset_index().to_csv('take2.csv')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Now try this for each regression separately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the same for temperature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempMod_byInd       = smf.ols(formula = 'lnRevNormd ~ C(indGroup)*(temp_zipQuarterquant_Extreme + lag1_temp_zipQuarterquant_Extreme + lag2_temp_zipQuarterquant_Extreme + lag3_temp_zipQuarterquant_Extreme) + C(indGroup):C(qtr) + C(yearQtr) + C(gvkey) + C(ageTercile) + C(profitTercile) + C(sizeTercile)', data = goodsData)\n",
    "tempMod_byInd_res   = tempMod_byInd.fit(cov_type='cluster',cov_kwds={'groups': firms},use_t=True)\n",
    "\n",
    "\n",
    "tempMod_byInd_res.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try just the concurrent quarter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precipMod_byInd       = smf.ols(formula = 'lnRevNormd ~ C(indGroup)*(precip_zipQuarterquant_Extreme) + C(indGroup):C(qtr) + C(yearQtr) + C(gvkey) + C(ageTercile) + C(profitTercile) + C(sizeTercile)', data = goodsData)\n",
    "precipMod_byInd_res   = precipMod_byInd.fit()\n",
    "\n",
    "\n",
    "precipMod_byInd_res.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try with the categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotCat_byInd       = smf.ols(formula = 'lnRevNormd ~ C(indGroup)*(C(hotDaysCat) + C(lag1_hotDaysCat) + C(lag2_hotDaysCat) + C(lag3_hotDaysCat)) + C(indGroup):C(qtr) + C(yearQtr) + C(gvkey) + C(ageTercile) + C(profitTercile) + C(sizeTercile)', data = goodsData)\n",
    "hotCat_byInd_res   = hotCat_byInd.fit()\n",
    "\n",
    "hotCat_byInd_res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wetCat_byInd       = smf.ols(formula = 'lnRevNormd ~ C(indGroup)*(C(wetDaysCat) + C(lag1_wetDaysCat) + C(lag2_wetDaysCat) + C(lag3_wetDaysCat)) + C(indGroup):C(qtr) + C(yearQtr) + C(gvkey) + C(ageTercile) + C(profitTercile) + C(sizeTercile)', data = goodsData)\n",
    "wetCat_byInd_res   = wetCat_byInd.fit()\n",
    "\n",
    "wetCat_byInd_res.summary()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like if we split hairs by dividing things up the last few quarters, everything starts to go a little haywire. The most generous description is something like, we can't separately identify the effects from different quarters, and there's a lot of fairly collinear effects. There are a few less generous descriptions as well, including that there's not necessarily much signal here. \n",
    "\n",
    "\n",
    "One of the understated pros of all of this is that the r-squared values are all very high - we're getting great identification here. We could potentially expand the data sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things for Larry tomorrow:\n",
    "    - emphasis on, here is the specific regression form. here's why i think it is good/bad\n",
    "    - main precipitation + temperature plot\n",
    "    - a sense of the heterogeneity, by types of place\n",
    "    - a little discussion of what to do about temperature: focus on a higher cutoff, the effects in places that aren't quite used to it, and the effects on firms that have more of their operations concentrated in one place\n",
    "           - the problem with our current definition (zip-quarter) is that for some quarters, we don't have high enough baselines to really register the types of high temperatures \n",
    "           - it seems like there might be more variability in precipitation? or at least, more zipcodes seem to trigger it than trigger the temperature threshold\n",
    "    - some of the industry - intxn results\n",
    "    - some of the specific industry results\n",
    "    - discussino of future results: indirect effect results, stock results, by concentration of firm \n",
    "    - a discussion of the different time frames: the further back, the less insight we have into what businesses are saying about all of this. the different data sources to mention are: disclosures (8-Ks); PRISM; zipcodes; compustat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goodsData.indGroup.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoffVarsYr = ['0.95']  # , ] # ,'1xQtr''1x5Qtrs',\n",
    "weatherVars  = ['precip_'] # , 'temp5Days_', 'precip5Days_'] # , 'precip_']#, , ] #[,]\n",
    "statVarsYr   = ['zipQuarterquant_'] #  , , ]  #,'zipQuarterquant_']\n",
    "outcomeVars  = ['lnRevNormd'] # , 'lnRev', 'lnCost', 'revenueChange', 'costChange']\n",
    "\n",
    "goodsData = goodsData[~goodsData.lnRev.isna() & ~goodsData.lnCost.isna()] # & ~goodsData.lnCostNormd.isna()]\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "results = pd.DataFrame()\n",
    "\n",
    "i = 0\n",
    "for outcomeVar in outcomeVars:\n",
    "    for weatherVar in weatherVars:\n",
    "        for statVar in statVarsYr:                     \n",
    "            for cutoffVar in cutoffVarsYr:\n",
    "                i = i + 1\n",
    "                indVar = weatherVar + statVar + cutoffVar\n",
    "                \n",
    "                \n",
    "                print(outcomeVar, \"~\", indVar)\n",
    "\n",
    "\n",
    "                # find: concurrent ; or lagged supplier data\n",
    "                X = goodsData.loc[:,((goodsData.columns.str.contains(indVar) & ~goodsData.columns.str.contains('empWt_')) | \n",
    "                                                (goodsData.columns.str.contains('indQtr_')) |\n",
    "                                                (goodsData.columns.str.contains('gvkey_')))] #  | \n",
    "                                                (goodsData.columns.str.contains('ageTercile_')) |\n",
    "                                                # (goodsData.columns.str.contains('sizeTercile_')) |\n",
    "                                                # (goodsData.columns.str.contains('profitTercile_')))]\n",
    "                \n",
    "                \n",
    "                X = sm.add_constant(X)\n",
    "\n",
    "                \n",
    "                firms = goodsData['gvkey']\n",
    "        \n",
    "\n",
    "                y = goodsData[outcomeVar]\n",
    "                \n",
    "                \n",
    "                model = sm.OLS(y, X).fit(cov_type='cluster',cov_kwds={'groups': firms},use_t=True)\n",
    "                coeff = model.params[1:     1 + len(goodsData.columns[goodsData.columns.str.contains(indVar) & ~goodsData.columns.str.contains('empWt_')])]\n",
    "                pvals = model.pvalues[1:    1 + len(goodsData.columns[goodsData.columns.str.contains(indVar) & ~goodsData.columns.str.contains('empWt_')])]\n",
    "                errs  = modelResults.bse[1: 1 + len(goodsData.columns[goodsData.columns.str.contains(indVar) & ~goodsData.columns.str.contains('empWt_')])]\n",
    "                # print(model.summary())\n",
    "                print(coeff)\n",
    "                print(pvals)\n",
    "\n",
    "\n",
    "                results.loc[i,'industry'] = ind\n",
    "\n",
    "                results.loc[i,'outcomeVar'] = outcomeVar\n",
    "                results.loc[i,'weatherVar'] = weatherVar\n",
    "\n",
    "                results.loc[i,'lag0']       = coeff[0]\n",
    "                results.loc[i,'lag1']       = coeff[1]\n",
    "                results.loc[i,'lag2']       = coeff[2]\n",
    "                results.loc[i,'lag3']       = coeff[3]\n",
    "                results.loc[i,'lag4']       = coeff[4]\n",
    "                \n",
    "                \n",
    "                results.loc[i,'pval0']      = pvals[0]\n",
    "                results.loc[i,'pval1']      = pvals[1]\n",
    "                results.loc[i,'pval2']      = pvals[2]\n",
    "                results.loc[i,'pval3']      = pvals[3]\n",
    "                results.loc[i,'pval4']      = pvals[4]\n",
    "                \n",
    "                \n",
    "                results.loc[i,'bse0']       = errs[0]\n",
    "                results.loc[i,'bse1']       = errs[1]\n",
    "                results.loc[i,'bse2']       = errs[2]\n",
    "                results.loc[i,'bse3']       = errs[3]\n",
    "                results.loc[i,'bse4']       = errs[4]\n",
    "\n",
    "                                \n",
    "                # results.to_csv(\"../../data/utilitiesResults_rightInds_noCtrls.csv\")\n",
    "                \n",
    "                print( time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weatherVars  = ['hotStreak', 'wetStreak'] # , 'temp5Days_', 'precip5Days_'] # , 'precip_']#, , ] #[,]\n",
    "outcomeVars  = ['lnRevNormd', 'lnCostNormd'] # , 'lnRev', 'lnCost', 'revenueChange', 'costChange']\n",
    "\n",
    "goodsData = goodsData[~goodsData.lnRev.isna() & ~goodsData.lnCost.isna()] # & ~goodsData.lnCostNormd.isna()]\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "results = pd.DataFrame()\n",
    "\n",
    "i = 0\n",
    "for outcomeVar in outcomeVars:\n",
    "    for weatherVar in weatherVars:\n",
    "        i = i + 1\n",
    "        indVar = weatherVar\n",
    "\n",
    "\n",
    "        print(outcomeVar, \"~\", indVar)\n",
    "\n",
    "\n",
    "        # find: concurrent ; or lagged supplier data\n",
    "        X = goodsData.loc[:,((goodsData.columns.str.contains(indVar) & ~goodsData.columns.str.contains('empWt_')) | \n",
    "                                        (goodsData.columns.str.contains('indQtr_')) |\n",
    "                                        (goodsData.columns.str.contains('gvkey_')))] #  | \n",
    "                                        # (goodsData.columns.str.contains('ageTercile_')) |\n",
    "                                        # (goodsData.columns.str.contains('sizeTercile_')) |\n",
    "                                        # (goodsData.columns.str.contains('profitTercile_')))]\n",
    "\n",
    "\n",
    "        X = sm.add_constant(X)\n",
    "        print(X.columns)\n",
    "\n",
    "        firms = goodsData['gvkey']\n",
    "\n",
    "\n",
    "        y = goodsData[outcomeVar]\n",
    "\n",
    "\n",
    "        model = sm.OLS(y, X).fit(cov_type='cluster',cov_kwds={'groups': firms},use_t=True)\n",
    "        coeff = model.params[1:     1 + len(goodsData.columns[goodsData.columns.str.contains(indVar) & ~goodsData.columns.str.contains('empWt_')])]\n",
    "        pvals = model.pvalues[1:    1 + len(goodsData.columns[goodsData.columns.str.contains(indVar) & ~goodsData.columns.str.contains('empWt_')])]\n",
    "        errs  = modelResults.bse[1: 1 + len(goodsData.columns[goodsData.columns.str.contains(indVar) & ~goodsData.columns.str.contains('empWt_')])]\n",
    "        # print(model.summary())\n",
    "        print(coeff)\n",
    "        print(pvals)\n",
    "\n",
    "\n",
    "        results.loc[i,'industry'] = ind\n",
    "\n",
    "        results.loc[i,'outcomeVar'] = outcomeVar\n",
    "        results.loc[i,'weatherVar'] = weatherVar\n",
    "\n",
    "        results.loc[i,'lag0']       = coeff[0]\n",
    "        results.loc[i,'lag1']       = coeff[1]\n",
    "        results.loc[i,'lag2']       = coeff[2]\n",
    "        results.loc[i,'lag3']       = coeff[3]\n",
    "        results.loc[i,'lag4']       = coeff[4]\n",
    "\n",
    "\n",
    "        results.loc[i,'pval0']      = pvals[0]\n",
    "        results.loc[i,'pval1']      = pvals[1]\n",
    "        results.loc[i,'pval2']      = pvals[2]\n",
    "        results.loc[i,'pval3']      = pvals[3]\n",
    "        results.loc[i,'pval4']      = pvals[4]\n",
    "\n",
    "\n",
    "        results.loc[i,'bse0']       = errs[0]\n",
    "        results.loc[i,'bse1']       = errs[1]\n",
    "        results.loc[i,'bse2']       = errs[2]\n",
    "        results.loc[i,'bse3']       = errs[3]\n",
    "        results.loc[i,'bse4']       = errs[4]\n",
    "\n",
    "\n",
    "        # results.to_csv(\"../../data/utilitiesResults_rightInds_noCtrls.csv\")\n",
    "\n",
    "        print( time.time() - start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(\"../../data/utilitiesResults_rightInds.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Employment-Wtd Weather\n",
    "Run the regressions using the emp-wtd data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoffVar   = '0.95'\n",
    "weatherVar  = 'precip_'\n",
    "statVar  = 'zipquant_'\n",
    "outcomeVar  = 'lnRevNormd'\n",
    "\n",
    "indVar = weatherVar + statVar + cutoffVar\n",
    "\n",
    "\n",
    "goodsData.columns[goodsData.columns.str.contains(indVar) & goodsData.columns.str.contains('empWt_')] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoffVar   = '0.95'\n",
    "weatherVar  = 'precip_'\n",
    "statVarYr  = 'zipquant_'\n",
    "outcomeVar  = 'lnRevNormd'\n",
    "\n",
    "ind = 2\n",
    "\n",
    "\n",
    "##################\n",
    "filename = '../../data/companyData/igData_ind' + str(ind) + '.csv'           \n",
    "goodsData = pd.read_csv(filename).drop(columns = {'Unnamed: 0'})\n",
    "\n",
    "\n",
    "indVar = weatherVar + statVar + cutoffVar\n",
    "\n",
    "\n",
    "print(outcomeVar, \"~\", indVar)\n",
    "\n",
    "\n",
    "# find: concurrent ; or lagged supplier data\n",
    "X = goodsData.loc[:,((goodsData.columns.str.contains(indVar) & goodsData.columns.str.contains('empWt_')) | \n",
    "                                (goodsData.columns.str.contains('indQtr_')) |\n",
    "                                (goodsData.columns.str.contains('gvkey_'))  | \n",
    "                                (goodsData.columns.str.contains('ageTercile_')) |\n",
    "                                (goodsData.columns.str.contains('sizeTercile_')) |\n",
    "                                (goodsData.columns.str.contains('profitTercile_')))]\n",
    "\n",
    "\n",
    "print(X.columns)\n",
    "\n",
    "firms = goodsData['gvkey']\n",
    "\n",
    "\n",
    "y = goodsData[outcomeVar]\n",
    "\n",
    "\n",
    "model = sm.OLS(y, X).fit(cov_type='cluster',cov_kwds={'groups': firms},use_t=True)\n",
    "pvals = model.pvalues[0:len(goodsData.columns[goodsData.columns.str.contains(indVar)])]\n",
    "coeff =  model.params[0:len(goodsData.columns[goodsData.columns.str.contains(indVar)])]\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_csv(\"../../allIndustryResults.csv\").drop(columns = {'Unnamed: 0'})\n",
    "industries = results.industry.unique()\n",
    "yLim   = 0.01\n",
    "numCol = 3\n",
    "padding = 1\n",
    "xdim = 20\n",
    "ydim = 40\n",
    "filePrefix = 'dirEffects'\n",
    "\n",
    "makePlots(results, industries, filePrefix, yLim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makePlots(results, industries, filePrefix, yLim, numCol = 2, padding = 1, xdim = 20, ydim = 40):\n",
    "    \n",
    "    # loop over outcome variables and weather definitions\n",
    "    weatherVars = results.weatherVar.unique()\n",
    "    outcomeVars = results.outcomeVar.unique()\n",
    "\n",
    "\n",
    "    for outcome in outcomeVars:\n",
    "        for weather in weatherVars:\n",
    "            # choose the elective parts of this - number of columns and the range of the axes\n",
    "            numCols = numCol\n",
    "            yLims   = yLim\n",
    "\n",
    "            rowNum = len(industries) // numCols + padding\n",
    "            colNum = numCols\n",
    "\n",
    "            fig, ax = plt.subplots(rowNum, colNum, sharex='all', sharey='all',\n",
    "                                  figsize=(xdim,ydim),\n",
    "                                  constrained_layout=True)\n",
    "\n",
    "            fig.suptitle('Direct Effects: ' + outcome + ' ~ ' + weather, fontsize=36)\n",
    "\n",
    "\n",
    "\n",
    "            i = 0\n",
    "            for ind in industries:\n",
    "                rowIndex = i // numCols \n",
    "                colIndex = i % numCols\n",
    "\n",
    "\n",
    "                i   = i + 1\n",
    "\n",
    "\n",
    "                rev = results[(results.outcomeVar == outcome) & (results.weatherVar == weather) & \n",
    "                             (results.industry == ind)].reset_index()\n",
    "                # indName = rev.industryName.unique()[0]\n",
    "                x   = [0,1,2,3,4]\n",
    "                y   = [rev.lag0,rev.lag1,rev.lag2,rev.lag3,rev.lag4]\n",
    "\n",
    "\n",
    "                errors = [rev.bse0,rev.bse1,rev.bse2,rev.bse3,rev.bse4]\n",
    "\n",
    "\n",
    "                ax[rowIndex, colIndex].errorbar(x,y,yerr = errors, fmt = '.k')\n",
    "                ax[rowIndex, colIndex].xaxis.grid(False)\n",
    "                ax[rowIndex, colIndex].yaxis.grid(False)\n",
    "                ax[rowIndex, colIndex].axhline(y=0)\n",
    "                ax[rowIndex, colIndex].set_ylim([-yLims, yLims])\n",
    "\n",
    "                ax[rowIndex, colIndex].yaxis.set_ticks(np.arange(-yLims, yLims + yLims, yLims/2))\n",
    "                ax[rowIndex, colIndex].xaxis.set_ticks(np.arange(0.0, 5.0, 1.0))\n",
    "\n",
    "                ax[rowIndex, colIndex].tick_params(axis='both', labelsize = 16)\n",
    "                ax[rowIndex, colIndex].set_title(ind, fontsize = 24)\n",
    "\n",
    "            fig.savefig(filePrefix + outcome + weather + '.png')\n",
    "            fig.show()\n",
    "\n",
    "\n",
    "                # ax[rowIndex, colIndex].\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Industry-Specific\n",
    "Go through every famafrench industry and run the regressions above. First do this by days of extremes at hqs.\n",
    "\n",
    "### HQs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goodsData = pd.read_csv(\"../../data/companyData/goodsData_igData.csv\").drop(columns = {'Unnamed: 0'})\n",
    "\n",
    "industries = goodsData.indGroup.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoffVarsYr = ['0.95'] \n",
    "weatherVars  = ['precip_'] # , 'temp_'] \n",
    "statVarsYr   = ['zipQuarterquant_']\n",
    "outcomeVars  = ['lnRevNormd'] # , 'lnCostNormd']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "results = pd.DataFrame()\n",
    "\n",
    "i = 0\n",
    "\n",
    "for ind in industries:\n",
    "    print('##########################################################')\n",
    "    print(ind)\n",
    "    filename = '../../data/companyData/igData_ind' + str(ind) + '.csv'           \n",
    "    goodsData = pd.read_csv(filename).drop(columns = {'Unnamed: 0'})\n",
    "    if goodsData.shape[0] > 0:\n",
    "    \n",
    "        for outcomeVar in outcomeVars:\n",
    "            for weatherVar in weatherVars:\n",
    "                for statVar in statVarsYr:                     \n",
    "                    for cutoffVar in cutoffVarsYr:\n",
    "\n",
    "                        i = i + 1\n",
    "\n",
    "\n",
    "                        indVar = weatherVar + statVar + cutoffVar\n",
    "\n",
    "\n",
    "                        print(outcomeVar, \"~\", indVar)\n",
    "\n",
    "\n",
    "                        # find: concurrent ; or lagged supplier data\n",
    "                        X = goodsData.loc[:,(goodsData.columns.str.contains(indVar) & ~goodsData.columns.str.contains('empWt_') & ~goodsData.columns.str.contains('lag4')) | \n",
    "                                                        (goodsData.columns.str.contains('indQtr_')) | #  |\n",
    "                                                        (goodsData.columns.str.contains('gvkey_')) | #  | \n",
    "                                                        (goodsData.columns.str.contains('ageTercile_')) |\n",
    "                                                        (goodsData.columns.str.contains('sizeTercile_')) |\n",
    "                                                        (goodsData.columns.str.contains('profitTercile_'))]\n",
    "\n",
    "                        X = sm.add_constant(X)\n",
    "\n",
    "                        firms = goodsData['gvkey']\n",
    "\n",
    "\n",
    "                        y = goodsData[outcomeVar]\n",
    "\n",
    "\n",
    "                        model = sm.OLS(y, X).fit(cov_type='cluster',cov_kwds={'groups': firms},use_t=True)\n",
    "                        pvals = model.pvalues[1: 1 + len(goodsData.columns[goodsData.columns.str.contains(indVar) & ~goodsData.columns.str.contains('empWt_')])]\n",
    "                        coeff = model.params[1: 1 + len(goodsData.columns[goodsData.columns.str.contains(indVar)  & ~goodsData.columns.str.contains('empWt_')])]\n",
    "                        errs  = model.bse[1: 1 + len(goodsData.columns[goodsData.columns.str.contains(indVar)     & ~goodsData.columns.str.contains('empWt_')])]\n",
    "                \n",
    "                        '''print(coeff)\n",
    "                        print(pvals)'''\n",
    "\n",
    "\n",
    "                        results.loc[i,'industry'] = ind\n",
    "\n",
    "                        results.loc[i,'outcomeVar'] = outcomeVar\n",
    "                        results.loc[i,'weatherVar'] = weatherVar\n",
    "\n",
    "                        # str(\"%.4f\" % allCoefs[i]) + ' (' + str(\"%.2f\" % allPVals[i]) + ')'\n",
    "                        \n",
    "                        results.loc[i,'lag0']       = str(\"%.4f\" % coeff[0]) + ' (' + str(\"%.2f\" % pvals[0]) + ')'\n",
    "                        results.loc[i,'lag1']       = str(\"%.4f\" % coeff[1]) + ' (' + str(\"%.2f\" % pvals[1]) + ')'\n",
    "                        results.loc[i,'lag2']       = str(\"%.4f\" % coeff[2]) + ' (' + str(\"%.2f\" % pvals[2]) + ')'\n",
    "                        results.loc[i,'lag3']       = str(\"%.4f\" % coeff[3]) + ' (' + str(\"%.2f\" % pvals[3]) + ')'\n",
    "                        \n",
    "                        results.loc[i,'n'] = X.shape[0]\n",
    "                        # results.loc[i,'lag4']       = coeff[4]\n",
    "\n",
    "                        '''results.loc[i,'pval0']      = pvals[0]\n",
    "                        results.loc[i,'pval1']      = pvals[1]\n",
    "                        results.loc[i,'pval2']      = pvals[2]\n",
    "                        results.loc[i,'pval3']      = pvals[3]\n",
    "                        # results.loc[i,'pval4']      = pvals[4]\n",
    "                        \n",
    "                        results.loc[i,'bse0']       = errs[0]\n",
    "                        results.loc[i,'bse1']       = errs[1]\n",
    "                        results.loc[i,'bse2']       = errs[2]\n",
    "                        results.loc[i,'bse3']       = errs[3]'''\n",
    "                        # results.loc[i,'bse4']       = errs[4]\n",
    "\n",
    "\n",
    "                        results.to_csv(\"../../allIndustryResults.csv\")\n",
    "\n",
    "                        print( time.time() - start)\n",
    "                        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(\"allIndustryResults.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results)\n",
    "\n",
    "'''# merge in the industry names\n",
    "conversionTable = pd.read_csv(\"../../data/indMapping.csv\")\n",
    "conversionTable.dropna(inplace=True)\n",
    "conversionTable.reset_index(drop = True, inplace = True)\n",
    "\n",
    "conversionTable.head()\n",
    "\n",
    "results = results.merge(conversionTable)\n",
    "\n",
    "results.to_csv(\"../../allIndustryResults.csv\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try this with the streak data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weatherVars  = ['hotStreak', 'wetStreak'] \n",
    "outcomeVars  = ['lnRevNormd', 'lnCostNormd']\n",
    "\n",
    "\n",
    "industries = range(1,44)\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "results = pd.DataFrame()\n",
    "\n",
    "i = 0\n",
    "\n",
    "for ind in industries:\n",
    "    print('##########################################################')\n",
    "    print(ind)\n",
    "    filename = '../../data/companyData/igData_ind' + str(ind) + '.csv'           \n",
    "    goodsData = pd.read_csv(filename).drop(columns = {'Unnamed: 0'})\n",
    "    \n",
    "    if goodsData.shape[0] > 0:\n",
    "    \n",
    "        for outcomeVar in outcomeVars:\n",
    "            for weatherVar in weatherVars:\n",
    "                i = i + 1\n",
    "\n",
    "\n",
    "                indVar = weatherVar\n",
    "\n",
    "\n",
    "                print(outcomeVar, \"~\", indVar)\n",
    "\n",
    "\n",
    "                # find: concurrent ; or lagged supplier data\n",
    "                X = goodsData.loc[:,((goodsData.columns.str.contains(indVar) & ~goodsData.columns.str.contains('empWt_')) | \n",
    "                                                (goodsData.columns.str.contains('indQtr_')) |\n",
    "                                                (goodsData.columns.str.contains('gvkey_'))  | \n",
    "                                                (goodsData.columns.str.contains('ageTercile_')) |\n",
    "                                                (goodsData.columns.str.contains('sizeTercile_')) |\n",
    "                                                (goodsData.columns.str.contains('profitTercile_')))]\n",
    "                \n",
    "                X = sm.add_constant(X)\n",
    "\n",
    "\n",
    "\n",
    "                firms = goodsData['gvkey']\n",
    "\n",
    "\n",
    "                y = goodsData[outcomeVar]\n",
    "\n",
    "\n",
    "                model = sm.OLS(y, X).fit(cov_type='cluster',cov_kwds={'groups': firms},use_t=True)\n",
    "                pvals = model.pvalues[1: 1 + len(goodsData.columns[goodsData.columns.str.contains(indVar) & ~goodsData.columns.str.contains('empWt_')] )]\n",
    "                coeff = model.params[1: 1 + len(goodsData.columns[goodsData.columns.str.contains(indVar)  & ~goodsData.columns.str.contains('empWt_')])]\n",
    "                errs  = model.bse[1: 1 + len(goodsData.columns[goodsData.columns.str.contains(indVar)     & ~goodsData.columns.str.contains('empWt_')])]\n",
    "                \n",
    "                '''print(coeff)\n",
    "                print(pvals)'''\n",
    "\n",
    "\n",
    "                results.loc[i,'industry'] = ind\n",
    "\n",
    "                results.loc[i,'outcomeVar'] = outcomeVar\n",
    "                results.loc[i,'weatherVar'] = weatherVar\n",
    "\n",
    "                results.loc[i,'lag0']       = coeff[0]\n",
    "                results.loc[i,'lag1']       = coeff[1]\n",
    "                results.loc[i,'lag2']       = coeff[2]\n",
    "                results.loc[i,'lag3']       = coeff[3]\n",
    "                results.loc[i,'lag4']       = coeff[4]\n",
    "                \n",
    "                results.loc[i,'bse0']       = errs[0]\n",
    "                results.loc[i,'bse1']       = errs[1]\n",
    "                results.loc[i,'bse2']       = errs[2]\n",
    "                results.loc[i,'bse3']       = errs[3]\n",
    "                results.loc[i,'bse4']       = errs[4]\n",
    "\n",
    "                results.loc[i,'pval0']      = pvals[0]\n",
    "                results.loc[i,'pval1']      = pvals[1]\n",
    "                results.loc[i,'pval2']      = pvals[2]\n",
    "                results.loc[i,'pval3']      = pvals[3]\n",
    "                results.loc[i,'pval4']      = pvals[4]\n",
    "\n",
    "\n",
    "                results.to_csv(\"../../allIndustryResults_streaks.csv\")\n",
    "\n",
    "                print( time.time() - start)\n",
    "                \n",
    "\n",
    "# merge in the industry names\n",
    "conversionTable = pd.read_csv(\"../../data/indMapping.csv\")\n",
    "conversionTable.dropna(inplace=True)\n",
    "conversionTable.reset_index(drop = True, inplace = True)\n",
    "\n",
    "conversionTable.head()\n",
    "\n",
    "results = results.merge(conversionTable)\n",
    "\n",
    "\n",
    "results.to_csv(\"../../allIndustryResults_streaks.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_csv(\"../../allIndustryResults_streaks.csv\").drop(columns = {'Unnamed: 0'})\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Employment Weights\n",
    "\n",
    "Now do this for the employment-weighted average of the days of extreme weather."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoffVarsYr = ['0.95'] # , '1x5Qtrs', '1x5Yrs'] # '1x5Qtrs',\n",
    "weatherVars  = ['precip_', 'temp_']        #, 'temp5Days_', 'precip5Days_'] # , 'precip_']#, , ] #[,]\n",
    "statVarsYr   = ['zipQuarterquant_']\n",
    "outcomeVars  = ['lnRevNormd', 'lnCostNormd']\n",
    "\n",
    "industries = range(1,44)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "results = pd.DataFrame()\n",
    "\n",
    "i = 0\n",
    "\n",
    "\n",
    "\n",
    "for ind in industries:\n",
    "    print('##########################################################')\n",
    "    print(ind)\n",
    "    filename = '../../data/companyData/igData_ind' + str(ind) + '.csv'           \n",
    "    goodsData = pd.read_csv(filename).drop(columns = {'Unnamed: 0'})\n",
    "    if goodsData.shape[0] > 0:\n",
    "\n",
    "\n",
    "        for outcomeVar in outcomeVars:\n",
    "            for weatherVar in weatherVars:\n",
    "                for statVar in statVarsYr:                     \n",
    "                    for cutoffVar in cutoffVarsYr:\n",
    "\n",
    "                        i = i + 1\n",
    "\n",
    "\n",
    "\n",
    "                        '''goodsData = goodsData[~goodsData.lnRev.isna() & \n",
    "                                             ~goodsData.lnCost.isna() & \n",
    "                                             ~goodsData.revenueChange.isna() & \n",
    "                                             ~goodsData.costChange.isna()]'''\n",
    "\n",
    "\n",
    "                        indVar = weatherVar + statVar + cutoffVar\n",
    "\n",
    "\n",
    "                        print(outcomeVar, \"~\", indVar)\n",
    "\n",
    "\n",
    "                        # find: concurrent ; or lagged supplier data\n",
    "                        X = goodsData.loc[:,((goodsData.columns.str.contains(indVar) & goodsData.columns.str.contains('empWt_')) | \n",
    "                                                        (goodsData.columns.str.contains('indQtr_')) |\n",
    "                                                        (goodsData.columns.str.contains('gvkey_'))  | \n",
    "                                                        (goodsData.columns.str.contains('ageTercile_')) |\n",
    "                                                        (goodsData.columns.str.contains('sizeTercile_')) |\n",
    "                                                        (goodsData.columns.str.contains('profitTercile_')))]\n",
    "\n",
    "                        X = sm.add_constant(X)\n",
    "\n",
    "                        firms = goodsData['gvkey']\n",
    "\n",
    "\n",
    "                        y = goodsData[outcomeVar]\n",
    "\n",
    "\n",
    "                        model = sm.OLS(y, X).fit(cov_type='cluster',cov_kwds={'groups': firms},use_t=True)\n",
    "                        pvals = model.pvalues[1: 1 + len(goodsData.columns[goodsData.columns.str.contains(indVar) & goodsData.columns.str.contains('empWt_')])]\n",
    "                        coeff = model.params[1: 1 + len(goodsData.columns[goodsData.columns.str.contains(indVar) & goodsData.columns.str.contains('empWt_')])]\n",
    "                        errs  = model.bse[1: 1 + len(goodsData.columns[goodsData.columns.str.contains(indVar)  & goodsData.columns.str.contains('empWt_')])]\n",
    "                \n",
    "                        '''print(coeff)\n",
    "                        print(pvals)'''\n",
    "\n",
    "\n",
    "                        results.loc[i,'industry'] = ind\n",
    "\n",
    "                        results.loc[i,'outcomeVar'] = outcomeVar\n",
    "                        results.loc[i,'weatherVar'] = weatherVar\n",
    "\n",
    "                        results.loc[i,'lag0']       = coeff[0]\n",
    "                        results.loc[i,'lag1']       = coeff[1]\n",
    "                        results.loc[i,'lag2']       = coeff[2]\n",
    "                        results.loc[i,'lag3']       = coeff[3]\n",
    "                        results.loc[i,'lag4']       = coeff[4]\n",
    "\n",
    "                        results.loc[i,'bse0']       = errs[0]\n",
    "                        results.loc[i,'bse1']       = errs[1]\n",
    "                        results.loc[i,'bse2']       = errs[2]\n",
    "                        results.loc[i,'bse3']       = errs[3]\n",
    "                        results.loc[i,'bse4']       = errs[4]\n",
    "\n",
    "                        results.loc[i,'pval0']      = pvals[0]\n",
    "                        results.loc[i,'pval1']      = pvals[1]\n",
    "                        results.loc[i,'pval2']      = pvals[2]\n",
    "                        results.loc[i,'pval3']      = pvals[3]\n",
    "                        results.loc[i,'pval4']      = pvals[4]\n",
    "\n",
    "\n",
    "                        results.to_csv(\"../../results_byInds_withControls_empWts.csv\")\n",
    "\n",
    "                        print( time.time() - start)\n",
    "                        \n",
    "\n",
    "# merge in the industry names\n",
    "conversionTable = pd.read_csv(\"../../data/indMapping.csv\")\n",
    "conversionTable.dropna(inplace=True)\n",
    "conversionTable.reset_index(drop = True, inplace = True)\n",
    "\n",
    "conversionTable.head()\n",
    "\n",
    "results = results.merge(conversionTable)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over outcome variables and weather definitions\n",
    "weather = results.weatherVar.unique()\n",
    "outcome = results.outcomeVar.unique()\n",
    "\n",
    "\n",
    "for weather in weatherVars:\n",
    "    for outcome in outcomeVars:\n",
    "        # choose the elective parts of this - number of columns and the range of the axes\n",
    "        numCols = 4\n",
    "        yLims   = 0.1\n",
    "\n",
    "        industries = results.industryName.unique()\n",
    "        rowNum = len(industries) // numCols + 1\n",
    "        colNum = numCols\n",
    "\n",
    "        fig, ax = plt.subplots(rowNum, colNum, sharex='all', sharey='all',\n",
    "                              figsize=(20,40),\n",
    "                              constrained_layout=True)\n",
    "\n",
    "        fig.suptitle('Direct Effects: ' + outcome + ' ~ ' + weather + ' Employment Weights', fontsize=36)\n",
    "\n",
    "\n",
    "\n",
    "        i = 0\n",
    "        for ind in industries:\n",
    "            rowIndex = i // numCols\n",
    "            colIndex = i % numCols\n",
    "\n",
    "\n",
    "            i   = i + 1\n",
    "\n",
    "\n",
    "            rev = results[(results.outcomeVar == outcome) & (results.weatherVar == weather) & \n",
    "                         (results.industryName == ind)].reset_index()\n",
    "            x   = [0,1,2,3,4]\n",
    "            y   = [rev.lag0,rev.lag1,rev.lag2,rev.lag3,rev.lag4]\n",
    "\n",
    "\n",
    "            errors = [rev.bse0,rev.bse1,rev.bse2,rev.bse3,rev.bse4]\n",
    "\n",
    "            # plt.errorbar(x,y,yerr = errors, fmt = '.k')\n",
    "            # plt.show()\n",
    "\n",
    "            '''ax[rowIndex, colIndex].text(0.5, 0.5, str((i, j)),\n",
    "                                  fontsize=18, ha='center')'''\n",
    "            ax[rowIndex, colIndex].errorbar(x,y,yerr = errors, fmt = '.k')\n",
    "            ax[rowIndex, colIndex].xaxis.grid(False)\n",
    "            ax[rowIndex, colIndex].yaxis.grid(False)\n",
    "            ax[rowIndex, colIndex].axhline(y=0)\n",
    "            ax[rowIndex, colIndex].set_ylim([-yLims, yLims])\n",
    "\n",
    "            ax[rowIndex, colIndex].yaxis.set_ticks(np.arange(-yLims, yLims + 0.1, 0.1))\n",
    "            ax[rowIndex, colIndex].xaxis.set_ticks(np.arange(0.0, 5.0, 1.0))\n",
    "\n",
    "            ax[rowIndex, colIndex].tick_params(axis='both', labelsize = 16)\n",
    "            ax[rowIndex, colIndex].set_title(ind, fontsize = 24)\n",
    "\n",
    "\n",
    "            # ax[rowIndex, colIndex].\n",
    "            \n",
    "        fig.savefig('dirEffects_' + outcome + '_' + weather + '_empWts' + '.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indirect Effects\n",
    "This is almost exactly the same but with supplier information in place of the direct company information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can alter this so that we're doing it with the employment weights as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoffVarsYr = ['0.95'] \n",
    "weatherVars  = ['precip_', 'temp_'] \n",
    "statVarsYr   = ['zipQuarterquant_']\n",
    "outcomeVars  = ['lnRevNormd', 'lnCostNormd']\n",
    "\n",
    "\n",
    "industries = range(1,44)\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "results = pd.DataFrame()\n",
    "\n",
    "i = 0\n",
    "\n",
    "\n",
    "\n",
    "for ind in industries:\n",
    "    print('##########################################################')\n",
    "    print(ind)\n",
    "    \n",
    "    filename = \"../../data/companyData/supplier_igData_ind\" + str(ind) + \".csv\"\n",
    "    goodsData = pd.read_csv(filename).drop(columns = {'Unnamed: 0'})\n",
    "\n",
    "    if goodsData.shape[0] > 50:\n",
    "        for outcomeVar in outcomeVars:\n",
    "            for weatherVar in weatherVars:\n",
    "                for statVar in statVarsYr:                     \n",
    "                    for cutoffVar in cutoffVarsYr:\n",
    "\n",
    "                        i = i + 1\n",
    "\n",
    "                        indVar = weatherVar + statVar + cutoffVar\n",
    "\n",
    "\n",
    "                        print(outcomeVar, \"~\", indVar)\n",
    "\n",
    "\n",
    "                        # find: concurrent ; or lagged supplier data\n",
    "                        X = goodsData.loc[:,(((goodsData.columns.str.contains(indVar)) & ~goodsData.columns.str.contains('empWt_')) | \n",
    "                                (goodsData.columns.str.contains('indQtr_')) |\n",
    "                                (goodsData.columns.str.contains('gvkey_')) | #  | \n",
    "                                (goodsData.columns.str.contains('ageTercile_')) |\n",
    "                                (goodsData.columns.str.contains('sizeTercile_')) |\n",
    "                                (goodsData.columns.str.contains('profitTercile_')) | \n",
    "                                (goodsData.columns == 'supplierTercile'))] \n",
    "                        \n",
    "                        X = sm.add_constant(X)\n",
    "\n",
    "                        print(X.columns)\n",
    "                        firms = goodsData['gvkey']\n",
    "\n",
    "\n",
    "                        y = goodsData[outcomeVar]\n",
    "\n",
    "\n",
    "                        model = sm.OLS(y, X).fit(cov_type='cluster',cov_kwds={'groups': firms},use_t=True)\n",
    "                        pvals = model.pvalues[1: 1 + len(goodsData.columns[goodsData.columns.str.contains(indVar) & ~goodsData.columns.str.contains('empWt_')] )]\n",
    "                        coeff = model.params[1: 1 + len(goodsData.columns[goodsData.columns.str.contains(indVar)  & ~goodsData.columns.str.contains('empWt_')])]\n",
    "                        errs  = model.bse[1: 1 + len(goodsData.columns[goodsData.columns.str.contains(indVar)     & ~goodsData.columns.str.contains('empWt_')])]\n",
    "                \n",
    "                        '''print(coeff)\n",
    "                        print(pvals)'''\n",
    "\n",
    "\n",
    "                        results.loc[i,'industry'] = ind\n",
    "\n",
    "                        results.loc[i,'outcomeVar'] = outcomeVar\n",
    "                        results.loc[i,'weatherVar'] = weatherVar\n",
    "\n",
    "                        results.loc[i,'lag0']       = coeff[0]\n",
    "                        results.loc[i,'lag1']       = coeff[1]\n",
    "                        results.loc[i,'lag2']       = coeff[2]\n",
    "                        results.loc[i,'lag3']       = coeff[3]\n",
    "                        results.loc[i,'lag4']       = coeff[4]\n",
    "\n",
    "                        results.loc[i,'bse0']       = errs[0]\n",
    "                        results.loc[i,'bse1']       = errs[1]\n",
    "                        results.loc[i,'bse2']       = errs[2]\n",
    "                        results.loc[i,'bse3']       = errs[3]\n",
    "                        results.loc[i,'bse4']       = errs[4]\n",
    "\n",
    "                        results.loc[i,'pval0']      = pvals[0]\n",
    "                        results.loc[i,'pval1']      = pvals[1]\n",
    "                        results.loc[i,'pval2']      = pvals[2]\n",
    "                        results.loc[i,'pval3']      = pvals[3]\n",
    "                        results.loc[i,'pval4']      = pvals[4]\n",
    "\n",
    "\n",
    "                        results.to_csv(\"../../indirResults_hqs.csv\")\n",
    "\n",
    "                        print( time.time() - start)\n",
    "\n",
    "\n",
    "# merge in the industry names\n",
    "conversionTable = pd.read_csv(\"../../data/indMapping.csv\")\n",
    "conversionTable.dropna(inplace=True)\n",
    "conversionTable.reset_index(drop = True, inplace = True)\n",
    "\n",
    "conversionTable.head()\n",
    "\n",
    "results = results.merge(conversionTable)\n",
    "\n",
    "results.to_csv(\"../../indirResults_hqs.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_csv(\"../../indirResults_hqs.csv\").drop(columns = {'Unnamed: 0'})\n",
    "print(results.industry.unique())\n",
    "results.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(outcome, weather, ind)\n",
    "\n",
    "rev = results[(results.outcomeVar == outcome) & (results.weatherVar == weather) & \n",
    "                         (results.industry == ind)].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over outcome variables and weather definitions\n",
    "weatherVars = results.weatherVar.unique()\n",
    "outcomeVars = results.outcomeVar.unique()\n",
    "\n",
    "industries = [2,17,18,28,31,40,41,42] # results.industryName.unique()\n",
    "\n",
    "for outcome in outcomeVars:\n",
    "    for weather in weatherVars:\n",
    "        # choose the elective parts of this - number of columns and the range of the axes\n",
    "        numCols = 3\n",
    "        yLims   = 0.03\n",
    "\n",
    "        # industries = results.industryName.unique()\n",
    "        rowNum = len(industries) // numCols + 1\n",
    "        colNum = numCols\n",
    "\n",
    "        fig, ax = plt.subplots(rowNum, colNum, sharex='all', sharey='all',\n",
    "                              figsize=(20,20),\n",
    "                              constrained_layout=True)\n",
    "\n",
    "        fig.suptitle('Indirect Effects: ' + outcome + ' ~ ' + weather, fontsize=36)\n",
    "\n",
    "\n",
    "\n",
    "        i = 0\n",
    "        for ind in industries:\n",
    "            rowIndex = i // numCols\n",
    "            colIndex = i % numCols\n",
    "\n",
    "\n",
    "            i   = i + 1\n",
    "\n",
    "\n",
    "            rev = results[(results.outcomeVar == outcome) & (results.weatherVar == weather) & \n",
    "                         (results.industry == ind)].reset_index()\n",
    "            indName = rev.industryName.unique()[0]\n",
    "            x   = [0,1,2,3,4]\n",
    "            y   = [rev.lag0,rev.lag1,rev.lag2,rev.lag3,rev.lag4]\n",
    "\n",
    "\n",
    "            errors = [rev.bse0,rev.bse1,rev.bse2,rev.bse3,rev.bse4]\n",
    "\n",
    "            # plt.errorbar(x,y,yerr = errors, fmt = '.k')\n",
    "            # plt.show()\n",
    "\n",
    "            '''ax[rowIndex, colIndex].text(0.5, 0.5, str((i, j)),\n",
    "                                  fontsize=18, ha='center')'''\n",
    "            ax[rowIndex, colIndex].errorbar(x,y,yerr = errors, fmt = '.k')\n",
    "            ax[rowIndex, colIndex].xaxis.grid(False)\n",
    "            ax[rowIndex, colIndex].yaxis.grid(False)\n",
    "            ax[rowIndex, colIndex].axhline(y=0)\n",
    "            ax[rowIndex, colIndex].set_ylim([-yLims, yLims])\n",
    "\n",
    "            ax[rowIndex, colIndex].yaxis.set_ticks(np.arange(-yLims, yLims + 0.1, 0.1))\n",
    "            ax[rowIndex, colIndex].xaxis.set_ticks(np.arange(0.0, 5.0, 1.0))\n",
    "\n",
    "            ax[rowIndex, colIndex].tick_params(axis='both', labelsize = 16)\n",
    "            ax[rowIndex, colIndex].set_title(indName, fontsize = 24)\n",
    "\n",
    "\n",
    "            # ax[rowIndex, colIndex].\n",
    "    \n",
    "        fig.savefig('indirEffects_' + outcome + '_' + weather + '.png')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now do this by streaks - consecutive days with at least 95th percentile temp or rain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "weatherVars  = ['hotStreak',  'wetStreak']   #[,]\n",
    "outcomeVars  = ['lnRevNormd', 'lnCostNormd'] # ['revenueChange'] #[, 'costChange']#,'lnCost','lnInc','lnRev']\n",
    "\n",
    "# if we wanted to do the regressions below for all industries, we would use the following\n",
    "'''filename = \"../../data/companyData/goodsData_supplierData.csv\"\n",
    "goodsData = pd.read_csv(filename).drop(columns = {'Unnamed: 0'})\n",
    "'''\n",
    "\n",
    "# goodsData = goodsData[~goodsData.lnRev.isna() & ~goodsData.lnCost.isna() & ~goodsData.lnCostNormd.isna()]\n",
    "goodsData['scTercile']  = pd.qcut(goodsData['suppliers'], 3, labels=False, duplicates = 'drop')\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "results = pd.DataFrame()\n",
    "i = 0\n",
    "\n",
    "industries = range(1,44)\n",
    "\n",
    "for ind in industries:\n",
    "    filename = \"../../data/companyData/supplier_igData_ind\" + str(ind) + \".csv\"\n",
    "    goodsData = pd.read_csv(filename).drop(columns = {'Unnamed: 0'})\n",
    "\n",
    "    if goodsData.shape[0] > 50:\n",
    "\n",
    "        for outcomeVar in outcomeVars:\n",
    "            for weatherVar in weatherVars:\n",
    "                \n",
    "                i = i + 1\n",
    "                \n",
    "                indVar = weatherVar\n",
    "\n",
    "\n",
    "                print(outcomeVar, \"~\", indVar)\n",
    "\n",
    "\n",
    "                # find: concurrent ; or lagged supplier datawet\n",
    "                X = goodsData.loc[:,(((goodsData.columns.str.contains(indVar))) | \n",
    "                                (goodsData.columns.str.contains('indQtr_')) |\n",
    "                                (goodsData.columns.str.contains('gvkey_')) | #  | \n",
    "                                (goodsData.columns.str.contains('ageTercile_')) |\n",
    "                                (goodsData.columns.str.contains('sizeTercile_')) |\n",
    "                                (goodsData.columns.str.contains('profitTercile_')) | \n",
    "                                (goodsData.columns == 'supplierTercile'))]     \n",
    "\n",
    "                X = sm.add_constant(X)\n",
    "\n",
    "                \n",
    "                firms = goodsData['gvkey']\n",
    "\n",
    "\n",
    "                y = goodsData[outcomeVar]\n",
    "\n",
    "\n",
    "                modelResults = sm.OLS(y, X).fit(cov_type='cluster',cov_kwds={'groups': firms},use_t=True)\n",
    "                pvals = modelResults.pvalues[1: 1 + len(goodsData.columns[goodsData.columns.str.contains(indVar) & goodsData.columns.str.contains('supplier_')])]\n",
    "                coeff = modelResults.params[1: 1 + len(goodsData.columns[goodsData.columns.str.contains(indVar)  & goodsData.columns.str.contains('supplier_')])]\n",
    "                errs  = modelResults.bse[1: 1 + len(goodsData.columns[goodsData.columns.str.contains(indVar)  & goodsData.columns.str.contains('supplier_')])]\n",
    "                \n",
    "                '''print(coeff)\n",
    "                print(pvals)'''\n",
    "\n",
    "\n",
    "                results.loc[i,'industry'] = ind\n",
    "\n",
    "                results.loc[i,'outcomeVar'] = outcomeVar\n",
    "                results.loc[i,'weatherVar'] = weatherVar\n",
    "\n",
    "                results.loc[i,'lag0']       = coeff[0]\n",
    "                results.loc[i,'lag1']       = coeff[1]\n",
    "                results.loc[i,'lag2']       = coeff[2]\n",
    "                results.loc[i,'lag3']       = coeff[3]\n",
    "                results.loc[i,'lag4']       = coeff[4]\n",
    "                \n",
    "                results.loc[i,'bse0']       = errs[0]\n",
    "                results.loc[i,'bse1']       = errs[1]\n",
    "                results.loc[i,'bse2']       = errs[2]\n",
    "                results.loc[i,'bse3']       = errs[3]\n",
    "                results.loc[i,'bse4']       = errs[4]\n",
    "\n",
    "                results.loc[i,'pval0']      = pvals[0]\n",
    "                results.loc[i,'pval1']      = pvals[1]\n",
    "                results.loc[i,'pval2']      = pvals[2]\n",
    "                results.loc[i,'pval3']      = pvals[3]\n",
    "                results.loc[i,'pval4']      = pvals[4]\n",
    "                \n",
    "                \n",
    "                \n",
    "                print( time.time() - start)\n",
    "\n",
    "                results.to_csv(\"../../data/indirResults_hqs_streaks.csv\")\n",
    "\n",
    "# merge in the industry names\n",
    "conversionTable = pd.read_csv(\"../../data/indMapping.csv\")\n",
    "conversionTable.dropna(inplace=True)\n",
    "conversionTable.reset_index(drop = True, inplace = True)\n",
    "\n",
    "conversionTable.head()\n",
    "\n",
    "results = results.merge(conversionTable)\n",
    "\n",
    "\n",
    "results.to_csv(\"../../data/indirResults_hqs_streaks.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_csv(\"../../data/indirResults_hqs_streaks.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weatherVars = results.weatherVar.unique()\n",
    "outcomeVars = results.outcomeVar.unique()\n",
    "\n",
    "industries = [2,17,18,28,31,40,41,42] # results.industryName.unique()\n",
    "\n",
    "for outcome in outcomeVars:\n",
    "    for weather in weatherVars:\n",
    "        # choose the elective parts of this - number of columns and the range of the axes\n",
    "        numCols = 3\n",
    "        yLims   = 0.2\n",
    "\n",
    "        # industries = results.industryName.unique()\n",
    "        rowNum = len(industries) // numCols + 1\n",
    "        colNum = numCols\n",
    "\n",
    "        fig, ax = plt.subplots(rowNum, colNum, sharex='all', sharey='all',\n",
    "                              figsize=(20,20),\n",
    "                              constrained_layout=True)\n",
    "\n",
    "        fig.suptitle('Indirect Effects: ' + outcome + ' ~ ' + weather, fontsize=36)\n",
    "\n",
    "\n",
    "\n",
    "        i = 0\n",
    "        for ind in industries:\n",
    "            rowIndex = i // numCols\n",
    "            colIndex = i % numCols\n",
    "\n",
    "\n",
    "            i   = i + 1\n",
    "\n",
    "\n",
    "            rev = results[(results.outcomeVar == outcome) & (results.weatherVar == weather) & \n",
    "                         (results.industry == ind)].reset_index()\n",
    "            indName = rev.industryName.unique()[0]\n",
    "            x   = [0,1,2,3,4]\n",
    "            y   = [rev.lag0,rev.lag1,rev.lag2,rev.lag3,rev.lag4]\n",
    "\n",
    "\n",
    "            errors = [rev.bse0,rev.bse1,rev.bse2,rev.bse3,rev.bse4]\n",
    "\n",
    "            # plt.errorbar(x,y,yerr = errors, fmt = '.k')\n",
    "            # plt.show()\n",
    "\n",
    "            '''ax[rowIndex, colIndex].text(0.5, 0.5, str((i, j)),\n",
    "                                  fontsize=18, ha='center')'''\n",
    "            ax[rowIndex, colIndex].errorbar(x,y,yerr = errors, fmt = '.k')\n",
    "            ax[rowIndex, colIndex].xaxis.grid(False)\n",
    "            ax[rowIndex, colIndex].yaxis.grid(False)\n",
    "            ax[rowIndex, colIndex].axhline(y=0)\n",
    "            ax[rowIndex, colIndex].set_ylim([-yLims, yLims])\n",
    "\n",
    "            ax[rowIndex, colIndex].yaxis.set_ticks(np.arange(-yLims, yLims + 0.1, 0.1))\n",
    "            ax[rowIndex, colIndex].xaxis.set_ticks(np.arange(0.0, 5.0, 1.0))\n",
    "\n",
    "            ax[rowIndex, colIndex].tick_params(axis='both', labelsize = 16)\n",
    "            ax[rowIndex, colIndex].set_title(indName, fontsize = 24)\n",
    "\n",
    "            # ax[rowIndex, colIndex].\n",
    "    \n",
    "        fig.savefig('indirEffects_' + outcome + '_' + weather + '.png')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "----------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Faster and More Heuristic\n",
    "The below gives us unclustered standard errors, output to a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findSE(X,reg,y):\n",
    "    N = len(X)\n",
    "    p = len(X.columns) + 1  # plus one because LinearRegression adds an intercept term\n",
    "\n",
    "    X_with_intercept = np.empty(shape=(N, p), dtype=np.float)\n",
    "    X_with_intercept[:, 0] = 1\n",
    "    X_with_intercept[:, 1:p] = X.values\n",
    "\n",
    "    y_hat = reg.predict(X)\n",
    "    residuals = y.values - y_hat\n",
    "    residual_sum_of_squares = residuals.T @ residuals\n",
    "    sigma_squared_hat = residual_sum_of_squares / (N - p)\n",
    "    var_beta_hat = np.linalg.inv(X_with_intercept.T @ X_with_intercept) * sigma_squared_hat\n",
    "\n",
    "    se0 = var_beta_hat[1, 1] ** 0.5\n",
    "    se1 = var_beta_hat[2, 2] ** 0.5\n",
    "    se2 = var_beta_hat[3, 3] ** 0.5\n",
    "    se3 = var_beta_hat[4, 4] ** 0.5\n",
    "    se4 = var_beta_hat[5, 5] ** 0.5\n",
    "    se5 = var_beta_hat[6, 6] ** 0.5\n",
    "    '''se6 = var_beta_hat[7, 7] ** 0.5\n",
    "    se7 = var_beta_hat[8, 8] ** 0.5\n",
    "    se8 = var_beta_hat[9, 9] ** 0.5'''\n",
    "    return([abs(reg.coef_[0]/se0),abs(reg.coef_[1]/se1),abs(reg.coef_[2]/se2),\n",
    "            abs(reg.coef_[3]/se3),abs(reg.coef_[4]/se4),abs(reg.coef_[5]/se5)]\n",
    "          )\n",
    "\n",
    "'''        \n",
    "abs(reg.coef_[0]/se0),\n",
    "          abs(reg.coef_[1]/se1),\n",
    "          abs(reg.coef_[2]/se2),\n",
    "          abs(reg.coef_[3]/se3),\n",
    "          abs(reg.coef_[4]/se4),\n",
    "          abs(reg.coef_[5]/se5),\n",
    "          \"SE0: \", se0,\n",
    "          \"SE1: \", se1,\n",
    "          \"SE2: \", se2,\n",
    "          \"SE3: \", se3,\n",
    "          \"SE4: \", se4,\n",
    "          \"SE5: \", se5,\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "'''cutoffVarsYr = ['0.95'] # ,'1xYr']                                    #,'1x5Yrs'] #, ] # ,'1xQtr', '1x5Qtrs'\n",
    "weatherVars  = ['precip_', 'temp_', 'precip5Days_', 'temp5Days_'] #[,]\n",
    "statVarsYr   = ['zipquant_','zipQuarterquant_']\n",
    "outcomeVars  = ['lnRev', 'revenueChange'] # ,'lnCost',  'costChange'] # [,'lnRevNormd','lnCostNormd'] # 'revenueChange' 'costChange',\n",
    "firmVars     = ['firmQtr_'] # 'gvkey'\n",
    "'''\n",
    "\n",
    "# try this by industry\n",
    "cutoffVarsYr = ['0.95'] # ,'1xYr']                                    #,'1x5Yrs'] #, ] # ,'1xQtr', '1x5Qtrs'\n",
    "weatherVars  = ['precip_', 'temp_', 'precip5Days_', 'temp5Days_'] #[,]\n",
    "statVarsYr   = ['ffquant_','indQuarterquant_']\n",
    "outcomeVars  = ['lnRev', 'revenueChange',  'lnCost',  'costChange'] # [,'lnRevNormd','lnCostNormd'] # 'revenueChange' 'costChange',\n",
    "firmVars     = ['firmQtr_']\n",
    "\n",
    "\n",
    "inds = [1, 2, 6, 7, 18, 31, 41, 42]\n",
    "\n",
    "goodsData = goodsData[~goodsData.lnRev.isna() & ~goodsData.lnCost.isna() &\n",
    "                      ~goodsData.lnCostNormd.isna() & ~goodsData.lnRevNormd.isna()]\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "results = pd.DataFrame()\n",
    "i = 0\n",
    "for ind in inds:\n",
    "    print('#######################################################################################',ind)\n",
    "    for outcomeVar in outcomeVars:\n",
    "        for weatherVar in weatherVars:\n",
    "            for statVar in statVarsYr:                     \n",
    "                for cutoffVar in cutoffVarsYr:\n",
    "                    for firmVar in firmVars:\n",
    "                        tempData = goodsData[goodsData.famafrench == ind]\n",
    "                        \n",
    "                        i = i + 1\n",
    "                        indVar = weatherVar + statVar + cutoffVar\n",
    "\n",
    "\n",
    "                        print(outcomeVar, \"~\", indVar, \"|\", firmVar)\n",
    "\n",
    "\n",
    "                        # find: concurrent ; or lagged supplier data\n",
    "                        X = tempData.loc[:,((tempData.columns.str.contains(indVar)) |\n",
    "                                          (tempData.columns.str.contains('indQtr_')) |\n",
    "                                          # (goodsData.columns.str.contains('gvkey_'))) |   # &   \n",
    "                                          # (goodsData.columns.str.contains('firmQtr_'))) |\n",
    "                                          (tempData.columns.str.contains(firmVar)))] # |\n",
    "                        '''(tempData.columns.str.contains('ageQtr_')) |\n",
    "                          (tempData.columns.str.contains('sizeQtr_')) |\n",
    "                          (tempData.columns.str.contains('profitQtr_'))]   #  & '''\n",
    "\n",
    "                                          # (goodsData.columns.str.contains('firmQtr_')))       & \n",
    "                                        # ~(goodsData.columns.str.contains('lag4')) &\n",
    "                                                                        # ~(goodsData.columns.str.contains('lag2')) & \n",
    "\n",
    "\n",
    "                        X = X[X.columns[(X.sum(axis = 0) >= 4)]]\n",
    "                        # print(X.columns)\n",
    "                        firms = tempData['gvkey']\n",
    "\n",
    "\n",
    "                        y = tempData[outcomeVar]\n",
    "\n",
    "\n",
    "                        ######################################\n",
    "                        # fit the model on this subset\n",
    "                        reg = linear_model.LinearRegression()\n",
    "                        reg.fit(X,y)\n",
    "\n",
    "\n",
    "                        # print('Coeff: ' , reg.coef_[0:5], 'SE type (looking >2): ', findSE(X,reg,y))\n",
    "                        results.loc[i,'ind'] = ind\n",
    "\n",
    "\n",
    "                        results.loc[i,'outcomeVar'] = outcomeVar\n",
    "                        results.loc[i,'weatherVar'] = weatherVar\n",
    "                        results.loc[i,'statVar']    = statVar\n",
    "                        results.loc[i,'cutoffVar']  = cutoffVar\n",
    "                        results.loc[i,'firmVar']    = firmVar\n",
    "\n",
    "\n",
    "                        results.loc[i,'lag0']       = reg.coef_[0]\n",
    "                        results.loc[i,'lag1']       = reg.coef_[1]\n",
    "                        results.loc[i,'lag2']       = reg.coef_[2]\n",
    "                        results.loc[i,'lag3']       = reg.coef_[3]\n",
    "                        results.loc[i,'lag4']       = reg.coef_[4]\n",
    "\n",
    "\n",
    "\n",
    "                        seratios = findSE(X,reg,y)\n",
    "\n",
    "                        results.loc[i,'ratio0']       = seratios[0]\n",
    "                        results.loc[i,'ratio1']       = seratios[1]\n",
    "                        results.loc[i,'ratio2']       = seratios[2]\n",
    "                        results.loc[i,'ratio3']       = seratios[3]\n",
    "                        results.loc[i,'ratio4']       = seratios[4]\n",
    "\n",
    "                        # print(results)\n",
    "\n",
    "                        print(time.time() - start)\n",
    "\n",
    "                        print('*******************************************************************')\n",
    "                    \n",
    "results.to_csv(\"../../data/results_notNormd.csv\")\n",
    "\n",
    "\n",
    "# merge in the industry names\n",
    "conversionTable = pd.read_csv(\"../../data/indMapping.csv\")\n",
    "conversionTable.dropna(inplace=True)\n",
    "conversionTable.reset_index(drop = True, inplace = True)\n",
    "\n",
    "conversionTable.head()\n",
    "\n",
    "results = results.merge(conversionTable)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
